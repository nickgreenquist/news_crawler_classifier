CU Boulder Associate Professor Karen Chin excavates dinosaur coprolites at Grand Staircase-Escalante National Monument in Utah, in this May 10, 2013 photo.
Courtesy University of Colorado/Handout via REUTERS

WASHINGTON (Reuters) - Some plant-eating dinosaurs apparently liked a side order of crabs to go with their usual salad.
Scientists said on Thursday fossilized dung thought to have come from herbivorous duck-billed dinosaurs that inhabited southern Utah 75 million years ago contained pieces of crustacean shells along with vestiges of vegetation.
The discovery provides the strongest evidence to date that some large herbivorous dinosaurs sometimes strayed from a purely vegetarian diet, said University of Colorado paleontologist Karen Chin, who led the research published in the journal Scientific Reports.
This was a very exciting discovery, precisely because it was so unexpected, Chin said.
Fossilized dung, called coprolites, offers insight into the diet of extinct creatures that cannot be gleaned by merely studying teeth, jaws and skeletons.
Ten coprolites from Utahs Grand Staircase-Escalante National Monument contained crustacean shells mixed with rotted coniferous wood.
For at least part of the year these duck-billed dinosaurs may have munched on rotting logs because they contained stores of crustaceans and other invertebrates, Chin said.
Field Museum scientists Pete Makovicky (L), Associate Curator of Dinosaurs, and Bill Simpson, Head of Geological Collections, use a cast of one of the T. rex SUEs gastralia -- a set of bones that look like an additional set of ribs -- to show where they will be positioned on her skeleton in Chicago, Illinois, U.S. in this undated handout photo obtained by Reuters August 29, 2017.
Zachary James Johnston/The Field Museum/Handout via REUTERS

Chin said the researchers do not know precisely what types of crustaceans were eaten by the dinosaurs, but it was possible they were crabs.
A variety of crustaceans also including crayfish and pillbugs are known to shelter in the moist environments of rotting logs.
The crustaceans were at least two inches (5 cm) long.
Rotting wood and fungal tissues would have offered useful nutritional compounds such as cellulose and fiber, and the crustaceans would have provided good sources of protein and calcium.
Protein is an important component of animal diets, and is particularly important when animals are breeding, Chin said.
The size of two dinosaurs, the Argentine titanosaur Patagotitan mayorum and the North American predator Tyrannosaurus rex are compared with a human figure for scale, in this handout illustration obtained by Reuters August 29, 2017.
The Field Museum/Handout via REUTERS

The researchers think eating crustaceans may have been a seasonal dietary change linked to breeding and egg-laying.
Some birds, the evolutionary descendants of dinosaurs, consume more protein and calcium during breeding season.
Duck-billed dinosaurs, also called hadrosaurs, earned their name because the front of their skull resembles a ducks bill.
They also possessed beaks and specialized teeth for grinding plant material, and are believed to have roamed the landscape in herds.
Two hadrosaurs that lived in the area at the time were: Parasaurolophus, roughly 33 feet (10 meters) long with a long tubular head crest; and Gryposaurus, about 39 feet (12 meters) long with an arched nasal crest.
Hadrosaurs were common in western North America and other parts of the world during the Cretaceous Period, representing an important plant-eating group alongside armored dinosaurs and horned dinosaurs.
A primitive type of jellyfish called Cassiopea, which goes to sleep nightly, is seen on the floor of their tank at Caltech in Pasadena, California, U.S. in this image released on September 20, 2017.
Courtesy Caltech/Handout via REUTERS

WASHINGTON (Reuters) - Even a jellyfish - one of Earths first and most ancient animals - needs its sleep.
Scientists said on Thursday they have demonstrated that a primitive type of jellyfish called Cassiopea goes to sleep nightly.
While sleep has been confirmed in other invertebrates such as worms and fruit flies, the jellyfish is the most evolutionarily ancient animal that has been shown to slumber.
These results suggest that even those animals that lack a centralized nervous system require sleep, which means that sleep is one of the most ancient behavioral states, deeply rooted within the animal lineage, California Institute of Technology biologist Ravi Nath said.
Jellyfish have thrived in the seas for at least 600 million years, longer than nearly any other animal.
By comparison, dinosaurs appeared roughly 230 million years ago and humans appeared roughly 300,000 years ago.
The findings involving such a primordial creature raise fresh questions about sleeps origin and purpose.
We do not know if sleep is limited to just animals, said Nath, who helped lead the study published in the journal Current Biology.
Sleep is a genetically encoded behavioral state.
Genes and neural circuits interact to generate the sleep state, Nath added.
I think it would be hard to demonstrate a sleep state in an organism that is not an animal, but I think the sleep state that we know may have been co-opted from periods of quiescence in organisms as diverse as plants, bacteria and fungi.
Jellyfish are among the first animals to have developed neurons - nerve cells - though they lack a brain, spine or central nervous system.
Cassiopea jellyfish live in clear, shallow, tropical waters of the Pacific and western Atlantic oceans, eating plankton.
Measuring about 1-2 inches (2.5-5 cm) in diameter, they are dubbed the upside-down jellyfish because they lie on the seafloor inverted in the water with their tentacles upward.
Through lab experiments, the researchers determined Cassiopea met three important sleep criteria: periods of decreased activity known as behavioral quiescence; a decreased response to stimuli; and an increased sleep drive after being sleep deprived.
The jellyfish were found to display periods of inactivity at night, pulsing their bodies 30 percent less often than during daytime.
When a platform underneath them was removed, they took up to 5 seconds to wake up and reorient themselves.
And when deprived of nighttime sleep by being nudged with a squirt of water, they became more likely to sleep during the day.
The researchers did not examine whether jellyfish dream.
SOURCE: bit.ly/2fElMrT Current Biology, online September 21, 2017.
(Reuters) - The U.S. space agency NASA received a final signal from its Cassini spacecraft on Friday as it ended a groundbreaking, 13-year Saturn mission with a meteor-like plunge into the ringed planets atmosphere.
Cassini, the first spacecraft to orbit Saturn, entered the gaseous giants crushing atmosphere at 7:55 a.m. EDT (1155 GMT) at about 70,000 miles per hour (113,000 km per hour), the National Aeronautics and Space Administration said.
This morning a lone explorer - a machine made by human-kind - finished its mission 900 million miles away, Cassini project manager Earl Maize said at a news conference on Friday at NASAs Jet Propulsion Laboratory in Pasadena, California.
We believe we got every last second of data.
The end of Cassinis voyage, which began with its launch in 1997 and a seven-year journey to Saturn, was met with applause, hugs and tears from NASA officials after its final transmission was received, according to video footage on the space agencys website.
Officials at the news conference displayed the last set of images Cassini captured of Saturn as it crashed into the planet.
The planets lakes and seas near its north pole were visible, along with detailed views of gaps in its massive rings.
Maize said Cassinis data, sent until the final fiery moment, was already being studied by NASA analysts in Arizona.
The transmissions are expected to include unprecedented data from the atmospheres upper fringe, about 1,190 miles (1,915 km) above Saturns cloudtops.
The data took 84 minutes to reach NASA antennas in Canberra, Australia, Maize said.
FILE PHOTO: The spacecraft Cassini is pictured above Saturn's northern hemisphere prior to making one of its Grand Finale dives in this NASA handout illustration obtained by Reuters August 29, 2017.
NASA/Handout via REUTERS

The final dive ended a mission that gave scientists a ringside seat to the sixth planet from the sun.
The spacecrafts discoveries included seasonal changes on Saturn, a hexagon-shaped pattern on its north pole and the moon Titans resemblance to a primordial Earth.
Cassini also found a global ocean on the moon Enceladus, with ice plumes spouting from its surface.
Enceladus has become a promising lead in the search for places outside Earth that could support life.
The spacecraft has produced 450,000 images and 635 gigabytes of data since it began probing Saturn and its 62 known moons in July 2004.
Slideshow (13 Images)

Cassini, a cooperative project between NASA, the European Space Agency and the Italian Space Agency, was launched into space in October 1997 from Cape Canaveral in Florida.
With the spacecraft running low on fuel, NASA crashed it into Saturn to avoid any chance of it someday colliding with and contaminating Titan, Enceladus or another moon that has the potential for indigenous microbial life.
Cassini started a series of 22 orbital dives in April, using Titans gravity to slingshot itself into the unexplored area between the planet and its rings.
The spacecraft studied Saturns atmosphere and took measurements to determine the size of the planets rocky core.
Scientists took to Twitter to share their goodbyes.
Farewell Cassini, how far youve come, astrophysicist Neil deGrasse Tyson said on Twitter.
On this eve, in fiery death, Saturn & you are one.
VIP (Vaporize In Peace): 2004-2017.
BAIKONUR COSMODROME, Kazakhstan (Reuters) - Two U.S. astronauts and a Russian cosmonaut arrived at the International Space Station on Wednesday, about six hours after their Soyuz spacecraft blasted off from Kazakhstan, a NASA TV broadcast showed.
Commander Alexander Misurkin of Roscosmos and flight engineers Mark Vande Hei and Joe Acaba of NASA lifted off from the Baikonur Cosmodrome at 3:17 a.m. local time on Wednesday (2117 GMT/1717 EDT on Tuesday).
Their spacecraft docked at 8:55 a.m..
The crew successfully performed a fast-track transit to the station, which orbits about 250 miles (400 km) above Earth, to begin a five-month mission.
Failure would have forced the spacecraft to take a two-day route for another attempt at docking.
Misurkin, Vande Hei and Acaba have joined NASA astronaut Randy Bresnik, Russias Sergey Ryazanskiy and Paolo Nespoli of the European Space Agency who have been aboard the orbital outpost since July.
To commemorate the upcoming 60th anniversary on Oct.4 of the launch of the first artificial satellite, Sputnik 1, the Soyuz crew used its small model as a zero gravity indicator during the flight on Wednesday.
(Reuters) - Green, purple, pink and yellow lights danced across the sky in striking aurora displays over northern Finland early on Friday.
Travel magazine All About Lapland posted a video on social media of the impressive light show seen from Pallas, in the Muonio region, adding it had rarely seen anything on this scale.
The Northern Lights are a result of collisions between electrically charged particles from the sun that enter the Earths atmosphere.
A strong geomagnetic storm was behind this weeks particularly stunning show.
Known as aurora borealis, or the Northern Lights, in the northern hemisphere, they go by aurora australis, or the Southern Lights, in the southern hemisphere.
LONDON, Sept 7 (Reuters) - The alcohol industry uses denial, distortion and distraction to mislead people about the risks of developing cancer from drinking, often employing similar tactics to those of the tobacco industry, a study said on Thursday.
Drinks industry organizations often present the relationship between alcohol and cancer as highly complex, implying there is no clear evidence of a consistent link, said the study led by scientists at the London School of Hygiene & Tropical Medicine (LSHTM) and Swedens Karolinska Institutet.
Other strategies include denying any relationship exists, or saying inaccurately that there is no risk with moderate drinking, the study found.
The industry also seeks to mention a wide range of other real and potential cancer risk factors in an effort to present alcohol as just one of many, it added.
Responding to the study, the Distilled Spirits Council, a U.S. alcohol trade association, said it was a highly selective review authored by researchers with anti-alcohol biases.
The Council does not recommend that people drink alcohol for potential health benefits, it said in a statement.
Drinking in moderation may pose health risks for some people, and some individuals should not drink at all.
The International Alliance for Responsible Drinking, which represents large brewers and distillers including Anheuser-Busch InBev and Diageo , said it disagreed with the studys conclusions.
We ... stand by the information that we publish on drinking and health, it said.
RISING RISK

The World Health Organization says drinking alcohol is a well-established risk factor for a range of cancers, including tumors of the mouth, liver, breast and colon and bowel.
And the risk of cancer rises with levels of alcohol consumed.
FILE PHOTO: A waiter serves beer in the traditional Schweizerhaus beer garden in Vienna, Austria June 21, 2017.
REUTERS/Leonhard Foeger/File Photo

The research team behind Thursdays study analyzed the information relating to cancer on the websites and documents of nearly 30 alcohol industry organizations around the world between September 2016 and December 2016.
The weight of scientific evidence is clear - drinking alcohol increases the risk of some of the most common forms of cancer, said Mark Petticrew, a professor of public Health at the LSHTM who co-led the study.
It has been argued that greater public awareness, particularly of the risk of breast cancer, poses a significant threat to the alcohol industry.
Our analysis suggests that the major global alcohol producers may attempt to mitigate this by disseminating misleading information.
Petticrews team identified three main industry strategies: Denying any link with cancer, or selective omission of the relationship; distortion by mentioning some risk of cancer, but misrepresenting or obfuscating its size; and distraction by seeking to draw focus away from the risks of alcohol and towards other cancer risks.
One of the most significant findings was that industry materials omitted or misrepresented evidence on breast and bowel cancer, both of which are linked to drinking.
When breast cancer was mentioned, 21 of the organizations studied gave no, or misleading, information about it, the study said.
Ian Gilmore, chair of the Alcohol Health Alliance UK, said the study clearly shows the alcohol industry misleading the public.
With only 1 in 10 people aware of the link between alcohol and cancer, people have both a need and a right to clear information about the health risks of drinking alcohol.
Petticrew said the studys findings, published in the journal Drug and Alcohol Review on Thursday, were important partly because the alcohol industry is often involved in spreading health information to people around the world.
CAPE CANAVERAL, Fla (Reuters) - NASA astronaut Peggy Whitson and two crewmates made a parachute touchdown in Kazakhstan on Saturday, capping a career-total 665 days in orbit, a U.S. record.
Whitson, 57, ended an extended stay of more than nine months aboard the International Space Station, a $100 billion research laboratory that flies about 250 miles (400 km) above Earth.
I feel great, the biochemist said during an inflight interview on Monday.
I love working up here.
Its one of the most gratifying jobs Ive ever had.
During her third mission aboard the station, Whitson spent much of her time on experiments, including studies of cancerous lung tissue and bone cells.
She also completed four spacewalks, adding to her six previous outings, to set a record for the most time spent spacewalking by a woman.
Two crewmates who launched with Whitson in November returned to Earth three months ago.
She stayed aboard to fill a vacancy after Russia scaled down its station staff from three to two cosmonauts.
Whitson returned to Earth with Jack Fischer, also with the National Aeronautics and Space Administration, and Russian cosmonaut Fyodor Yurchikhin, who had been aboard the station since June.
FILE PHOTO - The International Space Station (ISS) crew member, astronaut Peggy Whitson of the U.S. speaks prior to the launch of Soyuz MS-3 space ship at Baikonur cosmodrome, Kazakhstan, November 17, 2016.
REUTERS/Dmitri Lovetsky/Pool/File Photo

The crews Russian Soyuz capsule touched down in Kazakhstan at 9:21 p.m. EDT Saturday.
Im looking forward to seeing friends and family, Whitson said during another interview.
Slideshow (13 Images)

But the thing Ive been thinking about the most, kind of been fantasizing about a little bit, are foods that I want to make, vegetables that I want to saut, things that Ive missed up here.
In April, Whitson broke the 534-day U.S. record for cumulative time in space.
Only seven Russian men have logged more time, including Gennady Padalka, the world record-holder with 878 days in orbit.
Whitson, who grew up on a farm in Iowa, said she was inspired by the U.S. Apollo program that landed men on the moon, but it was not until later, when the first women become astronauts, that she set her sights on joining them.
Whitson, who became an astronaut in 1996, was the first woman to command the space station and also the first woman and first non-pilot to serve as chief of the NASA Astronaut Corps.
I am working on paying forward some of the advice and mentoring that I received on my journey, in hopes that one day those young people will do the same and look back on a life in which they leapt at the opportunities and broke their own records, she said.
FRANKFURT (Reuters) - European satellite launching firm Arianespace said it had called off the launch of two communications satellites seconds before lift-off on Tuesday, citing unspecified problems.
An Ariane 5 heavy-launcher rocket had been due to take off from Europes spaceport in French Guiana, carrying satellite Intelsat 37e for Intelsat and BSAT-4a for manufacturer Space Systems Loral.
Arianespace, majority-owned by a joint venture of Airbus and Safran, offers launches with Ariane 5, Soyuz and Vega rockets and says it has sent into orbit more than half of all telecommunications satellites now in service.
The company said engineers were trying to find out what caused the anomaly in the launch, which was to be the fifth Ariane 5 mission from the Guiana Space Center this year.
During the final seconds of the launch countdown for Arianespace Flight VA239, the checkout process detected an anomaly on the launcher as the Vulcain cryogenic main stage engine was being ignited, Arianespace said in a statement.
It said it would set a new launch date as soon as possible.
India's Polar Satellite Launch Vehicle (PSLV) C-39, carrying IRNSS-1H navigation satellite, lifts off from the Satish Dhawan Space Centre in Sriharikota, India, August 31, 2017.
REUTERS/P.
Ravikumar

NEW DELHI (Reuters) - Indias eighth navigation satellite imploded shortly after lift off on Thursday, state-run Indian Space Research Organisation (ISRO) said.
The IRNSS-1H satellite had been expected to join seven others in the Indian Regional Navigation Satellite System (IRNSS) to take the country a step further to developing its own global positioning system.
Satellite got separated internally but it imploded within the heat shield, in the fourth stage itself, ISRO Chairman A.S. Kiran Kumar told reporters in a televised news conference.
The heat shield is meant to protect the satellite from the heat generated by the friction against atmosphere during take-off.
Once a satellite is placed into orbit, it is expected to separate and fall off.
The IRNSS-1H satellite had been released from the Sriharikota Space Centre in southern India.
IRNSS helps navigate the countrys aerial and marine routes, as well as aid disaster management and vehicle tracking up to 1,500 kilometers (932 miles) around the mainland.
However, India lags behind the United States GPS, Russias GLONASS, Europes Galileo and Chinas Beidou systems that have dozens of satellites to provide information across the globe.
Field Museum scientists Pete Makovicky (L), Associate Curator of Dinosaurs, and Bill Simpson, Head of Geological Collections, use a cast of one of the T. rex SUEs gastralia -- a set of bones that look like an additional set of ribs -- to show where they will be positioned on her skeleton in Chicago, Illinois, U.S. in this undated handout photo obtained by Reuters August 29, 2017.
Zachary James Johnston/The Field Museum/Handout via REUTERS

(Reuters) - The worlds biggest T. rex is getting ready for a cutting-edge makeover.
The Field Museum in Chicago said on Wednesday it will take down and remount the 40-1/2-foot-long (12.3-meter) Tyrannosaurus nicknamed Sue, perhaps the worlds most famous dinosaur fossil, in a way that embodies the latest understanding of this ferocious Cretaceous Period predator.
The big T. rex will move to a new exhibition space in the museum, while a cast of the skeleton of the largest-known dinosaur, Patagotitan mayorum, will take the spot Sue now occupies in the museums Stanley Field Hall.
Patagotitan, a long-necked, four-legged plant-eater that was 122 feet (37.2 meters) long and weighed 70 tons, lived in Argentina 100 million years ago, more than 30 million years before T. rex stalked western North America.
The biggest land animal on record, it was a member of a dinosaur group called titanosaurs.
The museum next spring will unveil the fiberglass Patagotitan skeleton, which is being cast from fossils of seven Patagotitan individuals, and for two years will display some of the genuine fossils, including an 8-foot (2.4 meter) thighbone.
Named for the woman who discovered the fossils in South Dakota in 1990, Sue is the largest, most complete and best-preserved Tyrannosaurus rex ever unearthed.
The museum bought the fossils at auction for $8.4 million.
Sue will be taken down in February and put up again with noteworthy changes in anatomy and stance in its new exhibition hall in spring 2019, museum scientists said.
We are making several adjustments to the skeleton to reflect new and improved knowledge, said paleontologist Pete Makovicky, the museums associate curator of dinosaurs.
The most striking change, Makovicky said, will be the addition of gastralia, bones resembling an additional set of ribs spanning the belly that may have provided structural support to help the dinosaur breathe.
Adding these bones will illustrate just how massive Sue was and that it boasted a bulging belly, he added.
The size of two dinosaurs, the Argentine titanosaur Patagotitan mayorum and the North American predator Tyrannosaurus rex are compared with a human figure for scale, in this handout illustration obtained by Reuters August 29, 2017.
The Field Museum/Handout via REUTERS

The scientists concluded that the bone mounted as Sues wishbone was misidentified in 2000 and they will replace it with the dinosaurs actual wishbone, or furcula, the fused collar bones typical of meat-eating dinosaurs and their evolutionary descendants the birds.
They also will adjust the ribs to produce a slimmer, less barrel-shaped chest, and arrange the right leg so Sue is not crouching as much.
Often when you do something as expensive as mounting a vertebrate fossil skeleton for display you only get one shot at it.
Im happy were going to fix and update this incredible fossil, said paleontologist Bill Simpson, who heads the museums geological collections.
LIFESPAN AND BITE FORCE

Makovicky noted the accumulation of knowledge about T. rex and its cousins since 2000.
We now know more about tyrannosaur lifespans -- around 30 years; how they grew -- very fast as teenagers; and using computer models of Sue we revised their body mass upward to 9 or more tons, from 5 to 7 tons, Makovicky said.
Ongoing research is examining the molecular composition of cartilage preserved in T. rex bones, and recent studies have shown it possessed the most powerful bite of any land animal ever, Makovicky added.
When the Patagotitan skeleton is mounted, visitors will be able to walk underneath it and touch it.
Its head will reach the museums second-floor balcony nearly 30 feet (9 meters) up.
Another Patagotitan skeleton is displayed at the American Museum of Natural History in New York.
The museum said a $16.5 million gift from the Kenneth C. Griffin Charitable Fund, established by the founder and chief executive of hedge fund firm Citadel LLC, enabled it to carry out Sues makeover and add the Patagotitan.
The changes coincide with the museums 125th anniversary in 2018.
Image copyright Copernicus Sentinel data (2017) Image caption Widening gap: The picture contains data gathered on 13 and 16 September

The giant berg A-68 looks finally to be on the move.
Recent weeks have seen it shuffle back and forth next to the Antarctic ice shelf from which it broke away.
But the latest satellite imagery now indicates the near-6,000 sq km block is swinging out into the Weddell Sea.
A wide stretch of clear water has opened up between the berg's southern end and the remaining Larsen shelf structure, suggesting A-68 is set to swing around and head north.
This is the direction the Weddell currents should take the iceberg.
Polar experts expect the trillion-tonne block to essentially bump along the shelf edge until it reaches the great eastward movement of ocean water known as the Antarctic Circumpolar Current.
This would then export what is one of the largest bergs ever recorded out into the South Atlantic.
How far A-68 actually gets along this predicted path is anyone's guess, however.
The berg already shows evidence of fragmentation at its edges.
These bits - they carry the designation A-68b, A-68c, etc - all still float close to their parent.
But in time they will get separated, and it is entirely possible that big segments with deep keels could get anchored in shallow waters and become semi-permanent "ice islands".
A-68 calved during mid-winter and it required radar satellites - such as Europe's Sentinel-1 spacecraft - with their unique ability to pierce cloud and darkness to keep track of developments.
With the return now to longer days in the Antarctic, opportunities are increasingly opening up for high-resolution optical satellites to take a close look at the state of the berg.
And new imagery from the Spanish Deimos-2 spacecraft shows how the initial sharp edges of the block's northern-western corner have been lost.
Image copyright Deimos Imaging, an UrtheCast Company

Scientists are not just looking at the berg; they also continue to monitor the Larsen Ice Shelf.
They are checking to see if its behaviour has changed since the calving.
The shelf is the floating protrusion of glaciers coming off the Antarctic landmass, and the ejection of such a large section of its structure could potentially trigger further fracturing or a change in the speed of ice flow.
So far, however, there is little evidence of either.
When A-68 moves clear of its birth position it will reveal seafloor that probably has not been free of ice cover for 120,000 years - during the peak of the last warm phase in Earth's history known as the Eemian.
The area has already gained protected status from the Commission for the Conservation of Antarctic Marine Living Resources (CCAMLR).
This gives scientists priority access and keeps fisheries activity at bay for a minimum of two years.
Previous research in locations uncovered by departing bergs has found new species.
Expeditions to visit A-68 this coming Antarctic summer season are in the planning stage.
Jonathan.Amos-INTERNET@bbc.co.uk and follow me on Twitter: @BBCAmos
Image copyright Joan Costa Image caption The skeleton of a boy that shattered our view of Neanderthal brain development

A new study shows that Neanderthal brains developed more slowly than ours.
An analysis of a Neanderthal child's skeleton suggests that its brain was still developing at a time when the brains of modern human children are fully formed.
This is further evidence that this now extinct human was not more brutish and primitive than our species.
The research has been published in the journal Science.
Until now it had been thought that we were the only species whose brains developed relatively slowly.
Unlike other apes and more primitive humans, Homo sapiens has an extended period of childhood lasting several years.
This is because it takes time and energy to develop our large brain.
Previous studies of Neanderthal remains indicated that they developed more quickly than modern humans - suggesting that their brains might be less sophisticated.
But a team led by Prof Antonio Rosas of the Museum of Natural Sciences in Madrid found that if anything, Neanderthal brains may have developed more slowly than ours.
"It was a surprise," he told BBC News.
"When we started the study we were expecting something similar to the previous studies."
Image copyright Paleoanthropology Group MNCN-CSIC] Image caption The remains were discovered inside the El Sidrn cave in Asturias, Spain.
Prof Rosas and his team believe they are right and the previous studies are wrong because for the first time they were able to study a relatively complete skeleton of a child at a crucial stage in their development.
It was of a boy, who was nearly seven-and-a-half years old when he died.
His bones were found in the 49,000-year-old site of El Sidrn, in Spain.
The boy's remains are exceptionally well preserved and include a mix of baby and adult teeth, which enabled the team to accurately determine his age.
This brain is estimated to have been 87.5% of the size of an average adult Neanderthal brain upon death.
A modern human child at the same general age would have, on average, a brain that was 95% the size of an adult's.
The researchers also found that some of the small bones forming the boy's backbone were not fused.
In modern humans, these bones tend to fuse by the time children reach the age of six.
Image copyright Joan Costa Image caption The researchers were surprised to discover that Neanderthal brains develop more slowly

According to Prof Rosas, the finding reinforces the idea that Neanderthals were not that different from us.
The brutish picture of Neanderthals is an old one.
In the last few years there has been growing evidence to suggest that they were a distinct human species with some small differences.
Now we can say that their growth pattern is similar to ours, too.
The finding raises the intriguing possibility that the Neanderthals' slightly slower brain development meant that their brains might have been more advanced than ours.
But Prof Rosas prefers a more prosaic interpretation.
"Neanderthals have a larger brain and larger body and so it is logical to think that the brain of the Neanderthal continues to grow for a little longer to allow their brains and bodies to get to their adult size," he explained.
Before this finding, scientists believed that modern humans were the slowest growing species.
Now we know that Neanderthals took slightly longer, suggesting that both species inherited this growth pattern from a now extinct common ancestor.
Follow Pallab on Twitter
Image copyright Science Photo Library Image caption Duck-billed dinosaurs may have been tempted away from a vegetarian diet

The idea of plant-eating dinosaurs having a strict vegetarian diet has been called into question.
New evidence suggests that some dinosaurs snacked on shellfish and insects as well as plant food.
A study of fossilised droppings indicates duck-billed dinosaurs dined on crabs at certain times of the year.
Fossil remains of dinosaur dinners is rare, so this pescatarian diet may have been overlooked in the past.
The popular perception of what dinosaurs ate was simplistic, said Dr Karen Chin of the University of Colorado, Boulder, US, who led the research.
"Plant-eating dinosaurs had more complex diets than we assumed that they had, and these diets included feeding on some animals, including at least crustaceans, and this was more like diets of modern plant-eating birds," she told BBC News.
The new evidence comes from an area of southern Utah that is regarded as a treasure trove of fossils from the Late Cretaceous Period, when dinosaurs were coming to the end of their reign.
Image copyright Science Photo Library Image caption The hadrosaurs were duck-billed dinosaurs that flourished some 80-65 million years ago

Fossilised dinosaur droppings found on the Kaiparowits Plateau give new insights into what was on the menu for dinosaurs.
Fragments of shell and other remains show they consumed crustaceans such as crabs, which likely sheltered in rotting wood.
The dinosaurs probably actively hunted for crustaceans and insects in a "woody stew" rather than swallowing them accidently, the researchers said.
Animal products may have been a vital source of protein, particularly when they were about to lay their eggs.
Plant guzzlers

"This find really breaks the mould for what we expect a plant-eating dinosaur to do," said Dr Steve Brusatte of the University of Edinburgh, UK, who was not connected with the study.
"We think of them as these multi-tonne plant guzzlers, but some of them also indulged in other types of food.
"And I guess we shouldn't be too shocked because that's true of many plant eaters today, they'll ingest other stuff, sometimes accidentally, sometimes to supplement their diet with other nutrients."
The droppings were left by dinosaurs some 75 million years ago on what would then have been a landscape dotted with rivers and ponds.
Duckbilled dinosaurs were common in the area at the time.
The bones and teeth of the reptiles suggest they spent most of their time on land, though close to freshwater, feeding on tough plants such as ferns and conifers.
The discovery, detailed in the journal Scientific Reports suggests other plant-eating dinosaurs may have in fact been omnivorous.
"We'll just have to find more evidence and we're always on the look out for that," said Dr Chin.
Follow Helen on Twitter.
Image copyright JJM/Geograph Image caption The Shiant Islands could be declared free of non-native black rats next year

The calls of a small seabird have been recorded for the first time on a group of islands in The Minch.
Conservationists hope the sound of storm petrels' "churring" is an indication that an effort to eradicate rats on the Shiant Islands is working.
The black rats are not native to the islands off Lewis and are thought to be the descendants of rats that came ashore from shipwrecks in the 1900s.
Storm petrels are not found where there are rats, which eat their eggs.
Media playback is unsupported on your device Media caption Storm petrels were recorded for the first time on the islands in the summer

On the Shiants, colonies of puffins, razorbills and guillemots have been in decline, while Manx shearwaters and until now storm petrels have not been found at all.
RSPB Scotland, Scottish Natural Heritage and the Nicolson family, which owns the islands, secured funding to start the rat eradication work in 2015.
They hope it will be possible to declare the islands rat-free next March.
Storm petrels, which are slightly bigger than a sparrow, had been seen flying past the Shiants.
To encourage them to breed on the islands, conservationists played the sound of their calls from a loud speaker.
This summer, real storm petrels' churring was heard and the birds seen at a burrow by conservationists using night vision equipment.
Image copyright Ed Marshall/RSPB Images Image caption Conservationists say storm petrels are vulnerable to rats

Dr Charlie Main, senior project manager for the Shiant Isles Recovery Project, said: "The churring of a storm petrel is very distinctive and we're delighted that it's been recorded on the Shiants this summer.
"While we are still some way off the islands being officially declared rat-free, these calls indicate that all the biosecurity work we're doing to keep these islands predator-free and make them ideal breeding sites for seabirds is paying off."
She added: "The long-term aim is to allow a breeding colony of storm petrels to establish at the Shiants."
Dr Andrew Douse, policy and advice manager in ornithology at Scottish Natural Heritage, said the first recording of the birds was "very welcome".
He said: "Storm petrels only occur on islands without rats, which means that they are very vulnerable to the effects that arise from invasive species such as these.
"The Shiants are an ideal breeding location for storm petrels and hopefully they will go on to become an important stronghold for this species."
Image copyright SPL

Scientists have engineered an antibody that attacks 99% of HIV strains and can prevent infection in primates.
It is built to attack three critical parts of the virus - making it harder for HIV to resist its effects.
The work is a collaboration between the US National Institutes of Health and the pharmaceutical company Sanofi.
The International Aids Society said it was an "exciting breakthrough".
Human trials will start in 2018 to see if it can prevent or treat infection.
Our bodies struggle to fight HIV because of the virus' incredible ability to mutate and change its appearance.
These varieties of HIV - or strains - in a single patient are comparable to those of influenza during a worldwide flu season.
So the immune system finds itself in a fight against an insurmountable number of strains of HIV.
Super-antibodies

But after years of infection, a small number of patients develop powerful weapons called "broadly neutralising antibodies" that attack something fundamental to HIV and can kill large swathes of HIV strains.
Researchers have been trying to use broadly neutralising antibodies as a way to treat HIV, or prevent infection in the first place.
The study, published in the journal Science, combines three such antibodies into an even more powerful "tri-specific antibody".
Dr Gary Nabel, the chief scientific officer at Sanofi and one of the report authors, told the BBC News website: "They are more potent and have greater breadth than any single naturally occurring antibody that's been discovered."
The best naturally occurring antibodies will target 90% of HIV strains.
"We're getting 99% coverage, and getting coverage at very low concentrations of the antibody," said Dr Nabel.
Experiments on 24 monkeys showed none of those given the tri-specific antibody developed an infection when they were later injected with the virus.
Dr Nabel said: "It was quite an impressive degree of protection."
The work included scientists at Harvard Medical School, The Scripps Research Institute, and the Massachusetts Institute of Technology.
'Exciting'

Clinical trials to test the antibody in people will start next year.
Prof Linda-Gail Bekker, the president of the International Aids Society, told the BBC: "This paper reports an exciting breakthrough.
"These super-engineered antibodies seem to go beyond the natural and could have more applications than we have imagined to date.
"It's early days yet, and as a scientist I look forward to seeing the first trials get off the ground in 2018.
"As a doctor in Africa, I feel the urgency to confirm these findings in humans as soon as possible."
Dr Anthony Fauci, the director of the US National Institute of Allergy and Infectious Diseases, said it was an intriguing approach.
He added: "Combinations of antibodies that each bind to a distinct site on HIV may best overcome the defences of the virus in the effort to achieve effective antibody-based treatment and prevention."
Follow James on Twitter.
Image copyright Jessica Thompson Image caption Burials at Mount Hora in Malawi yielded DNA used in the study

DNA from ancient remains has been used to reconstruct thousands of years of population history in Africa.
Researchers sequenced the genomes of 16 individuals who lived between 8,000 and 1,000 years ago.
The data shows how the invention and spread of farming had a major impact on the genes of people in Africa - just as it did in Europe and Asia.
The findings are published in the journal Cell.
The results suggest that populations related to the indigenous people of southern Africa had a wider distribution in the past.
This southern African-like genetic background is found in hunter-gatherers from Malawi and Tanzania in the east of the continent.
These hunters lived between 8,100 and 1,400 years ago.
But the later spread of farmers from western Africa had a major impact on the genetic make-up of people in surrounding regions.
Further DNA analysis revealed the hunter-gatherers in eastern Africa had mixed extensively with the incoming farmers.
The researchers estimate that the mixing occurred between 8,000 and 4,000 years ago.
The study also found possible evidence of migration into Africa from the Middle East.
About 38% of the ancestry of a 3,100-year-old livestock herder from Tanzania was related to ancient farmers from the Levant region.
"These results document a prehistoric population landscape that we didn't know about," said co-author Pontus Skoglund, from Harvard Medical School, US.
"They document how farmer and herder migrations swept through eastern and southern Africa."
The researchers also found tentative evidence of adaptive evolution - changes driven by environmental pressure - for genes involved in taste in the ancient individuals.
These taste receptors are known to be important for detecting and learning to avoid poisonous plants.
Image copyright Fredex8

The UK and US have reached a deal to develop a special relationship for science.
An agreement between the two countries aims to make it easier for researchers to travel, collaborate and share facilities.
US science bodies are said to be "eager" to take advantage of research opportunities lost because of Brexit.
The deal is part of government efforts to develop research collaborations outside the EU.
BBC News revealed earlier this year when the deal was being negotiated that the aim was to develop a legal framework to allow a freer flow of people, research grants and tariff-free exchange of equipment between the two countries.
Possible strategic areas of collaboration include:

synthetic biology

information technology

GM research

Image copyright SANGER CENTRE Image caption America and Britain were key partners on the project to decode the human genome

The agreement, signed by the Science Minister Jo Johnson and his US counterparts, states that national laws will "seek to facilitate" freer movement of people and scientific equipment.
Speaking in Washington, Mr Johnson said that the deal would help to ensure that the UK would maintain its global lead in many areas of research.
"Our continued collaboration with the US on science and innovation is beneficial to both of our nations, and through this agreement we are sharing expertise to enhance our understanding of many important topics that have the potential to be world changing," the minister added.
The impetus for the deal came following the UK referendum result to leave the European Union.
British universities, in collaboration with small businesses, receive 850m in research grants each year from membership of the EU's research programmes.
EU membership also makes it easy to form collaborations.
There are fears that much of the funding and collaborative work with EU scientists will be in jeopardy once the UK leaves the EU, despite recent assurances from the Brexit Secretary, David Davis, that his aim is to foster even closer scientific relationships with the EU.
Prof Venki Ramakrishnan, president of the Royal Society, welcomed the deal with the US but remains concerned that Mr Davis' aspiration to have closer collaboration with the EU lacks any detail on how to achieve his aim.
"This agreement sends a welcome message that UK science remains outward looking.
International research collaboration allows the rapid exchange of new ideas and expertise and it also allows us to address problems that no one country can on its own.
It is an essential part of modern science," he said.
Image copyright NSF/LIGO Image caption A wider partnership could give UK researchers even more access to US facilities

British researchers are being encouraged to foster links with other nations.
While most if not all research leaders are still dismayed by the referendum result - some are beginning to see advantages for greater collaboration with the US.
For example, there is scope for greater freedom in research in synthetic biology and information technology because biotechnology and privacy regulation is less restrictive outside the EU.
For their part, US science bodies see Brexit as an opportunity for them.
US research leaders are anxious that American research groups fill any shortfall left by the UK's departure from the EU, rather than their rivals in India and China.
Mr Johnson announced that the government had pledged 65m to participate in a US-based and led international project to learn more about sub-atomic particles called neutrinos.
He said he hoped it would be the first of many more UK research collaborations with the US.
Media playback is unsupported on your device Media caption Pallab Ghosh looks at how the neutrino beam would be fired underground

The UK-led Dune project involves 150 scientists from 14 British universities and two laboratories run by the UK's Science and Technologies Facilities Council participating in a US-based effort involving 1,000 scientists from 31 countries.
The UK was likely to participate in Dune before the referendum result, but the project received greater support from ministers subsequently because it fitted well with the government's narrative to reassure the British scientific community that Brexit would free them to take up new opportunities outside the EU.
Echoing that message Sir Mark Walport, currently the government's chief scientific adviser and soon to be chief executive of UK Research and Innovation, the body that will oversee funding of civil government research, said that the agreement sent a "clear signal that UK researchers are outward looking and ready to work with the best talent wherever that may be".
"UK Research and Innovation is looking forward to extending partnerships in science and innovation around the world," he added.
Follow Pallab on Twitter
Image copyright Getty Images Image caption Barn owls rely on their hearing to hunt

Barn owls keep their acute sense of hearing into old age, scientists have discovered.
Previously, starlings have been found to have this ability, suggesting birds are protected from age-related hearing loss.
Understanding more about the "ageless ears" of barn owls could help develop new treatments for human hearing problems.
Birds are able to naturally repair damage to the inner ear.
Georg Klump of the University of Oldenburg, Germany, a researcher on the study, said owls keep their hearing into very old age.
"Birds can repair their ears like (humans) can repair a wound," he said.
"Humans cannot re-grow the sensory cells of the ears but birds can do this."
It appears that humans lost these regenerative abilities at some point in evolution.
Like all mammals, people commonly suffer from hearing loss in old age.
By the age of 65, humans can expect to lose more than 30 dB in sensitivity at high frequencies.
Commenting on the study, Dr Stefan Heller of Stanford University School of Medicine, said work was underway to investigate differences between birds and mammals.
"To truly utilise this knowledge, we need to conduct comparative studies of birds and mammals that aim to find the differences in regenerative capacity, a topic that is actively pursued by a number of laboratories worldwide," he said.
The research, published in the journal, Royal Society Proceedings B, was carried out on seven captive barn owls.
The birds were trained to fly to a perch to receive a food reward in response to sounds.
Even the oldest owl, which reached the ripe old age of 23, showed no signs of age-related hearing loss.
Barn owls typically only live to the age of three or four in the wild.
The birds rely on their hearing to hunt prey at night.
Follow Helen on Twitter.
Image copyright Kathy Niakan Image caption The genetic machinery needed to modify the DNA is injected into the embryo

The blueprint for life - DNA - has been altered in human embryos for the first time in the UK.
The team at the Francis Crick Institute are unravelling the mysteries of the earliest moments of life.
Understanding what happens after a sperm fertilises an egg could lead to ways of improving IVF or explain why some women miscarry.
The embryos were modified shortly after fertilisation and allowed to develop for seven days.
The researchers are exploring one of the most astounding of transformations.
We have all journeyed from a single fertilised egg to a human being - built from myriad different tissues ranging from bone to those needed to read this page.
The first few steps on that journey are as critical as they are poorly understood.
Image copyright Kathy Niakan Image caption The embryo divides and develops from a single fertilised egg (top left) to a blastocyst (bottom right)

Breakthroughs in manipulating DNA have allowed the team at the Crick to turn off a gene - a genetic instruction - suspected to be of vital importance.
The easiest way of working out how something works is to remove it and see what happens.
So the researchers used the gene-editing tool Crispr-Cas9 to scour the billions of letters of genetic code, find their genetic target and break the DNA to effectively disable it.
They were targeting a gene.
You are unlikely to have heard of it, but OCT4 is a superstar in early embryo development.
Its complete role is not understood but it acts like an army general issuing commands to keep development on track.
The researchers used 41 embryos that had been donated by couples who no longer needed them for IVF.
After performing the genetic modification, the team could watch how the embryos developed without OCT4.
Media playback is unsupported on your device Media caption In a first for UK scientists, human embryos have been genetically modified.
Over the course of the first seven days, a healthy, normal embryo goes from one cell to about 200.
It also goes through the first steps of organising itself and handing out specialised jobs to different cells.
The embryo forms a hollow sphere called a blastocyst, with some cells destined to go on to form the placenta, some the yolk sac and others, ultimately, us.
But without OCT4 the blastocyst cannot form.
It tries - but implodes in on itself.
From the embryo's perspective it is a disaster but for scientists it has given unprecedented insight.
Image copyright Kathy Niakan Image caption The cells coloured green in the blastocyst have high levels of OCT4 and are the ones that go on to form the human body

It is the first time human embryos have been edited to answer questions about fundamental biology.
Dr Kathy Niakan, a group leader at the Crick in London, told the BBC: "When it seemed it was working we were quite excited about the possibility that this would open up.
"This is basic research which is providing us with a foundation of knowledge about early human development."
By deepening understanding of the earliest moments in life, it could help explain what goes wrong in infertility.
During IVF, of 100 fertilised eggs, fewer than 50 reach the blastocyst stage, 25 implant into the womb and only 13 develop beyond three months.
This study alone, published in the journal Nature, cannot explain what is going wrong or why some women miscarry.
But by interrogating all the genes suspected of playing a role in our inception, it could lead to new advances.
Image copyright crick institute Image caption Dr Kathy Niakan in the Crick laboratories where the embryos were modified

Dr Niakan told the BBC: "If we knew the key genes for an embryo to develop successfully that would, I would hope in the future, lead to improvements in IVF technology and give us really important insights into why some pregnancies fail."
One option for IVF is to have a better way of testing which embryos are going to be successful.
Or it may be possible to boost embryos during IVF by growing them in a different culture media - a fertiliser for fertilised eggs.
Ethical debate

These experiments have been legal since 2008 in the UK, where it is possible to manipulate such embryos for 14 days as long as they are not implanted.
But while this application of the technology is answering fundamental questions of science, other research groups are trying to remove genes that cause disease.
That is provoking deep ethical debate.
Dr Sarah Chan, a bioethicist at the University of Edinburgh, told the BBC: "I don't think this study should raise any ethical concerns.
"It is very clear that the aim of the research was basic science and that there was never any intention to create genetically modified human beings.
"That said if we could one day use gene editing in human embryos for medical purposes, the potential benefits could be huge, but before we took such a step we would want to make sure that we'd had a really robust and wide-ranging public dialogue on all of the ethical issues involved."
Dr Rob Buckle, the chief science officer at the UK Medical Research Council, said: "Genome editing technologies are having a game-changing effect on our ability to understand the function of critical human genes.
"As genome editing techniques develop it's vital that this work continues within a robust yet adaptable regulatory framework so that its full potential can be realised in a scientific, ethical and legally rigorous way."
Follow James on Twitter.
Image copyright Colin Richards / UHI Image caption Ring of Brodgar is a famous Orkney site

Rivalries in Orkney more than 4,500 years ago led to competition between communities including over how people were buried, according to new research.
Scientists were able to gather much more precise estimates of the timing and duration of events in the period around 3200-2500 BC by examining more than 600 radiocarbon dates.
The study challenges many previously-held ideas about Neolithic Orkney.
The study has been published in the journal Antiquity.
It was led by Prof Alex Bayliss from Historic England, with Prof Colin Richards of the University of the Highlands and Islands in Kirkwall as co-author.
It is part of a wider project called The Times of Their Lives.
Ritual clues

The study concludes that seemingly rapid changes in settlements and monuments indicate that there were rivalries and tension between social groups.
This was played out in how they buried their dead and in their communal gatherings and rituals.
The study covered famous Orkney sites including Skara Brae and Maeshowe.
Key dates indicated by the study

Orkney was probably first colonised in 3600 BC

Settlement peaked in the period 3100-2900 BC

There was a phase of decline 2800-2600 BC, measured by the number of stone houses in use

Settlement resumed in 2600-2300 BC, and it could have been about this time that the Ring of Brodgar itself was erected.
Prof Bayliss said: "This study shows that new statistical analysis of the large numbers of radiocarbon dates that are now available in British archaeology really changes what we can know about our pasts.
"People in the Neolithic made choices, just like us, about all sorts of things - where to live, how to bury their dead, how to farm, where and when to gather together - and those choices are just beginning to come into view through archaeology.
"It's an exciting time to be an archaeological scientist."
Image copyright Colin Richards / UHI

Prof Richards said: "Our study shows how much remains to be discovered in Orkney about the Neolithic period, even though it may appear well known."
Prof Alasdair Whittle of Cardiff University is the lead investigator for The Times of Their Lives.
Prof Whittle said: "Visitors come from all over the world to admire the wonderfully preserved archaeological remains of Orkney, in what may seem a timeless setting.
"Our study underlines that the Neolithic past was often rapidly changing, and that what may appear to us to be enduring monuments were in fact part of a dynamic historical context."
Image copyright AFP Image caption Renewable energy in Nicaragua

The 2015 Paris agreement's ambitious goal of limiting global warming to 1.5C remains within reach, a study suggests.
The study is one of several to address the "carbon budget", which - among other things - determines how much CO2 the planet can emit and still reach a given limit for global warming.
It indicates the 2015 target, perceived by some as tough, could be met with very stringent emissions cuts.
It used computer models that project climate behaviour into the future.
The aim of the Paris deal was "holding the increase in global average temperature to well below 2C above pre-industrial levels and pursuing efforts to limit temperature increase to 1.5C."
But scientists admit they were taken by surprise by the ambition of the 1.5C figure.
The results of the work with computer models have been published in Nature Geoscience.
This type of work necessarily contains uncertainties regarding the way the Earth's climate will respond in future and how quickly societies can move away from fossil fuel use.
But the study authors say: "Pursuing 'efforts to limit the temperature increase to 1.5C' is not chasing a geophysical impossibility".
Co-author Michael Grubb, from University College London, said: "This paper shows that the Paris goals are within reach, but clarifies what the commitment to 'pursue efforts to limit the temperature increase to 1.5C' really implies."
Those commitments would require strengthening the nationally determined contributions (NDCs) - the pledges to cut emissions contained in the Paris agreement.
Previous estimates of the remaining 1.5C carbon budget, based on the Intergovernmental Panel on Climate Change's (IPCC) Fifth Assessment of the climate, were around four times lower.
But unlike those figures, which relied on one line of evidence, the new study uses multiple approaches to examine the same question, arriving at a rather different result.
Co-author Prof Pierre Friedlingstein, from the University of Exeter, said: "This is very good news for the achievability of the Paris targets."
Prof Myles Allen, another author, from the University of Oxford, told BBC News: "In the main body of the IPCC assessment, what it would take to meet a 1.5C goal wasn't assessed in any detail.
To be honest, it wasn't thought to be the policy priority at the time.
"Perhaps it should have been, but that was the view of the academic community then.
But the ambition of Paris caught a lot of people by surprise."
Analysis by David Shukman, BBC Science Editor:

The climate models are exaggerating.
The predictions are too alarmist.
The Tuvaluans and other islanders are safer than we thought.
These are among the conclusions that some might reach from this latest work.
In reality, nothing is quite that straightforward.
The models are simulated approximations of possible futures.
Inevitably they are going to be at least slightly adrift of reality, either in the amount of warming or its timing.
They come with caveats and margins of error.
In many ways, it's remarkable that these computer constructs are even roughly on track.
And models designed to come up with very broad potential outcomes for the end of the century may not be fine-tuned enough to give more detailed forecasts year-by-year.
The authors themselves are anxious that their research is not misunderstood.
The need for urgent action to reduce emissions is unchanged, they say.
It's just that the most ambitious of the Paris Agreement targets is not as unachievable as many once thought, that there is time to act, though the task remains a monumental one.
Myles Allen added: "For a two in three chance of keeping temperatures within 1.5C, we'd have to reduce emissions in a straight line to zero from where we are now over the next 40 years.
"It's possible, but extremely challenging.
So if people are saying: can we now relax?
That's not the right message to take at all."
Different take

Scientists agree urgent action will be needed to tackle the effects of rapid temperature increase over the next century.
But a study earlier this year in the journal Nature Climate Change suggested the allowable carbon budget had probably been overestimated.
It said the "pre-industrial baseline" used to benchmark present day warming was probably older than the IPCC had assumed.
Therefore, the degree of warming since that baseline was probably greater than had been believed.
On Twitter, one of the authors of that report, Prof Michael Mann, said the latest research in Nature Geoscience, "doesn't account for [the] pre-industrial baseline issue we examined".
He added: "There is some debate about [the] precise amount of committed warming if we cease emitting carbon immediately.
We're probably very close to 1.5C."
Meanwhile, another paper in Nature Geoscience, by Gunnar Myhre, from the Center for International Climate and Environmental Research, in Oslo, and colleagues, suggests the greenhouse effect caused by human-induced CO2 emissions is now half-way to doubling compared with pre-industrial conditions.
Although the concentrations themselves have not yet reached the halfway mark, this is being described as an iconic watermark.
Follow Paul on Twitter.
Image copyright Getty Images Image caption The large and the small are most at risk of extinction, on land and in water

The biggest and the smallest of the world's animals are most at risk of dying out, according to a new analysis.
Size matters when it comes to extinction risk, with vertebrates in the so-called "Goldilocks zone" - not too big and not too small - winning out, say scientists.
Action is needed to protect animals at both ends of the scale, they say.
Heavyweights are threatened mainly by hunting, while featherweights are losing out to pollution and logging.
"The largest vertebrates are mostly threatened by direct killing by humans," said a team led by Prof Bill Ripple of Oregon State University in Corvallis, US.
"Whereas the smallest species are more likely to have restricted geographic ranges - an important predictor of extinction risk - and be threatened by habitat degradation."
Image copyright Jurgen Leckie Image caption The great hammerhead shark is under threat from illegal fishing

The research adds to evidence that animals are dying out on such a scale that a sixth extinction is considered under way.
This has prompted efforts to determine the key drivers of extinction risk.
One clue is body size.
Research on birds and mammals has shown that those with larger bodies are more likely to go extinct.
Yet, when the researchers made a data base of thousands of birds, mammals, fish, amphibians and reptiles at risk of extinction, they found disproportionate losses at the large and small ends of the scale.
"Surprisingly, we found that not only the largest of all vertebrate animal species are most threatened, but the very tiniest ones are also highly threatened with extinction," Prof Ripple told BBC News.
Image copyright Dave Young Image caption Warty swamp frog: This frog is believed to be in decline across much of its range

Large charismatic animals, such as elephants, rhinos and lions have long been the target of protection efforts.
However, fish, birds, reptiles and amphibians that are the giants of their kind, such as the whale shark, Somali ostrich and Chinese giant salamander, tend to be overlooked.
Meanwhile, small species at risk - such as frogs and shrews - receive very little attention.
"I think, for the smallest species, first of all we need to bring higher awareness to them, because the larger ones get a lot of attention, but the smaller ones get very little," said Prof Ripple.
In the study, researchers from the US, UK, Switzerland and Australia compared body mass and extinction risk for more than 25,000 vertebrate species.
Of these, around 4,000 are threatened with extinction, as assessed by the Red List of the International Union for the Conservation of Nature.
Vertebrates with the smallest and the largest bodies were found to be most at risk of disappearing, whether they were on land or living in oceans, streams or rivers.
Image copyright R Hutterer Image caption The Canarian shrew is a tiny endangered mammal living only on the Canary Islands

Threats facing the heaviest included:

Regulated and unregulated fishing

Hunting and trapping for food, trade or medicines

The lightest were mainly at risk from:

Pollution of lakes, streams and rivers

Farming

Logging of forests

Development.
Image copyright Factcatdog Image caption The Bavarian pine vole is thought to be critically endangered

The researchers say that while different approaches are needed for the conservation of large versus small species, there is an urgent need to step up efforts for both.
"Ultimately, reducing global consumption of wild meat is a key step necessary to reduce negative impacts of human hunting, fishing, and trapping on the world's vertebrates," they write in the journal, Proceedings of the National Academy of Sciences, which published the study.
"Indeed, based on our findings, human activity seems poised to chop off both the head and tail of the size distribution of life."
Extinction can be a natural process, affecting a handful of species each year.
However, estimates suggest the world is now losing species at hundreds of times the "background" rate.
Co-researcher Thomas Newsome of the University of Sydney in Australia said for large animals lessening the negative impacts of hunting, fishing and trapping was key.
"But it's ultimately slowing the human population growth rate that will be the crucial long-term factor in limiting extinction risks to many species," he said.
Follow Helen on Twitter.
Image copyright Wildlife Justice Commission

Criminal networks smuggling rhino horn out of Africa are turning it into jewellery to evade its detection in airports, an investigation has found.
Wildlife trade monitoring network Traffic revealed an "emerging trend" of making and smuggling beads, bracelets and bangles and rhino horn powder.
The lead investigator told BBC News the trade in rhino horn was now "morphing" into a market for luxury items.
At least 7,100 rhinos are estimated to have been killed in Africa since 2007.
Today, about 25,000 of the animals remain.
Julian Rademeyer from Traffic explained that the production of rhino horn "trinkets" mirrored some of the patterns seen in the trade in ivory.
"It's very worrying," he told BBC News.
"Because if someone's walking through the airport wearing a necklace made of rhino horn, who is going to stop them?
"Police are looking for a piece of horn and whole horns."
Status symbol

The primary destinations for smuggled rhino horn remain the same; the largest markets are in China and Vietnam.
But this investigation also found that smuggling routes constantly changed and adapted, becoming more complex in order to avoid countries and airports where law enforcement resources were being focused.
This shift in how horn is processed before it is moved could make it more difficult to detect.
"This is quite a preliminary assessment," explained Mr Rademeyer, "but it's vital that there's information sharing about these new trends - particularly with law enforcement."
He added that the market for medicinal rhino horn - believed by many to be a cure for a range of illnesses, from rheumatism to cancer - seemed to have "reduced somewhat".
But owning rhino horn - particularly for wealthy men in Vietnam - is also seen as a status symbol.
"It's about power - about showing off your wealth," said Mr Rademeyer.
"It's been called the Ferrari factor - having something says you are wealthy and that you're untouchable [by the law]."
Image copyright TRAFFIC

Susie Offord-Woolley, managing director of the charity Save the Rhino International, said this kind of information was "essential" in order that law enforcement officers could be trained to identify rhino horn jewellery.
"The fact they're carving [the horn] up now means these gangs are getting more concerned about security, and that's a good sign," she added.
At the current rate of poaching, Save the Rhino says that rhinos could be extinct in the wild within the next 10 years.
"That's what we're all trying to avoid," said Ms Offord-Woolley.
And while this is a fight to save a species, she added, "this also affects so many people".
She added: "In last 10 years, 1,000 rangers have been killed in Africa while on patrol protecting rhinos.
"So this is an issue for people's lives, as well."
Follow Victoria on Twitter
Image copyright AFP Image caption Scientists are emphasising that the big cats' new status does not mean they are safe from extinction

Has the chilling threat of extinction worn off at last for the long-endangered snow leopard?
Not exactly - but the iconic big cats' conservation status has been improved from "endangered" to "vulnerable".
The decision was announced by the International Union for Conservation of Nature (IUCN) - the global standard for assessing extinction risk.
Experts have warned that the species still faces serious threats from poaching and habitat destruction.
The elegant yet elusive creatures, which live in the mountains of central Asia, were first listed as endangered by the IUCN in 1972.
The status change followed a three-year assessment process by five international experts.
Dr Tom McCarthy, who runs the Snow Leopard Programme at big cat charity Panthera, was one of them.
"To be considered 'endangered,' there must be fewer than 2,500 mature snow leopards and they must be experiencing a high rate of decline," he explained.
"Both are now considered extremely unlikely, which is the good news, but it does not mean that snow leopards are 'safe' or that now is a time to celebrate.
"The species still faces 'a high risk of extinction in the wild', and is likely still declining - just not at the rate previously thought."
Image copyright AFP/Getty Images Image caption A baby snow leopard pictured at the Tierpark zoo in Berlin

Being classed as "vulnerable" means a species has under 10,000 breeding animals left, with a population decline of at least 10% over three generations.
The Snow Leopard Trust, which aims to protect the big cat through community projects, strongly opposes the status change.
It plans to challenge the decision with the IUCN.
"We believe it could have serious consequences for the species," it wrote in a blog post.
Snow leopard researchers believe the species' decline may have been slowed by conservation projects - including some to protect farm animals from the predators, which are sometimes killed in revenge for livestock losses.
The number of protected areas within the snow leopards' habitat has also increased significantly in recent decades.
Snow leopard stats

The rarely-sighted cats live in the craggy peaks of central Asia - including the Himalayas, and Russia's remote Altai mountains

Their habitat covers more than 1.8 million sq km / 694,980 sq miles, across 12 countries

Scientists say they are threatened by poaching for their fur, infrastructure developments, and climate change

Usually found at elevations of 3,000-4,500m (11,480-14,760ft)

Solitary creatures, they usually hunt at dawn and dusk and are able to kill prey up to three times their own weight

Mostly feed on wild animals, but will also prey on livestock

Their spotted coats change with the seasons - from a thick, white fur to keep them warm and camouflaged in winter, to a fine yellow-grey coat in summer

Retaliatory killings by farmers are not uncommon, but are rarely reported
Image copyright Reuters Image caption The Paris deal commits the signatories to keeping rising global temperatures "well below" 2C above pre-industrial levels

The US has insisted it will leave the Paris climate accord, despite reports that it may be softening its stance.
Following a meeting of environment ministers on Saturday, the EU climate commissioner, Miguel Arias Canete, said Trump officials had indicated the US would either stay in the 2015 accord or review its terms.
But the White House insisted there had been "no change" in the US position.
In June President Donald Trump said the US would withdraw from the deal.
He said it was part of his "solemn duty to protect America" and he would seek a new deal that would not disadvantage US businesses.
But opponents say withdrawing from the accord is an abdication of US leadership on a key global challenge.
The Paris agreement commits the US and 187 other countries to keeping rising global temperatures "well below" 2C above pre-industrial levels and "endeavour to limit" them even more, to 1.5C.
Only Syria and Nicaragua did not sign up to the deal.
What did Trump originally announce in June?
Speaking in the White House Rose Garden, he characterised the Paris agreement as a deal that aimed to hobble, disadvantage and impoverish the US.
He claimed the agreement would cost the US 6.5 million jobs and $3tn (2.2tn) in lost GDP - while rival economies like China and India were treated more favourably.
Media playback is unsupported on your device Media caption Trump: The world won't laugh any more at US

"In order to fulfil my solemn duty to protect America and its citizens, the United States will withdraw from the Paris climate accord... but begin negotiations to re-enter either the Paris accord or a really entirely new transaction on terms that are fair to the United States," he said.
During his visit to France in July, however, Mr Trump hinted that the US could shift its position on the deal - but did not elaborate.
"Something could happen with respect to the Paris accord... We'll see what happens."
What is now being reported?
On Saturday, the Wall Street Journal quoted Mr Arias as saying that Trump administration officials said the US would not pull out of the agreement, and were offering to re-engage in the deal.
The WSJ said the shift in the position came at a meeting of environment ministers from about 30 countries at a gathering in Montreal, Canada.
That meeting was attended by a US observer.
Media playback is unsupported on your device Media caption Matt McGrath explains why we should care about climate change

The US "stated that they will not renegotiate the Paris Accord, but they [will] try to review the terms on which they could be engaged under this agreement," Mr Canete said.
He said that "there would be a meeting on the sidelines of next week's UN General Assembly with American representatives "to assess what is the real US position", according to the AFP news agency.
"It's a message which is quite different to the one we heard from President Trump in the past," Mr Canete added.
At the same time, Chilean Environment Minister Marcelo Mena tweeted (in Spanish): "I was in the meeting, and the [US] negotiator effectively did not close the door on continuing in the agreement, and ruled out looking for a new agreement."
But in a statement later on Saturday, White House spokeswoman Sarah Huckabee Sanders said: "There has been no change in the United States' position on the Paris agreement,

"As the president has made abundantly clear, the United States is withdrawing unless we can re-enter on terms that are more favourable to our country."
How could this change things?
Bloomberg reported that the US is "no longer seeking to withdraw from the pact and then renegotiate it, but rather wants to re-engage with the Paris Agreement from within".
While the White House insists its stance has not changed, deciding not to withdraw from the Paris deal and instead focus on negotiating while remaining a signatory would represent a significant about-turn.
The Los Angeles Times said staying in the Paris deal would be "one of the most controversial" reversals of the Trump presidency.
It would also risk angering Mr Trump's more conservative supporters at a time he is facing criticism for engaging with Democratic leaders, the liberal magazine Mother Jones wrote.
Media playback is unsupported on your device Media caption "Long live Cassini" - the project team says farewell

The American-led Cassini space mission to Saturn has just come to a spectacular end.
Controllers had commanded the probe to destroy itself by plunging into the planet's atmosphere.
It survived for just over a minute before being broken apart.
Cassini had run out of fuel and Nasa had determined that the probe should not be allowed simply to wander uncontrolled among Saturn and its moons.
The loss of signal from the spacecraft occurred pretty close to the prediction.
Here at mission control, at the Jet Propulsion Laboratory (JPL) in Pasadena, California, the drop-off was timed at 04:55 PDT (11:55 GMT; 12:55 BST).
How the last hours unfolded

Nasa's Earl Maize addressed fellow controllers: "Congratulations to you all.
This has been an incredible mission, an incredible spacecraft and you're all an incredible team.
I'm going to call this the end of mission.
Project manager off the net."
The statement brought restrained applause and some comforting embraces.
The loss of signal indicated that the probe was tumbling wildly in the planet's gases.
Travelling downwards at over 120,000km/h, it could have survived the violence for no more than about 45 seconds before being torn to pieces.
Incineration in the heat and pressure of the plunge was inevitable - but Cassini still managed to despatch home some novel data on the chemical composition of Saturn's atmosphere.
Cassini: A mission of 'astonishing discovery'

Sorry, your device is unsupported.
Tap To Progress

Swipe to go back Click Arrows To Progress



Loading .
Tap To Progress Images: Nasa, Kongle Go back to start

And so ends one of the most successful space missions in history.
In its thirteen years at Saturn, Cassini has transformed our understanding of the sixth planet from the Sun.
It has watched monster storms encircle the globe; it witnessed the delicate interplay of ice particles move through the planet's complex ring system; and it revealed extraordinary new insights on the potential habitability of Saturn's moons.
Titan and Enceladus were the standout investigations.
The former is a bizarre place where liquid methane rains from an orange sky and runs into huge lakes.
Cassini put a small European robot called Huygens on Titan's surface in 2005.
It returned a remarkable image of pebbles that had been smoothed and rounded by the action of that flowing methane.
Cassini also spied what are presumed to be volcanoes that spew an icy slush and vast dunes made from a plastic-like sand.
On Enceladus, the observations were no less stunning.
Media playback is unsupported on your device Media caption "Where Cassini took its final plunge": Linda Spilker explains the last images

Image copyright NASA Image caption Controllers' screens: The loss of signal was indicated by the absence of a green spike (right)

This moon was seen to spurt water vapour into space from cracks at its south pole.
The H2O came from an ocean held beneath the icy shell of Enceladus.
When Cassini flew through the water plumes, it showed that conditions in the sub-surface ocean were very probably suitable for life.
Today, scientists are already talking about how they can go back with another, more capable probe to investigate this idea further.
Image copyright NASA/JPL-CALTECH/SSI/JASON MAJOR Image caption Cassini's cameras were switched off for the last few hours leading to the plunge

A great many of those researchers have been gathered this week at the nearby campus of the California Institute of Technology.
They watched a feed from the control room at JPL on giant screens.
Jonathan Lunine, from Cornell University at Ithaca, New York, spoke for many when he said: "I feel sad but I've felt sad the whole week; we knew this was going to happen.
And Cassini performed exactly as she was supposed to and I bet there is some terrific data on the ground now about Saturn's atmosphere."
And Linda Spilker, the Nasa Cassini project scientist, added: "When I look back on the Cassini mission I see a mission that was running a 13-year marathon of scientific discovery.
And this last orbit was just the last lap.
And so we stood in celebration of successfully completing the race.
And I know I stood there with a mixture of tears and applause."
Although the probe has gone its science lives on.
It has acquired a huge amount of data that will keep researchers busy for decades to come.
A lot of it has barely even been assessed.
"Linda Spliker and I were joking earlier that those last few seconds of the Cassini mission - our first 'taste' of the atmosphere of Saturn - might be a number of PhD theses for students to come," observed Michael Watkins, the director of JPL.
"So, even in those last few seconds, it will continue its re-writing of the textbooks."
Image copyright NASA/JPL-CALTECH/SSI Image caption Pictures of Titan were pulled off the probe's memory before the plunge

Media playback is unsupported on your device Media caption Why scientists are so excited about Saturn's icy moon Enceladus

Saturn's moons: The strange and the wonderful

Image copyright NASA/JPL-CALTECH/SSI

Cassini has photographed some of Saturn's 62 moons: the two-tone Iapetus (1) with its walnut-like equatorial ridge; Mimas (2), which has a giant crater that instantly makes everyone think of the "Death Star" from the Star Wars movies; Hyperion (3), which displays clusters of bizarre pock marks akin to a sponge or wasps' nest; Atlas (4), which resembles a flying saucer; the potato-like Prometheus (5); and Pan (6), which has a shape that would not look out of place in a ravioli dish.
Image copyright NASA/JPL-CALTECH/SS Image caption A last look at Enceladus going over the northern limb of Saturn

Image copyright NASA/JPL-CALTECH/SSI Image caption Also in the end group of images was this fabulous shot of the rings

The Cassini-Huygens mission is a joint endeavour of Nasa, and the European and Italian space agencies.
The BBC has plenty of coverage of the ending of the mission on both TV and radio.
Inside Science ran a preview of the climax on Radio 4.
A Horizon documentary will also review the mission and the final hours in a special programme to be broadcast on Monday 18 September at 21:00 BST on BBC Two.
And you can still watch the Sky At Night programme Cassini: The Gamechanger on the iPlayer.
Cassini-Huygens - in numbers Mission to Saturn 7.9bn km travelled since launch 6 named moons discovered 453,000 images taken

2.5 million commands executed

635GB of science data collected

3,948 science papers published

Jonathan.Amos-INTERNET@bbc.co.uk and follow me on Twitter: @BBCAmos
Image copyright RHS/Mike Sleigh Image caption Bright blue berries on the shrub, harlequin glorybower

Berries are appearing on plants and hedgerows early this year because of the unusual weather patterns.
The combination of a warm, dry spring, followed by July and August rains, has led to a plethora of berries, according to horticulturists.
"Berries are a vital part of gardens and wildlife, and things have come together this year to make an abundant and beautiful crop," said Guy Barter, chief horticulturist at the Royal Horticultural Society (RHS).
Plants that are already bearing berries include spindle bushes (Euonymus) and firethorn (Pyracantha), while crab apples are also ripening early.
The fruits are likely to coincide with the appearance of autumn colour on leaves.
Image copyright Anna Brockman/RHS Image caption Skimmia japonica: The glossy green fruit ripen to bright red in autumn

Image caption Firethorn (Pyracantha)

"At some stage, the autumn colours will form and you will get these wonderful colour combinations of reds, blacks, yellows and purples - something to look forward to," he added.
Trevor Dines of the charity, Plantlife, said there have been near-perfect conditions for good fruit in our hedgerows this year.
The dry warm spring encouraged pollinating bees, wasps and flies to be out at peak flowering times in April and May.
Then, the warm, wet summer was perfect for fruit development, with water around to swell the berries.
Meanwhile, autumn colour is also on display in some areas.
"With the return to wetter conditions over summer, it's been a bit of an extended growing season and so it's not surprising that we're now seeing fruit set and autumn colours arriving three to five weeks earlier than normal," said Dr Dines.
"Oak trees in north Wales are already starting to turn colour - you'd normally not see that until late October."
Image copyright RHS Image caption Berries can be seen on many plants at RHS Wisley in Surrey

Berries are a valuable source of food for wildlife, particularly birds.
Thrushes, blackbirds, redwings and fieldfares feast on berries throughout the winter.
The seeds pass out through the bird's gut and are often deposited far away, helping to spread plants far and wide.
Follow Helen on Twitter.
Image copyright Queen's University Belfast Image caption The flexible organic supercapacitor could last three times longer than conventional batteries

Queen's University Belfast scientists have designed a new flexible organic battery that could revolutionise how medical implants are powered.
Devices such as pacemakers are currently fitted with rigid metal based batteries, which can cause discomfort.
The charge in the batteries is set to last three times as long as in their conventional counterparts.
As it is decomposable, the organic battery is also expected to have environmental benefits.
Research leader Dr Geetha Srinivasan from Queen's University's Ionic Liquid Laboratories (QUILL) research centre said the device was also non-flammable and had no leakage issues.
She said the "flexible supercapacitor" could be used to power body sensors such as pacemakers.
Image copyright Queen's University Belfast Image caption Dr Geetha Srinivasan said the new battery would be safer than the batteries currently used in pacemakers

"In medical devices such as pacemakers and defibrillators there are two implants, one which is fitted in the heart and another which holds the metal based, rigid batteries - this is implanted under the skin," said Dr Srinivasan.
"The implant under the skin is wired to the device and can cause patients discomfort as it is rubs against the skin.
"For this reason batteries need to be compatible to the human body and ideally we would like them to be flexible so that they can adapt to body shapes."
Foldable laptops?
Dr Srinivasan said the new battery would be safer than the batteries currently in use.
"It avoids using flammable solvents, therefore you don't have the hazard of explosion," she said.
Image copyright Queen's University Belfast Image caption The flexible supercapacitor could relieve discomfort for those who have medical implants

The technology could also have a non medical application in foldable phones or laptops of the future, the designs of which are currently constrained by rigid batteries.
"Everyone wants to go lightweight and everyone wants to be flexible," Dr Srinivasan said.
"If the battery goes flexible the whole electronics and equipment can go flexible, it's interesting and exciting."
While current batteries contain toxic materials that are complicated to recycle, organic batteries would simply decompose over time.
The new device would be manufactured with organic composites using "natural feedstock" (biomaterials such as cellulose) rather than expensive metals or semiconductors.
Image caption The new batteries would be manufactured with natural organic composites such as cellulose

But there is no danger of the organic batteries decomposing in the human body as they only start to break down at temperatures above 270C.
With the right funding in place, Dr Srinivasan said the devices could easily be commercialised - so that it could be powering phones or similar devices within the next five years.
Image copyright Thinkstock Image caption Culling will be carried out in 21 areas of England this year

Licences have been issued for badger culling in 11 new areas in Devon, Wiltshire, Somerset, Dorset and Cheshire.
Culling is part of the government's 25-year strategy to eradicate bovine TB, but opponents say there is no evidence it is effective.
A badger vaccination programme to stop the spread of TB is restarting.
The Badger Trust condemned the policy as "politically motivated' and an "insult to the nation's intelligence".
The new licences have been granted by Natural England.
It follows a decision to extend culling in areas of Gloucestershire and Somerset.
The government said it will launch a new advisory service for farmers in high risk areas this autumn advising them how to limit the spread of the disease.
Farming Minister George Eustice said: "Bovine TB not only has a devastating impact on our beef and dairy farms, but causes harm and distress to infected cattle.
"Vaccination is just one part of our comprehensive strategy, which also includes tighter cattle controls, improved biosecurity and badger control in areas where bTB is rife, to tackle the reservoir of disease in wildlife."
'Political aggression'

The government's chief vet Nigel Gibbens said: "Proactive badger control is currently the best available option and the licensing of further areas is necessary to realise disease-control benefits across the high risk area of England, rather than at local levels."
Dominic Dyer, chief executive of the Badger Trust, said 32,247 badgers could be killed under these new licences in the next six weeks.
"The government is simply pandering to its core voters in the farming sector," he said.
"No credible scientist has ever suggested that culling badgers will make any significant impact on lowering TB in cattle and there is now clear evidence the policy is failing badly.
"The government is simply imposing its will in an act of political aggression against both science and the will of the people."
The Department for Environment, Food and Rural Affairs (Defra) said that in 2016, operations in Somerset, Gloucestershire, Dorset, Devon, Cornwall, Herefordshire and Wiltshire were all successful in meeting their targets for culling badgers.
In total, culling will be carried out in 21 areas in the south-west, west and north-west of England this year.
Image caption A Portuguese man-of-war, which was one of a group of six, washed up at Gwithian

Large numbers of potentially fatal Portuguese man-of-war have washed up on a Cornish beach, prompting its closure.
RNLI lifeguards erected do not swim red flags at Perranporth beach earlier because of the "unusually large number" of the creatures.
The jellyfish-like organisms, which have long purple tentacles, have also been seen in Wales this month, says the Marine Conservation Society (MCS).
With mild sea temperatures of 16C there were fears of swimmers being stung.
The RNLI said it placed red flags at Perranporth beach between 10:00 and 13:30 BST to signal that the water was out of bounds, while lifeguards took advice on the level of danger to beachgoers.
More on the man-of-war sightings and other stories from Cornwall

Man-of-war were spotted at Newgale, Pembrokeshire, on 8 September and the next day on beaches near the holiday destination of Newquay.
Image copyright Rachel Wyatt Image caption A leatherback turtle was found washed up at Portreath

They have also been seen at Porthmelon Beach on the Isles of Scilly and on the Cornish beaches of Portheras Cove and Summerleaze, Widemouth, Perranporth, Hayle, Holywell Bay and Praa Sands.
Six were also reported at Gwithian.
Dr Peter Richardson from the MCS said a man-of-war's tentacles, which are usually about 10m (30ft) long, "deliver an agonising and potentially lethal sting".
"They are very pretty and look like partially deflated balloons with ribbons but picking one up could be very nasty," he said.
The man-of-war retain their sting when they are wet, even if they look dead, he warned.
He advised anyone who was stung to get the tentacles away from the body as soon as possible.
What is a Portuguese man-of-war?
Image copyright Joanna Clegg Image caption The man-of-war can be tempting to children because it looks like a deflated balloon

The ( Physalia physalis ) is not a jellyfish, but a floating colony of organisms dependent on one another for survival

) is not a jellyfish, but a floating colony of organisms dependent on one another for survival Its gas-filled bladder (sometimes known as the sail), enables it to float on the ocean surface and drift with the current

Its sting - delivered from tentacles which can reach up to 50m below the surface - is extremely painful for humans and can be fatal in rare circumstances

Hundreds of swimmers are stung every year, especially when huge numbers appear in coastal waters

Leatherback turtles have also been washed up, Dr Richardson said.
A leatherback turtle was found at Portreath on 9 September and another one has been reported in Pembrokeshire.
The NHS recommends using tweezers or a clean stick, and gloves if possible, to remove man-of-war tentacles.
If symptoms become more severe, or a sensitive part of the body has been stung, you should seek medical help.
The MCS is asking people to report any sightings which could rise as man-of-war are driven across the Atlantic by recent storms.
Image copyright RNLI Image caption The RNLI said it wasn't uncommon to see man-of-war after windy conditions

What else would you like to know about man-of-war?
Ask us your questions using the form below and we could be in touch.
Image copyright Stanford University Image caption The study created composite faces judged most and least likely to belong to homosexuals

A facial recognition experiment that claims to be able to distinguish between gay and heterosexual people has sparked a row between its creators and two leading LGBT rights groups.
The Stanford University study claims its software recognises facial features relating to sexual orientation that are not perceived by human observers.
The work has been accused of being "dangerous" and "junk science".
But the scientists involved say these are "knee-jerk" reactions.
Details of the peer-reviewed project are due to be published in the Journal of Personality and Social Psychology.
Narrow jaws

For their study, the researchers trained an algorithm using the photos of more than 14,000 white Americans taken from a dating website.
They used between one and five of each person's pictures and took people's sexuality as self-reported on the dating site.
The researchers said the resulting software appeared to be able to distinguish between gay and heterosexual men and women.
In one test, when the algorithm was presented with two photos where one picture was definitely of a gay man and the other heterosexual, it was able to determine which was which 81% of the time.
With women, the figure was 71%.
"Gay faces tended to be gender atypical," the researchers said.
"Gay men had narrower jaws and longer noses, while lesbians had larger jaws."
But their software did not perform as well in other situations, including a test in which it was given photos of 70 gay men and 930 heterosexual men.
When asked to pick 100 men "most likely to be gay" it missed 23 of them.
In its summary of the study, the Economist - which was first to report the research - pointed to several "limitations" including a concentration on white Americans and the use of dating site pictures, which were "likely to be particularly revealing of sexual orientation".
'Reckless findings'

On Friday, two US-based LGBT-focused civil rights groups issued a joint press release attacking the study in harsh terms.
"This research isn't science or news, but it's a description of beauty standards on dating sites that ignores huge segments of the LGBTQ (lesbian, gay, bisexual, transgender and queer/questioning) community, including people of colour, transgender people, older individuals, and other LGBTQ people who don't want to post photos on dating sites," said Jim Halloran, chief digital officer of Glaad, a media-monitoring body.
"These reckless findings could serve as a weapon to harm both heterosexuals who are inaccurately outed, as well as gay and lesbian people who are in situations where coming out is dangerous."
Image caption Campaigners raised concerns about what would happen if surveillance tech tried to make use of the study

The Human Rights Campaign added that it had warned the university of its concerns months ago.
"Stanford should distance itself from such junk science rather than lending its name and credibility to research that is dangerously flawed and leaves the world - and this case, millions of people's lives - worse and less safe than before," said its director of research, Ashland Johnson.
The two researchers involved - Prof Michael Kosinski and Yilun Wang - have since responded in turn, accusing their critics of "premature judgement".
"Our findings could be wrong... however, scientific findings can only be debunked by scientific data and replication, not by well-meaning lawyers and communication officers lacking scientific training," they wrote.
"However, if our results are correct, Glaad and HRC representatives' knee-jerk dismissal of the scientific findings puts at risk the very people for whom their organisations strive to advocate."
'Treat cautiously'

Previous research that linked facial features to personality traits has become unstuck when follow-up studies failed to replicate the findings.
This includes the claim that a face's shape could be linked to aggression.
One independent expert, who spoke to the BBC, said he had added concerns about the claim that the software involved in the latest study picked up on "subtle" features shaped by hormones the subjects had been exposed to in the womb.
"These 'subtle' differences could be a consequence of gay and straight people choosing to portray themselves in systematically different ways, rather than differences in facial appearance itself," said Prof Benedict Jones, who runs the Face Research Lab at the University of Glasgow.
It was also important, he said, for the technical details of the analysis algorithm to be published to see if they stood up to informed criticism.
"New discoveries need to be treated cautiously until the wider scientific community - and public - have had an opportunity to assess and digest their strengths and weaknesses," he said.
Image copyright Stefan Greif Image caption Greater mouse-eared bats (Myotis myotis) were studied in experiments

Modern buildings with large expanses of glass or mirrored surfaces are "potentially dangerous" for bats, research suggests.
Scientists are calling for monitoring of the risks, particularly in areas where bats congregate in large numbers.
Bats have a remarkable ability to fly at high speeds in the dark avoiding natural hazards such as trees.
Yet, smooth, vertical surfaces such as glass windows create a "blind spot" for the flying mammals, a study shows.
"Bats predominately rely on their echolocation system to forage, orientate, and navigate," says a team led by Dr Stefan Greif of the Max Planck Institute for Ornithology near Munich in Germany.
"We found that bats can mistake smooth, vertical surfaces as clear flight paths, repeatedly colliding with them, likely as a result of their acoustic mirror properties."
Collision risk

Bats use echolocation to detect obstacles in flight, find their way into roosts and forage for food.
As they fly, they make calls and listen to the returning echoes to build up a sonic map of their surroundings.
Bats can flit through natural obstacles, such as forests, which return some echo back to them.
However, vertical mirroring surfaces such as window panes appear to trick them into thinking that the way ahead is clear.
Prof Gareth Jones of Bristol University, who is not connected with the study, is an expert on bat echolocation.
"Sound reflects away in front of a bat flying over water, and the flight route ahead is often clear, or interrupted with obvious targets like trees that can be detected by echolocation," he explained.
"Vertical surfaces seem to reflect sound in ways that make the surface difficult to detect, and increase collision risk."
Image copyright Stefan Greif Image caption A colony of greater mouse-eared bats

Smooth vertical surfaces are rare in bats' natural habitat.
However, they treat horizontal, smooth surfaces like water, and attempt to drink from them.
To investigate the issue, researchers analysed the flight behaviour of greater mouse-eared bats (Myotis myotis) in dark flight tunnels.
The researchers placed a metal plate either vertically or horizontally in the corner of the tunnel and watched what happened.
Of 21 individual bats, 19 collided with the vertical plate at least once but never with the horizontal plate.
When the bats collided with the vertical plate, they were producing fewer calls and approaching the plate at a more acute angle and at higher flight speeds compared with the bats that avoided collision.
Similar findings were found with three species of bat in the wild.
No bats were injured in the experiment.
Nature-friendly cities

The findings, published in the journal, Science, may explain why injured or dead bats are sometimes found near buildings.
The researchers are calling for more evidence to be gathered on the scale of the threat to bats.
They say smooth vertical services should be avoided at sites where bats migrate, forage or raise their young.
"Only if we identify and evaluate the real extent of collisions with acoustic mirrors can we avoid or mitigate potential detrimental effects on bat populations," said Dr Greif and co-researchers.
Commenting on the research, Prof Kate Jones of University College London, said: "As we try and encourage more sustainable and nature-friendly cities, it is really important to understand how city design will impact wildlife populations and this study provides some key information for bats."
Bats make up one fifth of all land mammals.
They are among the most endangered of the world's animals, because much of their habitat has been destroyed.
As important pollinators for many plants, and key predators of insects, their loss has serious consequences for the planet.
Follow Helen on Twitter.
Video

The winners have been announced for the Insight Astronomy Photographer of the Year.
The competition received 3,800 entries from amateurs and professional photographers from all over the world.
One of the judges is Dr Marek Kukula.
He tells Dan Damon about the dreamers and scientists behind the images.
(IMAGE & CREDIT: The Rho Ophiuchi Clouds  Artem Mironov (Russia) - STARS & NEBULAE WINNER & OVERALL WINNER.)
How long do elephants spend sleeping?
Researchers find that African elephants in the wild sleep an average of two hours a day and regularly go nearly two days without sleep.
Video

Flies are notoriously hard to swat because they see around four times faster than humans.
They effectively watch you coming in slow-motion.
In fact, scientists discovered that so-called 'killer flies' have the fastest vision of any animal.
Find out more with CrowdScience: Spider silk and super fly senses.
Video

The space race of the Cold War pitted the world's two superpowers against one another to explore what lies beyond Earth.
Now anyone with enough money and enterprise can get there.
But this new race isn't between countries - it's between companies.
Find out more at The Disruptors #thedisruptors @BBCMoney

Producer: Philippa Goodrich; Reporter: Tim Bowler
Video

The small satellite industry is the fastest growing part of the space sector "and they all require launch" says New Zealand's Rocket Lab boss Peter Beck.
His firm aims to disrupt the established space sector by launching its commercial satellite-carrying rockets once a week.
Find out more at The Disruptors #thedisruptors @BBCMoney

Producer: Adrienne Murray; Cameraman: Mauricio Olmedo-Perez
What is 'dragon skin' ice?
Strange-looking ice has been spotted by scientists working in the Antarctic.
It's the first time in ten years this rare type of ice has been seen.
Image caption Could a genetic mutation explain some dogs' insatiable appetite?
When it comes to man's best friend, science may finally have solved the mystery of their gluttony - some Labradors, it seems, are genetically predisposed to being hungry.
That's according to scientists who were discussing their ongoing mission to improve our favourite pets' health at the British Science Association Festival in Brighton.
Several research teams in the UK are on a mission to improve canine health.
Researchers at the University of Cambridge have studied the appetite of Britain's favourite dog breed, and suggest Labradors are genetically at risk of becoming overweight.
Roughly a quarter of British households own a pet dog, and Labrador retrievers remain our most popular canine companion.
However, this stereotypically "greedy" breed often suffers size-related health problems.
Blame the owners?
"Obesity is a serious issue for our dog population," says Dr Eleanor Raffan from the Wellcome Trust-MRC Institute of Metabolic Science.
"It has the potential to have a massive impact on pet welfare."
In research supported by the Dogs Trust, Dr Raffan and her colleagues have analysed DNA from the saliva of Labradors across the UK.
They found that particularly greedy individuals possess a gene mutation responsible for increasing their appetite.
"We found around a quarter of pet Labradors have at least one copy of this mutation in the gene," Dr Raffan explains.
Their increased appetite manifests itself as a "food obsession", familiar to dog-owners as begging or scavenging for food.
In the past, the onus has been on owners to restrict the diet of their pets to prevent excessive weight gain.
But Dr Raffan's research suggests the propensity for large appetites, and hence potential obesity, is hardwired into some individuals.
"We hope to shift the paradigm away from owner-blaming" says Dr Raffan.
"It's a bit more nuanced than just owners needing to be careful."
Freedom from hunger

Dr Raffan cautions against any attempt to breed this "greedy mutation" out of Labrador lines.
While it might predispose the dogs to obesity, a strong focus on food may also explain why Labradors are so easy to train and are such loyal human companions.
"If we try to get rid of the mutation, we might find we change the personality of the breed, and that would be a real shame," she explains.
Yet their results raise an ethical conundrum.
Owners and veterinary surgeons are responsible for providing five core so-called freedoms to animals in their care, including freedom from pain and disease, and freedom from hunger.
Obesity is a disease, and negatively impacts upon canine quality of life.
"But equally, being hungry is a welfare issue," says Dr Raffan.
"And these dogs are genetically hungry."
Dr Raffan hopes future research will improve the satiety of their diets, allowing a feeling of "fullness" without the potential for excessive weight gain.
Bearing the weight

Being overweight undoubtedly reduces a dog's quality of life, and can also affect their ability to cope with arthritis and other underlying joint disorders.
At the University of Liverpool, scientists are using state-of-the-art imaging technology to study diseases affecting the knee joints of Labradors.
Damage to the canine cruciate ligament, similar to the injuries commonly suffered by professional human athletes, is the most common orthopaedic problem seen in veterinary practices.
Injury to the knee ligaments is also more common in heavier dog breeds

"We're trying to understand how the shape of the Labrador body and the way they walk might contribute to knee problems," says Prof Eithne Comerford, a specialist in musculoskeletal biology.
Using high-speed x-ray cameras, the researchers film their canine patients walking through the lab, and watch their knee bones slide and twist in real-time.
The team hopes to understand how walking contributes to the risk of ligament injury and rupture in Labradors, with the ultimate goal of reducing lameness and suffering within the breed.
"This data will also help veterinary surgeons and engineers design better treatments for ligament damage in Labradors, like customised knee implants," explains biomechanist Dr Karl Bates from the University of Liverpool.
Both research groups rely heavily on the good will of Labrador owners, both for collecting samples and entering their pets into experimental trials.
In addition to tackling diagnosed health issues, researchers hope to change the public's perception of what "desirable" traits should characterise our favourite breeds.
"There is a real danger when we breed dogs to be cuddlier and cuter," warns Dr Raffan.
"I think people have seen so many overweight Labradors, they start to assume it's normal".
Dr Charlotte Brassey is a BBSRC Future Leader Fellow at Manchester Metropolitan University, and British Science Association Media Fellow 2017.
Twitter: @cbrassey
Image copyright Zhong-Jian Liu and Li-Jun Chen Image caption The orchid was found at Wutongshan Mountain in Shenzhen, China

The orchid is known for its beauty and once changed hands for vast sums.
Now, scientists are gaining an insight into how the plant prized for its beauty colonised almost every habitat on Earth.
A team in China has unpicked the genetic blueprint of an orchid that grows wild in the mountains of southeast China.
The orchid in question, from the subfamily, Apostasiodea, split off from modern species millions of years ago.
Researchers led by the Orchid Conservation and Research Centre of Shenzhen sequenced the genome of the orchid and compared it with more modern species.
Image copyright Zhong-Jian Liu and Li-Jun Chen Image caption The whole genome of another orchid was re-sequenced for this study

The data, published in the journal, Nature, "provides a reference for studying orchid evolution" and suggests distinctive features found only in orchids played a key role "in the tremendous radiation of the group", they say.
The orchid is one of the biggest families of flowering plants.
Many are grown for their beautiful flowers, while others are of economic importance, such as the source of the food flavouring, vanilla.
Commenting on the study, Dr Trevor Dines, of the wild plant conservation charity, Plantlife, said orchids have a host of unique features that make them special and instantly recognisable.
"Whether you're looking at a big, blousy Moth orchid from the supermarket or a tiny rare Bog orchid on a remote Snowdonia hillside, the flowers have the same underlying blueprint," he said.
"This research reveals that elements of this blueprint appeared right at the very start of the evolution of the orchid family, and may well have helped in their spectacular subsequent evolution into the 26,500-28,000 species we know of today."
Image copyright Zhong-Jian Liu and Li-Jun Chen Image caption The flowers of Apostasia shenzhenica

Some of the unique features of orchids include masses of pollen, known as pollonia, exceptionally light seeds and the ability to grow upon other plants, using them for support.
All these features are found in the 50 or more species of wild, native orchids in the UK, from the Lady's-slipper orchid to the Bog orchid.
Follow Helen on Twitter.
Image copyright Getty Images

The US solar industry has seen dramatic growth in the past few years, but a request for a rare trade action has led to a fierce fight over the future of the industry - and one that wouldn't exist without the presidency of Donald Trump.
Phil Brodhagen runs a solar installation company in Colorado Springs, and his customers - local homeowners and businesses in a military-friendly town - love American-made products.
Until they see the price.
"They want to go solar, but they do have a limit on how much they can spend."
he says.
"They'd love an American product, but if they can't afford it, they'll either not get a system at all, or go for the cheaper one."
Brodhagen is one of hundreds of business owners across the US paying very close attention to a case in front of the US International Trade Commission.
And he's worried about the outcome.
"It will hurt this industry," he says.
"It's going to be me laying off people as well as everyone else."
On Friday, the commission is expected to rule on whether imported solar products have seriously injured US solar product manufacturers, enough to impose higher tariffs on imports worldwide.
The petition was brought by two solar manufacturers who are based in the US, but owned by overseas companies.
Suniva and SolarWorld have argued their financial troubles - as well as a series of other US solar manufacturer bankruptcies - are due to a massive oversupply of solar cells and panels imported from overseas, primarily from Chinese companies.
Image copyright Getty Images

They point to dozens of US companies like theirs that have gone out of business since 2012.
"Quite simply, we need the commission's help to save solar manufacturing in the United States," Juergen Stein, chief executive of SolarWorld Americans told the commission in August.
But SolarWorld and Suniva find themselves fiercely opposed by much of the solar industry in the US, including the largest trade group, the Solar Energy Industries Association (SEIA).
SEIA has argued increasing the prices of panels through tariffs will set back the solar industry for years, hurting companies that buy and install solar panels, or make solar-related products.
The trade group estimates a loss of as many as 88,000 jobs, or a third of the current solar work force, if Suniva and SolarWorld's requests come to pass.
The group accuses the two companies of using the rare trade action to save themselves, at the expense of the rest of the industry.
What's at stake?
For both sides, the immediate future of the fast-growing solar industry in America.
Bret Sowers, a utility-scale solar farm developer, calls the trade case an "eminent threat" to his business.
Projects like his are reliant on how low a price per watt cost they can offer utility firms.
Their competition is not just other solar firms, but coal and wind, natural gas and nuclear energy.
New solar capacity doubled between 2015 and 2016 and such large-scale projects drove more than half the growth.
Image copyright Reuters Image caption An employee makes a final inspection on panels during a tour of an REC solar panel manufacturing plant in Singapore

"We have close to $2bn in investment we've planned across the southeast," he says, based on prices continuing their downward trend.
If he can't deliver the prices he expected, those solar farms won't be built.
"That's hundreds of construction jobs gone," he says, and layoffs at his company.
Sowers is specifically frustrated because US plants at SolarWorld and Suniva were not building the larger, 72-cell panels at the kind of scale his projects need.
"The two dots don't really connect.
They were making cars and I'm buying trucks - and now they're claiming the trucks are hurting the cars."
James Marlow, who runs a similar Georgia company, is frustrated with the petition, even though he just finished a project with Suniva panels.
"They used to be the home town team," he says of the firm, originally spun out from Georgia Tech and headquartered in the state.
In 2015, in an effort to expand, a Hong Kong-based energy firm purchased more than half the company, but Suniva filed for bankruptcy earlier this year, and weeks later, brought the trade petition.
SolarWorld, whose parent company also filed for insolvency in Germany, joined the petition shortly thereafter.
Marlow says he supports bringing back manufacturing to America, but thinks that means a whole set of policies to deal with what's a "drastically larger" issue.
"It's why most of our clothes are made in Asia and why this cell phone I'm talking to you on made in Asia - it's not just one action."
Media playback is unsupported on your device Media caption A stretch of road has been paved with solar PV (photovoltaic) panels in France.
He attended the 15 August arguments in front of the trade commission on the case and said interest was intense.
There were two overflow rooms for people to listen.
An official told him they hadn't seen that many people come to hear a case since NAFTA.
If the trade commission finds in favour of the manufacturers, it can make recommendations, but it is up to the president to decide.
And President Trump is eager to impose tariffs, especially in an industry in which he could be seen to be tough on Chinese manufacturing.
He reportedly has said "I want someone to bring me some tariffs" because "China is laughing at us".
Image copyright Getty Images

Once the trade commission makes its initial ruling, it will have several more weeks to make a recommendation to Trump.
The president then can decide to take the recommendation or not.
Solarworld had earlier successes with two requests for increased tariffs on Chinese manufacturers for similar unfair trade practice accusations.
But that wasn't enough, says Tim Brightbill, a lawyer representing SolarWorld, because Chinese firms shifted production to other countries to get around the tariffs.
He also claims the potential job loss numbers are overblown.
"These predictions were made before when SolarWorld brought actions against China, that somehow jobs would be lost.
But the opposite happened," Brightbill says.
The situation is especially odd considering both SolarWorld and Suniva are owned by parent companies that could be harmed by the tariff.
Brightbill says "it just shows that SolarWorld is committed to manufacturing here," even if it involves putting a tariff on a German-produced panel.
They may not be alone.
While the US solar industry is holding its breath, foreign manufacturers are starting to think about setting up shop in the US, especially if the commission recommends a broad tariff.
Both sides see the dispute as a turning point for the industry - and both think the president should be on their side.
"If the Trump administration wants to create jobs," James Marlow says.
"They should join with the solar industry."
The question for President Trump will be - which part?
Image copyright Cold Spring Harbor Laboratory Image caption Crick's lecture was said to have altered the logic of biology

Sixty years ago this week, one of the greatest British scientists, Francis Crick, gave a lecture in London in which he accurately predicted how genes work, setting the course for the genetic revolution we are now living through.
Here, evolutionary biologist Professor Matthew Cobb from Manchester University unpicks the predictions that set a new course for how we understand the very stuff we are made from.
In one lecture, it has been said that Francis Crick "permanently altered the logic of biology".
Only four years earlier, he and the young American Jim Watson had solved the double helix structure of DNA, using data gathered by Rosalind Franklin.
Aged 41, Crick was still five years away from winning the Nobel Prize for this work, but he had a reputation as a powerful and profound thinker.
He gave his lecture - "On protein synthesis" - at University College London for the Society for Experimental Biology.
In it, Crick spoke about how genes do what they do.
At the time, this subject was still very murky - some scientists were not even convinced that genes were made of DNA.
But Crick delivered four predictions about genes - and their link to the proteins that build our bodies.
In each of these ideas, he was right.
Cracking the code

Image copyright Science Photo Library

Crick started with the main thing that genes do: they control the production of proteins.
The problem Crick explored was that the DNA in a gene is simply a chemical code - a string of something called bases - A, C, T, G.

Crick had to explain how the cell could get from this one-dimensional sequence of bases in DNA to the complex three-dimensional structures of proteins.
Even more puzzling was the fact that proteins can fold themselves into nearly any shape.
Crick's answer was simple: the order of bases in the gene - what he called "genetic information" - corresponded to the order of the amino acids that make up each protein, and nothing more.
There was no structural information about the protein that was encoded in the gene, he claimed.
He called this the sequence hypothesis.
Somehow, the cell "read" the information in the gene and assembled the amino acids together like beads on a string.
The resulting protein folded itself - spontaneously - into its final 3-D structure.
We still cannot easily predict the structure of a protein from the order of its amino acids, but Crick's sequence hypothesis holds good.
Central dogma

To explain how exactly cells assemble proteins, Crick predicted there must be some small molecules - he called these "adaptors" - that could recognise each of the 20 different amino acids in the body, and would bring them to where they could be turned into a protein in the right order.
As Crick gave his talk in London this molecule was being identified in an American laboratory.
It is now called transfer RNA.
It is the biological messenger that reads and "translates" the genetic code in the cell's protein-building factory.
Image copyright Wellcome Library, London Image caption Crick drew a diagram to explain the flow of information from DNA to proteins

The most controversial and influential part of the lecture though was what was called the central dogma.
Crick explained that as proteins are synthesised, information is taken from the DNA molecule, first into an RNA molecule, and is then used to make a protein.
Before the lecture, he drew a little diagram to explain what he meant.
The arrows show what Crick called the flow of information going from DNA to RNA to protein.
DNA and RNA could also copy themselves, so there are also arrows going from DNA to DNA and from RNA to RNA.
Because the experimental data were not clear, Crick accepted that it might just be possible that DNA could directly lead to the production of proteins, so he drew an arrow there, too (this is not in fact the case).
The most important point was that, as Crick put it, once the information had gone from DNA into a protein, it could not get back into your DNA.
There was no biochemical route for a protein to change your DNA sequence.
Crick thought it might be possible for information to go from RNA to DNA, and this later turned out to be the case, when it was discovered that some RNA viruses can get into our DNA.
But the route from protein to DNA is impossible.
This central dogma emphasises that our DNA sequence cannot be changed by our proteins, or by how they are changed by experience.
Over the last 60 years this has proved to be correct.
Despite the excitement about what is called epigenetics, which explains how genes can be turned on and off by the environment, this never leads to a change in our actual DNA sequence.
Crick's dogma was absolutely right.
Crick later cheerfully admitted that when he coined the phrase, he didn't know what a dogma was.
What he really meant was that it was a basic assumption about how genes worked.
Whatever its name, it still guides scientists today.
Crick's final brilliant prediction was to suggest that in the future biologists would use sequence data to understand evolution, by comparing the sequences of different species.
In 1957, when Crick was speaking, protein sequences were known from only five species, while DNA sequencing was science fiction and 20 years in the future.
But this is exactly what happened, and we can now understand how organisms evolved in unprecedented detail, by comparing their sequences, just as Crick suggested.
Crick's lecture, which was published the following year, continues to be read and cited by scientists all over the world.
It is a monument of clear and penetrating thinking by one of the 20th century's greatest minds.
In all his key predictions, Francis Crick was right, and he did indeed change the logic of biology.
Professor Matthew Cobb is a zoologist, historian and author based at Manchester University
Image copyright Clayton Conn

Photographer Clayton Conn took these pictures in Mexico City, his home since 2009.
His neighbourhood - Portales, in the borough of Benito Jurez - suffered gravely in Tuesday's earthquake, the most lethal tremor to hit Mexico in a generation.
"The area I live in was hit pretty hard, so a lot of the people - a lot of my neighbours are devastated."
This image shows the building two doors down from his apartment.
It originally had five storeys.
"The two bottom floors have been completely collapsed," he says.
"The neighbours said that there are people still inside.
But the building was still sort of... kind of standing... From what I understand, people are still in there.
And those neighbours, they couldn't touch the building.
They fear it could continue collapsing."
Mr Conn was out with his girlfriend when the earthquake struck at 13:14 local time (18:14 GMT).
"I had my camera with me," he explains, "so we spent the day in the streets documenting, and also trying to get home."
Image copyright Clayton Conn

Image copyright Clayton Conn

Image copyright Clayton Conn

A couple of blocks away, he saw crowds of people staring across the rubble of another building, an eight or 10-storey apartment complex.
Neighbours wearing bicycle helmets for protection had joined the rescue effort alongside police and disaster relief workers.
"When they felt like there was a sign of someone, or they felt movement or that someone could be trapped down there, they would raise their fists - and that's the signal.
"So everyone - a crowd of a thousand people - immediately raise their fists, and there's almost complete silence.
You can just hear the generators from the vehicle they've brought in to shine light.
You couldn't hear a thing.
In that silence, they can try to communicate with anyone who is trapped below."
Image copyright Clayton Conn

Image copyright Clayton Conn

"A lot of people at first didn't realise the extent of the damage, so at first people were sort of joking in parks, and other areas where you're supposed to congregate when this occurs, to be safe.
"Once people started to realise that this was much more serious than maybe a small earthquake - because in Mexico City we feel earthquakes very frequently - some that are strong... A lot of people were in a state of shock - but a lot of people were reacting in a very heartening way.
"People were grabbing stuff from their houses, their offices, and just mobilising themselves.
"Within 20 minutes of the earthquake I was seeing people who looked like office workers carrying shovels and pickaxes - I have no idea where they got them from!
"A lot of people wearing their button-up shirts and pants - and a lot of younger people, artists, student types, running around with their shovels."
Image copyright Clayton Conn

Image copyright Clayton Conn

"The authorities weren't able to immediately attend all the places that were affected, all the buildings.
There's not enough rescue teams.
So there was a degree of shock and nervousness, but also - that sense of empathy that was really strong as well.
"People were handing out food... it was a really hot day.
"I only saw one woman that started crying.
I saw lots of people with sad faces, but also faces that were not completely overwhelmed.
Image copyright Clayton Conn

Image copyright Clayton Conn

The new earthquake struck on the 32nd anniversary of a magnitude 8 quake that killed up to 10,000 people and left 30,000 others injured.
That 1985 tremor caused serious damage to Mexico City and its surrounding areas, with more than 400 buildings collapsed and thousands more damaged.
Every year, the authorities carry out earthquake drills as part of the commemoration.
The photographer says they were held 40 minutes to an hour before the real-life disaster.
"There's an alarm that goes off - an earthquake alarm.
It's pretty effective.
It gives you, usually, about 40 seconds to a minute of heads-up...

"You hear this dramatic alarm and you leave the building.
But yesterday [when the real quake hit], the alarm didn't go off immediately - it went off midway through the earthquake.
"That might have caught a lot of people off guard."
This picture shows troops from the Mexican military, who mobilise in response to natural disasters - be it a hurricane or an earthquake.
The yellow armband signifies that that they're responding to an event, and providing aid to possible victims.
Image copyright Clayton Conn

All pictures copyrighted.
Image copyright Science Photo Library

Try to swat a fly and it will soon become clear that they're faster than you.
Much faster.
But how on Earth do these tiny creatures - with their minuscule brains - outwit us so easily?
You've probably pondered it after chasing a fly around your house and flailing your shoe with repeated, unsuccessful swats.
How does it move so fast?
Can it read my mind?
It was the question put to the BBC World Service CrowdScience team for our most recent episode addressing the apparent super powers of tiny animals.
The answer is that, compared with you and me, flies essentially see the world in slow motion.
To illustrate this, have a look at a clock with a ticking hand.
As a human, you see the clock ticking at a particular speed.
But for a turtle it would appear to be ticking at twice that speed.
For most fly species, each tick would drag by about four times more slowly.
In effect, the speed of time differs depending on your species.
This happens because animals see the world around them like a continuous video.
But in reality, they piece together images sent from the eyes to the brain in distinct flashes a set number of times per second.
Humans average 60 flashes per second, turtles 15, and flies 250.
It's all relative

The speed at which those images are processed by the brain is called the "flicker fusion rate".
In general, the smaller the species, the faster its critical flicker fusion rate - and flies, in particular, put us to shame.
Professor Roger Hardie, from the University of Cambridge, investigates how flies' eyes work, and he has an experiment to determine their flicker fusion rate.
Image copyright SPL Image caption "How d'ya like them apples?"
For flies, time drags more slowly than for people

"The flicker fusion rate is simply how fast a light has to be turning on and off before it's perceived or seen as just a continuous light" says Prof Hardie.
Roger inserts tiny glass electrodes into the living light sensitive cells of their eyes - photoreceptors - before flashing LED lights at faster and faster speeds.
Each flash of the LED produces a tiny electrical current in the photoreceptors that a computer can graph onto a screen.
Tests reveal the fastest fly records distinct responses to flickering up to 400 times per second, more than six times faster than our own rate.
The fastest vision of all is found in a species literally called a "killer fly".
It's a tiny predatory species found in Europe that catches other flies out of the air with super-fast reactions.
In her "fly lab" at Cambridge University, Dr Paloma Gonzales-Bellido demonstrates the killer flies' hunting behaviour by releasing fruit fly prey into a special filming box with a female killer fly.
Media playback is unsupported on your device Media caption Some flies see six times faster than us, catching prey in mid-air in less than a second.
Paloma records the behaviour at 1,000 frames per second using slow motion video cameras with a recording buffer.
The attached computer constantly saves the video, over-writing itself every twelve seconds.
When the fly moves, Paloma clicks a button to permanently save the last 12 seconds.
"Our reaction time is so slow that if we were to stop it when we think something is happening it would have happened already," says Dr Gonzales-Bellido.
Essentially, we can't even click a button before the behaviour has happened, it's that fast.
Fly vs fly

With the killer flies and their prey in the filming box, initially the killer fly just sat around motionless, but as one of the fruit flies flew about 7cm above it, there was a flash of movement and suddenly the killer fly was at the bottom of the box chomping into the quivering fruit fly.
Only looking at the slowed-down footage on the computer did it become clear what happened; the killer fly took off, circled the fruit fly three times as it tried to grab it repeatedly, before succeeding in capturing the elusive fruit fly with its front legs.
The whole behaviour from take-off to landing took just one second.
It appears as a flash to our eyes, so conversely, the swatting hand of a human must appear at a snail's pace.
Image copyright Other Image caption The killer fly's eyes contain many more mitochondria than in the eyes of other fly species

Image caption Paloma Gonzales-Bellido uses a special filming box to study killer flies

To enable this incredible speed of the killer fly, which is faster even than other fly species, the light-detecting cells in the killer fly eyes contain many more mitochondria (the "batteries" of biological cells) than are present in the same cells of other flies.
These are the batteries of the cell, so the speedy vision must take more energy than slow vision, explaining why all eyes aren't just set to the highest flicker fusion rate.
The carnivorous diet of the killer fly provides the large amounts of energy it needs to power these high-energy cells.
But even if we had the same number of mitochondria in the cells or our own eyes, we wouldn't have the same vision speed because flies' light-sensitive cells have a totally different design to those of vertebrates.
Behind the structural differences in the eyes of flies is their evolutionary origin.
Arthropods and vertebrates, the groups holding flies and humans, evolved their eyes entirely separately around 700-750 million years ago.
String theory

Flies' eyes evolved to pick up light with a series of tiny string-like structures that lie horizontal to the path that light travels through the eye.
These structures react to light mechanically whereas vertebrates have long tube-like cells facing the light, with chemicals that react to light at the base.
This structure in the fly eye is something Roger studies in his lab.
"It's more sensitive in terms of being able to give a large signal to the tiniest amount of light and it can also respond faster than the rods and cones in the vertebrate eye," he explains.
Image caption Roger Hardie studies the structure of the fly visual system

There are a few reasons for this higher sensitivity, but what Prof Hardie discovered is that they respond mechanically to light, as opposed to chemically as in cones and rods.
Mechanical responses enable faster neural signals.
On top of that, there's a limit to the speed at which neural impulses can travel and the smaller nerve distances from fly eye to fly brain speeds up processing compared to larger vertebrates.
Some vertebrates experience much faster vision than our own.
Whether the species is able to fly seems to correlate with faster vision, as does being small.
This may be because small flying animals have to react so quickly during flight to avoid approaching obstacles.
'Slow motion swats'

The fastest vision of all is found in species that catch flies in the air.
Back with vertebrates, when investigating the vision of the pied flycatcher, a small perching bird that catches flies in flight, scientists at Uppsala University in Sweden discovered that it was able to identify a light flashing on and off 146 times per second from a continuous light source.
The birds were trained to associate a flashing light source with a tasty treat, and would accurately identify the flashing light up to this rate, placing their flicker fusion rate at 146.
That's about twice the rate humans can see but still not as fast as the average fly.
This means the birds, like flies, experience each tick of the clock more slowly than humans.
There is an evolutionary pressure on the flycatchers to experience the ticking hand of the clock as slowly as possible in order to outwit their speedy prey.
Over evolutionary time, birds that experienced 'slower ticking' could react faster to their prey, allowing them to eat more, raise more chicks and pass this speedy vision to future generations.
The flies that have been chased by the fast-sighted birds will be evolving faster reactions to get away.
Creating an evolutionary arms race that has gone on longer even than the existence of birds.
Prey flies have been evolving faster vision and reactions to escape predatory flies like the killer fly since they evolved flight.
Next time you try inanely to swat a fly, try not to be so disheartened.
Your lumbering, slow motion swats are being thwarted by hundreds of millions of years of natural selection letting the flies watch your attempts in slow motion.
Between you and the fly, time, it seems, is relative.
Listen to 'CrowdScience' on the BBC World Service, the programme whose listeners inspired this article, and send your science questions to 'CrowdScience@bbc.co.uk' :
The low-lying Caribbean islands inhabited by Panama's indigenous Guna people are threatened by rising sea levels and increasingly unpredictable weather.
But unlike many island communities facing such problems, the Guna have an escape plan.
The tiny port of Carti on the mainland of Panama is the jumping-off place for day trippers who come to swim, splash and snorkel around the idyllic-looking islands that dot the horizon.
Motor boats buzz in and out carrying smiling visitors wearing life jackets and sun hats.
It's one of Panama's premier tourist destinations.
The islands - almost one for every day of the year - make up the Guna Yala autonomous region, together with a strip of territory on the mainland.
Most Guna communities live on the archipelago, and have done for centuries, after they were driven offshore by disease and venomous snakes.
But now many believe that only a move back to the mainland can secure their future.
It is the people of Gardi Sugdub - Crab Island - who are in the vanguard of the relocation project.
A kilometre inland from the port, where the earth is the colour of rusty nails, they have set aside 17 hectares (42 acres) for the development of a new village - La Barriada.
Unlike other communities around the globe threatened by the vagaries of climate change, the Guna people have a huge advantage: they already own the land they want to relocate to.
Victoria Navarro is one of those from Gardi Sugdub who pictures a new, more spacious existence on dry, higher land.
"I can imagine the community here in La Barriada," she says, looking out across the area of low, tropical vegetation that features a stream, and a small hill.
"My grandchildren want to play soccer and volleyball, but there's no place for them to do that on the island.
Here they can be free like the birds."
Back in 2010, Victoria and her island neighbours began to clear this land, close to the area where they grow crops, in preparation for construction of the new village.
"Everyone came and participated," she remembers.
"It was a very happy time."
Around the same time, with finance from the Inter-American Development Bank, Panama's national government began work on a huge new school adjacent to La Barriada.
The $9m complex, designed for students from across the archipelago, is almost complete.
A little further down the hill, $11m was invested in a new health centre.
Everything looked hopeful, especially when the government made a commitment in 2015 to build 300 houses in La Barriada - the Guna may own all this land, but they do not have the financial resources to develop so many homes.
Find out more

Listen to Linda Pressly's report on Panama's vanishing islands for Crossing Continents at 11:00 on Thursday on BBC Radio 4

Or catch up later on the BBC iPlayer

However, today work on the school and hospital has halted, as a result of a litany of contractual hiccups - and crucially, a failure to plan for adequate supplies of water and electricity.
Work never began on the 300 houses.
The Guna are disappointed but undeterred, and they continue to lobby and to raise funds.
Victoria is an optimist.
She still comes every so often to La Barriada to help re-clear those 17 hectares.
Even so, this patch of land is slowly being reclaimed by the jungle - much as Victoria's home is gradually being swallowed by the Caribbean Sea.
Image caption The La Barriada health centre stands half finished as the jungle regrows around it

Her island, Gardi Sugdub, is just 400m long and 150m wide, but it is occupied by about 2,000 people.
Every inch of the island is built on, unless it's part of a sandy footpath.
Victoria herself lives in a compound with 50 of her extended family - 17 people share her simple bamboo home.
The lack of space for a growing population once seemed to be a bigger problem than the rising sea level, which has been creeping up at a rate of between 2.3mm and 2.5mm per year - roughly an inch every 10 years.
But efforts to enlarge the island may have made its inhabitants more vulnerable to the effects of climate change.
Media playback is unsupported on your device Media caption Our island's being swallowed by the sea

Delfino Davies, who works as a guide for visiting tourists, lives with the rest of his extended family in six simple bamboo houses constructed in a line radiating from the centre of the island out to the shoreline.
It made sense to his forefathers to push the shore further away.
"My grandfather, Charlie Davies, when he came here it was a small island so he reclaimed land.
He brought the stone here, and extended his land," he says.
This has happened across the Guna archipelago.
People have infilled around the edges of the islands using stone, rubbish, and - most controversially - coral.
Image caption Coral is sometimes used for infilling and extending the shoreline

"Coral reefs stop wave action.
So when you remove the coral, even down to 3m in depth, you have no protection.
This has created chaos for people," says Dr Hector Guzman, a research scientist at the Smithsonian Tropical Institute in Panama City.
"The Carti area was where we got the most dramatic data about the destruction of the coral reef when we compared aerial photos taken in the 1960s and then again in 2003."
This means that the islanders are now particularly vulnerable to storm surges, and when the rain and wind come, Victoria Navarro often finds herself ankle-deep in water at home.
"I never sleep well - we're awake 24 hours a day," she says.
Image caption Victoria with her husband Raulio Harris in her overcrowded compound

In 2008, severe storms tore across the island over two long weeks.
Although a move to the mainland had already been mooted, it was in the wake of that destruction that people on Gardi Sugdub began to put together a plan.
The Guna are very well-organised.
Sailas, spiritual and civic leaders, take decisions based on input from the community - on Gardi Sugdub there are meetings almost every day.
And a committee dedicated to the relocation plan is responsible for driving it forward and liaising with government agencies.
"This project's going to be a model for the rest of the Guna people," says Blas Lopez, a sociologist and community activist.
"But some of the other island communities don't think it will happen.
They see the government hasn't supported us, so they're waiting to see if it will become a reality.
If we achieve our dream, other communities will move back to the mainland too."
On the much smaller nearby island of Gardi Muladup, a lack of space means pigs snuffle and feed in pens constructed over the ocean.
Carlos Perez, one of the sailas for this community of 500, is a sprightly 102 years old.
And he is worried.
"We can't control the water," he says.
"In January and February there are very strong winds, and huge waves."
This island has even less protection than Gardi Sugdub.
Image caption Carlos Perez: The people of Gardi Mudalup also want to move onshore

"We're a solitary island - there are no other islands in front of us, so we're much more vulnerable to flooding."
Carlos Perez says his people want to move back to the mainland too.
They have a piece of land on the mainland they call Red Mountain, and they hope to follow the people of Gardi Sugdub.
Not everyone is looking forward to a new life on dry land, though.
Even though her home floods, Antoneta Reurter, the mother of six children, says she has no plans to leave Gardi Sugdub.
In fact, she is hoping she will acquire more space for her family if her neighbours move to La Barriada.
And she does not trust predictions that some of the islands on the archipelago could be flooded in a decade.
"I don't believe the scientists," she says.
"I don't think the islands will disappear - only God can decide that.
If people are corrupt and behave badly, God can send a hurricane or an earthquake and maybe then the islands could go."
Her view - that other-worldly powers may punish the Guna for wickedness - is not one shared by the director of education on Gardi Sugdub, Francisco Gonzales.
"We're more and more affected by climate change," he says.
"And what we're seeing lately isn't the same as what we've seen before - the weather can be really good, then there's a sudden change.
The sea's rising, there are floods in the streets and high winds damage the school's roof.
When that happens we have to send the children home to keep them safe."
Five hundred students squash into the island's classrooms in shifts.
The new school next to the illusory La Barriada on the mainland should have opened three years ago.
When - yet again - classes failed to commence this year, the people protested, blocking the main road leading inland from the port of Carti, and demanding an end to false promises.
Now it seems the government of President Juan Carlos Varela may be listening.
"We hope we can re-start work on the school, and complete it in the first quarter of 2018," Jorge Gonzalez, the minister who has taken the lead on the relocation project, told the BBC.
"We're going to try and find the economic resources, and get electricity to the school and the health centre."
And what about La Barriada, and the construction of those 300 homes he promised back in 2015?
"They're in the budget for this year and next - the Ministry of Housing's in the process of contracting a company than can build them.
We're hoping they will be delivered in 2018.
That's a reality."
And there are signs the government's commitment is genuine - housing officials have since visited La Barriada to inspect the land.
So perhaps, after all, the Guna's foresight will pay off, and their efforts will provide a model for other communities confronting climate displacement in the region and beyond.
Photographs taken by Simon Maybin

Join the conversation - find us on Facebook, Instagram, Snapchat and Twitter.
Image copyright Getty Images Image caption Investigations of murder cases would benefit from the data gathered at a body farm

You are dead.
Now what?
It's the start of a fascinating and eventful - if gory and smelly - journey, at least for your body as it decomposes.
Understanding decomposition can hold the key to solving murders, finding missing people and crucially recognising them, and that is why "body farms" exist.
Body farms are essentially outdoor laboratories where experiments using donated human cadavers investigate taphonomy - the science of decomposition.
Worldwide there are several such facilities: one in Australia, the others are in the US.
But now UK scientists, including Dr Anna Williams from the University of Huddersfield, are lobbying for one in the UK.
This page contains some images a number of readers might find disturbing.
At the British Science Association's annual Science Festival this week in Brighton, Dr Williams presented on the importance of body farms to science and why she believes a UK facility is needed.
"Much of what we know about human decomposition was discovered in US body farms," she said.
Image copyright SPL Image caption Insect clues: The rate at which blowfly pupae grow is dependent on temperature

"We know that the sequence of events in decomposition proceeds along the same path regardless of where the body is, but the timing is very different depending on many factors - moisture, temperature and insects are probably the most important."
But more nuanced factors may also influence decomposition - "such as bacteria already on, and in, the body; whether the person was obese, had been on antibiotics, was diabetic, or even whether they were a vegetarian or not."
So decomposition is anything but simple.
And add in to the mix the fact that the bodies of murder victims can be found on a woodland floor, sealed in a suitcase, buried in a shallow grave, encased in concrete, burnt, dismembered, naked, clothed, wrapped in plastic, and so on.
Traumatic injury is also variable: gunshot wound, stabbing, hanging the list goes on.
Body farm advocates point out the benefits of such facilities, including training dogs to sniff out dead bodies, recognising facial features and ancestry after decay, and even helping to work out how fingerprints change and whether DNA can be recovered after varying intervals of decomposition.
But what about the classic detective question on finding a dead body: "Time of death"?
This is much more difficult to pin down than TV dramas would have you believe, especially a few weeks and more after death.
Medical examiners often use insect colonisation on the body, but this is notoriously unreliable to apply from place to place as it depends on fickle local weather conditions.
Image copyright Anna Williams Image caption Pigs are used in UK experiments, but is their decomposition very different from humans?
Exciting new data published last year in the journal Plos One suggests that the succession of bacteria that come and go, feeding on the decaying body, may help scientists to more accurately pinpoint post-mortem interval.
This discovery was made by analysing bacteria scraped from the nose and ear canals of decomposing cadavers at the world's first body farm in Tennessee.
In the UK, all decomposition experiments use animals - usually pigs.
This does have some advantages.
Most obviously, rotting animals in our countryside is not as objectionable to people as rotting humans.
Indeed, it might be a challenge getting a local community to accept a body farm in its area.
The other advantage is that when pigs are used, multiple experiments can be set up where the conditions prior to decomposition can be varied to show different outcomes.
This has not been the case with human experiments.
As Dr Patrick Randolph-Quinney from the University of Central Lancashire explained, the number of human bodies used in experiments has rarely exceeded three or four individuals, and this limited number will not catch all of the possible outcomes of decomposition.
"It's little more than anecdotal observation without any real understanding or prediction of underlying processes - you might call it 'anecdata'," he told BBC News.
But, on the flipside, there are big disadvantages to using pigs.
Firstly, we really don't know whether pigs decompose similarly to humans, and whether they are a good substitute to use.
This is being actively investigated in the newly opened Australian body farm.
Media playback is unsupported on your device Media caption Australian body farm: More than 500 people have donated their bodies

The results are eagerly awaited.
But as Dr Williams said in her presentation at the science festival: "There can be no better substitute for humans in understanding human decomposition".
Dr Williams firmly believes that a UK body farm facility will allow forensic science to flourish in Britain, producing new data on decomposition bespoke to our climate and situation.
But she cautioned: "We need academics to collaborate and share data across the UK, and across the world - that way experiments have the best chance of being rigorous with larger sample sizes."
Dr Randolph-Quinney has a further ambition: "If we imagine a game of 'fantasy taphonomy', where we had enough money and resources to investigate human decomposition properly, we wouldn't necessarily use outdoor facilities."
"We might build a grave in the lab, where we could adequately control experimental variables such as temperature, humidity, and recover all the products such as body fluids, DNA, organic gases that a body gives off after death.
"This would allow us to model and predict the underlying processes in a scientific way.
We can't do that at present."
Either way human body donations are required.
This may not be a big problem: at both US and Australian facilities there is a waiting list of living donors ready, upon death, to give their body to forensic science.
I was sent for 'gay cure'

Before the legalisation of homosexuality in July 1967, gay men in the UK lived in fear of arrest, beatings and blackmail.
Image copyright AFP/Getty Image caption Houston is now the flood capital of the United States

Parts of the Houston region have been hammered by more than 50in of rainfall since Hurricane Harvey made landfall, setting new records for the US.
But why has the city become America's flood capital?
In April 2016 "historic" flooding hit Houston, with 17.6in (44.7cm) of rain dumped on the city in a single day.
The flood came only 11 months after another massive storm struck the city, dropping over a foot of rain.
Together, these two events caused 16 deaths and more than $1bn (777m) in damages.
Both pale in comparison to Hurricane Harvey, the impact of which has secured Houston's unenviable reputation as the US city most severely affected by floods.
Understanding why the risk to life and property is rising is crucial not only to the future of America's fourth-largest city, but to others around the world which share many of its problems.
Urban sprawl

Houston's unbridled, rapid growth is a primary factor.
The population of its metropolitan area is close to 6.8 million people and, with predictions of some of the country's fastest growth for the coming years, it is expected to top 10 million by 2040.
Interactive See how Houston has developed since 1984 2017 1984

Growth itself is not a problem, as it can create economic, social and environmental benefits for cities.
But poorly planned growth which fails to carefully manage land use - for housing, businesses and the infrastructure like roads, parks and sewers that cities need - can create problems and even lead to disasters.
Houston has long favoured light touch controls, which has led to haphazard development.
The city now covers an enormous area of more than 1,500 sq km.
It is the archetype of urban sprawl, where land is made readily accessible for real estate development on the city's ever expanding periphery.
Loss of habitat

This unplanned growth has led to many problems.
One is that vast acres of wetlands and prairie land - which soak up large amounts of rainfall - have been paved over.
Between 1992 and 2010, for example, White Oak Bayou in north-west Houston lost about 70% of its original wetlands.
During heavy rain the city's growing expanses of concrete generate runoff that clogs and sometimes overwhelms its complex network of waterways.
This includes creeks and bayous, as well as flood controls like levees and detention basins.
Successful wetland and prairie land protection would not itself have a major effect in reducing flooding caused by unprecedented rainfall like that delivered by Harvey.
Yet, protecting and restoring the natural areas provides an important contribution to making Houston less vulnerable to more moderate storms.
They also bring environmental benefits - providing fish and wildlife habitats, and cleaning polluted runoff that can sometimes enter from the city.
The artificially blue-coloured areas show water detected before and after the storm.
Interactive See how flood waters caused by Hurricane Harvey have covered low-lying areas After Before

A city for cars

Another problem is that investment in flood control infrastructure - things like channels, dams and reservoirs - has failed to keep pace with the expansion of the city.
Houston is a car-oriented city, with multi-billion dollar projects supporting one of the most advanced systems of roads and highways in the world.
Image caption Houston is a city built for cars

The goal is to keep traffic moving.
The mismatch between spending on flood prevention and roads can bring new challenges, as fresh tarmac is laid for motorists.
One example is the partially completed State Highway 99.
Once completed this 290km (180-mile) loop will be the longest in the nation - encircling the Houston area.
Further urban sprawl on the edges of the city will inevitably follow and without careful planning, large new tracts of impervious concrete will be laid.
The runoff generated can cause problems for residents when heavy rains arrive.
For example, since the 1980s, rainfall has increased 26% in the Brays Bayou watershed, but runoff has increased by 204%.
Another study suggests that an additional 3,500 households in the Sims Bayou watershed in the south of the city were exposed to flooding as a result of increased runoff.
What can be done?
The tragedy wrought by Hurricane Harvey offers an opportunity to plan for the rebuilding of a more resilient city.
The expansion of the city has led to short-term financial rewards for developers and builders, while local government has benefitted from an expanded tax base.
But they have not shared the risk presented by flooding - the costs of which are mostly passed on to residents and the national government.
Image copyright Getty Images Image caption More than 3,000 people have been rescued in Houston alone

To survive on the Texas Gulf Coast in the coming century, the city and its surrounding region will have to make careful planning decisions to guide growth.
Better co-ordination between federal, state and local government bodies is sorely needed.
The city will also have to consider how it defends itself against storms.
Making huge investments in flood control infrastructure will be necessary if they are to keep pace with the rapid expansion of the population.
Around the world

While Harvey offers a dramatic example, devastating storms are becoming more frequent and severe around the world.
Rapid and poorly planned urbanisation, rising sea levels, and subsidence put the world's coastal cities at increased risk of flooding.
One World Bank study forecasts that global flood damage for large coastal cities could cost $1 trillion a year by 2050 unless action is taken.
There are cities that offer a hint of what can be achieved - both in the US and elsewhere.
Faced with more coastal storms and rising sea levels on the Atlantic Coast, Norfolk, Virginia, has adopted long-term strategies for guiding future land use and development.
For example, areas at low risk of flooding where there has so far been limited development will be transformed into high density and mixed income neighbourhoods.
In contrast, high risk areas with established neighbourhoods are to gradually retreat from shorelines, with housing buyouts, while key sewer and water utilities, and roads will be maintained rather than expanded.
Image copyright Getty Images Image caption Rotterdam's Maeslant surge barrier is part of the city's extensive flood prevention system

Rotterdam, in the Netherlands, provides another model.
Ninety percent of the densely populated city lies below sea level.
Its pioneering solutions to flooding entail living with the water, rather than trying to contain it.
It has installed underground garages, green roofs that absorb water and water plazas that serve as a kind of aquatic town square, while simultaneously acting as huge storage reservoirs when extreme rainfall occurs.
From the Norfolk and Rotterdam perspectives, flooding and climate change are not obstacles to economic development, but opportunities.
About this piece

This analysis piece was commissioned by the BBC from an expert working for an outside organisation.
Philip Berke is Professor of Land Use and Environmental Planning at Texas A&M University.
Edited by Duncan Walker
Image copyright Science Photo Library Image caption Chemist Thomas Midgley insisted that tetraethyl lead was safe

Leaded petrol was safe.
Its inventor was sure of it.
Facing sceptical reporters at a press conference in October 1924, Thomas Midgley dramatically produced a container of tetraethyl lead - the additive in question - and washed his hands in it.
"I'm not taking any chance whatever," Midgley declared.
"Nor would I... doing that every day."
Midgley was - perhaps - being a little disingenuous.
He had recently spent several months in Florida, recuperating from lead poisoning.
Some of those who'd made Midgley's invention hadn't been so lucky, which is why reporters were interested.
50 Things That Made the Modern Economy highlights the inventions, ideas and innovations which have helped create the economic world in which we live.
It is broadcast on the BBC World Service.
You can find more information about the programme's sources and listen online or subscribe to the programme podcast.
On the Thursday of the week before Midgley's press conference, at a Standard Oil plant in New Jersey, a worker named Ernest Oelgert started hallucinating.
By Friday, he was running around the laboratory, screaming in terror.
On Saturday, with Oelgert dangerously unhinged, his sister called the police.
He was taken to hospital and forcibly restrained.
By Sunday, he was dead.
Within the week, so were four of his colleagues - and 35 more were in hospital.
Only 49 people worked there.
'The loony gas building'

None of this surprised workers elsewhere in Standard Oil's facility.
They knew there was a problem with tetraethyl lead.
As Gerald Markowitz and David Rosner note in their book Deceit and Denial: The Deadly Politics of Industrial Pollution, the lab where it was developed was known as "the loony gas building".
Nor should it have shocked Standard Oil, General Motors or the DuPont Corporation, the three companies involved with adding tetraethyl lead to gasoline.
Image copyright Science Photo Library Image caption An aerial photograph of DuPont's Deepwater factory site, where tetraethyl lead was developed

The first production line in Ohio had already been shut down after two deaths.
A third plant elsewhere in New Jersey had also seen fatalities.
Workers kept hallucinating insects - the lab was known as "the house of butterflies".
Better working practices could make tetraethyl lead safe to produce.
But was it really sensible to add it to petrol, when the fumes would be belched out on to city streets?
About a century ago, when General Motors had first proposed adding lead to petrol - in order to improve performance - scientists were alarmed.
They urged the government to investigate the public health implications.
Midgley breezily assured the surgeon general that "the average street will probably be so free from lead that it will be impossible to detect it or its absorption", although he conceded that "no actual experimental data has been taken".
Image copyright Science Photo Library Image caption Chemist Thomas Midgley with the Delco laboratory test engine

General Motors funded a government bureau to conduct some research, adding a clause saying it had to approve the findings.
Risky, but useful?
The bureau's report was published amid the media frenzy over Oelgert's poisoned workmates.
It gave tetraethyl lead a clean bill of health and was met with some scepticism.
Under pressure, the government organised a conference in Washington DC in May 1925.
The debate there exemplified the two extremes of approach to any new idea that looks risky, but useful.
In one corner: Frank Howard, vice-president of the Ethyl Corporation - a joint venture between General Motors and Standard Oil.
He called leaded petrol a "gift of God", arguing that "continued development of motor fuels is essential in our civilization".
Image copyright Alamy Image caption Dr Alice Hamilton argued the benefits of adding lead to petrol were outweighed by the risks

In the other corner: Dr Alice Hamilton, the country's foremost authority on lead.
She argued leaded petrol was a chance not worth taking.
"Where there is lead," she said, "some case of lead poisoning sooner or later develops, even under the strictest supervision."
Hamilton knew that lead had been poisoning people for thousands of years.
In 1678, workers who made lead white - a pigment for paint - were described as suffering ailments including "dizziness in the head, with continuous great pain in the brows, blindness, stupidity".
The Romans used lead in water pipes.
Lead miners often ended up mad or dead - and some correctly intuited that low-level, long-term exposure was also unwise.
"Water conducted through earthen pipes is more wholesome than that through lead," wrote the civil engineer Vitruvius, 2,000 years ago.
"This may be verified by observing the workers in lead, who are of a pallid colour."
Pollution v progress

Many societies still grapple with the general question on which Howard and Hamilton disagreed: how much pollution is a price worth paying for progress?
There's some evidence that as countries get richer, they tend initially to get dirtier and later clean up.
Economists call this the "environmental Kuznets curve", and it makes intuitive sense.
If you're poor, you prioritise material gains.
As your income grows, you may choose to spend some of it on a nicer, safer environment.
Image copyright Alamy Image caption The Roman civil engineer Vitruvius warned against the dangers of lead 2,000 years ago

But was lead-free petrol really such an expensive luxury?
True, the lead additive solved a problem: it enabled engines to use higher compression ratios, which made cars more powerful.
However, it was not the only way to solve the problem.
Ethyl alcohol had much the same effect and wouldn't mess with your head, unless you drank it.
Midgley knew this, having combined petrol with practically every imaginable substance, from iodine to camphor to melted butter.
Why did the petrol companies push tetraethyl lead instead of ethyl alcohol?
Researchers who have studied the decision remain puzzled.
Cynics might point out that any old farmer could distil ethyl alcohol from grain.
It couldn't be patented, or its distribution profitably controlled.
Tetraethyl lead could.
The crime connection

The US didn't tax lead in petrol until the 1970s, then finally banned it as part of clean air legislation, as the country moved down the far side of the environmental Kuznets curve.
Two decades later, in the 1990s, rates of violent crime started to go down.
There are many reasons why this might have happened, but the economist Jessica Reyes had an intriguing thought.
Children's brains are especially susceptible to chronic lead poisoning.
Is it possible that kids who didn't breathe leaded petrol fumes grew up to commit less violent crime?
Image copyright Alamy

Reyes could test her hypothesis: different US states phased out leaded petrol at different times.
By comparing the dates of clean air legislation with subsequent crime data, she concluded that more than half the drop - 56% - was because of cars switching to unleaded petrol.
Other researchers have found similar links between lead water pipes and urban homicide.
Disputed science and delayed regulation

You can put a dollar figure on the value of crime reduction, Reyes found.
It's about 20 times higher than the cost of de-leading petrol - and that's before you count other downsides of children breathing lead, like worse performance in school.
How did the US get this so wrong for so long?
Image copyright A Periam Photography / Alamy Stock Photo Image caption Asbestos continued to be widely used in construction despite the emerging evidence of its dangers

It's a tale of disputed science and delayed regulation, much like you could tell about asbestos, or tobacco, or other products we now know slowly kill us.
The problem is that people who want to ban things aren't always disinterested visionaries like Hamilton.
Sometimes they're obstructive cranks.
The only way to tell the difference is by conducting studies.
And, as Gerald Markowitz and David Rosner point out, "For the next four decades, all studies of the use of tetraethyl lead were conducted by laboratories and scientists funded by the Ethyl Corporation and General Motors".
More from Tim Harford:

How Diesel's engine changed the world

Battery bonanza: From frogs' legs to mobiles and electric cars

Why the falling cost of light matters

How a razor revolutionised the way we pay for stuff

And what of the scientist who first put lead in petrol?
By all accounts, Midgley was a genial man who may even have believed his own spin about the safety of a daily tetraethyl lead handwash.
But, as an inventor, his inspirations seem to have been cursed.
His second major contribution to civilisation was the chlorofluorocarbon, or CFC, which improved refrigerators, but destroyed the ozone layer.
In middle age, afflicted by polio, Midgley applied his inventor's mind to lifting his weakened body out of bed.
He devised an ingenious system of pulleys and strings.
They tangled around his neck, and killed him.
Tim Harford writes the Financial Times's Undercover Economist column.
50 Things That Made the Modern Economy is broadcast on the BBC World Service.
You can find more information about the programme's sources and listen online or subscribe to the programme podcast.
In early 2015, a team of scientists from the United Kingdom, Bulgaria, Sweden, the United States and Greece set off to investigate the effects of climate change and the impact of sea level changes in the Black Sea since the end of the Earths last glacial cycle 12,000 years ago.
What they discovered by chance during their studies was more than they could have ever imagined: 60 shipwrecks dating back 2,500 years, including artifacts from the Byzantine Era, the Middle Ages and the Ottoman Empire.
This week, after nearly three years at sea, the scientists who participated in the Black Sea Maritime Archaeology Project docked their research vessel in the port of Burgas, Bulgaria, and displayed dramatic 3-D printed replicas of those shipwrecks, which represent more than a thousand years of maritime history.
SUNKEN WWII SHIP MAY CONTAIN $130M IN NAZI GOLD

This assemblage must comprise one of the finest underwater museums of ships and seafaring in the world, said the projects chief investigator, Jon Adams, professor of maritime archaeology at the University of Southampton in England.
The ships were found lying hundreds or thousands of meters deep, many with their masts still standing and their rudders in place.
Cargoes of amphorae and ships fittings, their carvings and tool marks as distinct as the day they were made, were found lying on the decks.
Many of the ships revealed structural features, fittings and equipment that were known to have existed, but had never actually been seen.
We have never seen anything like this before, said Dr. Kroum Batcherov of the University of Connecticut.
This is history in the making unfolding before us.
The wrecks were found using robotic laser scanning, acoustic and photogrammetric techniques.
The earliest one found so far dates back to the Classical period, around 400-500 BC.
ARCHAEOLOGISTS IN NORWAY MAY HAVE UNCOVERED A VIKING BOAT GRAVE

We dived on one wreck, a merchant vessel of the Byzantine period dating to the 10th century, Adams said.
It lies at a depth of 93m that puts it into the diving range, so we took the opportunity to visually inspect certain structural features firsthand.
The condition of this wreck below the sediment is staggering, the structural timber looks as good as new.
This suggested far older wrecks must exist, and indeed, even in the few days since the dive, we have discovered three wrecks considerably older, including one from the Hellenistic period and another that may be older still.
Dr. Kalin Dimitrov, director of the Centre of Underwater Archaeology in Sozopol, Bulgaria, added:

"During the third season of the Black Sea MAP we continued filling in the blanks of the mosaic of ancient seafaring with the discovery and documentation of outstandingly well-preserved ships.
The vessels represent the Roman and Byzantine periods and the time of ancient Greek colonization.
The discovered shipwrecks will undoubtedly rewrite the history of ancient shipbuilding."
The start to the end of the world is coming this fall, according to doomsday writer David Meade.
Meade, who said he is using astronomy and the Biblical book of Revelations, has predicted that Oct. 15 will be the start of the tribulation  the seven-year period that brings the demise of the world.
Hold on and watch  wait until the middle of October and I dont believe youll be disappointed, said Meade, who also predicted a magnificent sign in the skies will occur on Sept. 23.
Meade certainly isnt the first person who predicted the end of the world.
Heres a look at some other recent times the world was supposed to end.
October 7, 2015

Chris McMann, the leader of the eBible Fellowship group in Philadelphia, warned that the world would be destroyed by a fire on Oct. 7, 2015.
When that didnt happen, McCann told The Guardian it was surprising.
eBible Fellowship appears to still be in existence.
December 21, 2012

Conspiracy theorist, numerologists and self-described prophets looked to Dec. 21, 2012 as the day the world would officially end  known as the Mayan Apocalypse.
They predicted the world would end with a massive solar storm that would knock out the power grid or from a comet blasting into Earth.
May 21, 2011

Harold Camping, a former evangelist, convinced so many people that the world would end on May 21, 2011 with a series of earthquakes that many quit their jobs and donated money to Campings Family Radio network.
After the world was still very much in tact on May 22, Camping changed the date to Oct. 21, 2011.
And when the world still wasnt destroyed then, Camping apologized for his sinful statements.
He died in 2013.
April 29, 2007

Former Southern Baptist pastor Pat Robertson has predicted the world will end multiple times  including on April 29, 2007.
He made the prediction in his book The New Millennium in 1990.
January 1, 2000

There was widespread concern and theories that computers couldnt handle the start of the new Millennium and the world would end.
That idea was also promoted by Jerry Falwell, the southern pastor who died in 2007.
Falwell warned that the new century would be Gods instrument to shake this nation, to humble this nation.
Tim LaHaye and Jerry Jenkins, authors of the fiction Left Behind series about the end times, also at one point warned that the Y2K could have brought about the destruction of the world.
The end of the world is starting this fall, according to a doomsday writer and researcher.
David Meade, author of Planet X: The 2017 Arrival, has predicted that Sept. 23 will bring a magnificent sign in the skies over Jerusalem, a historical event signaling an upcoming Tribulation Period of seven years.
He also asserted that a Planet X will cause the greatest catastrophic infliction of life upon mankind, since Noahs Ark,  citing the biblical story of a great flood that wiped out much of the Earth and humanity.
The Planet X will cause volcanic eruptions, a short stoppage of the Earths rotation, change in climate, tidal waves and earthquakes.
Read on for a look at who Meade is and when he predicts the world to end.
So when does he say the world will end?
According to Meades website, Sept. 23 is not actually the end of the world, but the day that a magnificent sign in the skies over Jerusalem will appear that will be a historical event signaling an upcoming Tribulation Period of seven years.
The tribulation period in Christianity is considered to be the seven year period when the anti-Christ comes into power and Gods wrath is released on those still on Earth.
TV PROGRAMS IN CALIFORNIA INTERRUPTED WITH END-OF-THE-WORLD PREDICTION

I dont know when the Rapture will happen.
I expect nothing to happen in September, Meade said.
However, the writer also opined that the seven-year Tribulation Period will begin on Oct. 15, citing the use of astronomical calculations and the book of Revelations in the Bible as his sources.
October is the month to watch!
The major signs that converge on September 23 are indeed amazing, but those are celestial events.
They are time markers.
The mainstream media states that something visible will occur on these dates.
I dont believe that, Meade said.
The actual event of the beginning of the Tribulation occurs on October 15.
Thats when the action starts, he continued.
Hold on and watch  wait until the middle of October and I dont believe youll be disappointed.
What are his religious beliefs?
Meade said on his website he was raised Catholic.
Catholics believe the Bible.
We were taught the Book of Revelation is true, Meade said.
The Popes believe it is true.
Protestants know it is true  it is taught in Sunday school.
This is not new information.
TEXAS INVESTORS BUILD LUXURIOUS HOMES FOR DOOMSDAY SCENARIOS

In an interview with the Washington Post, Meade denied that he has ever called himself a Christian numerologist.
What is his educational background?
Meade told the Washington Post that he studied astronomy at a university in Kentucky.
However, he declined to say which school for safety reasons, the Washington Post reported.
A biography of Meade on a Planet X News website said he went to the University of Louisville.
What does NASA say about Planet X?
NASA debunked claims that another planet is putting Earth in imminent danger and called claims of wayward planets such as Planet X an Internet hoax.
If Planet X was real and headed for an encounter with the Earth in 2012, astronomers would have been tracking it for at least the past decade, and it would be visible by now to the naked eye, NASA said.
Obviously, it does not exist.
Over the past two weeks, Mexico has experienced a lot of shaking.
On Sept. 8, a magnitude-8.1 earthquake struck 54 miles (87 kilometers) southwest of Pijijiapan, which sits just above the Mexico-Guatemala border.
Eleven days later, a magnitude-7.1 quake struck 3 miles (5 km) east of Raboso, near Mexico City.
And today (Sept. 21), another quake  a magnitude 4.8  hit just outside Pijijiapan.
While Mexico's position along major tectonic fault lines makes it a hotbed of seismic activity, the frequency of these powerful earthquakes begs the question: Are these quakes happening more often?
[The 10 Biggest Earthquakes in History]

Not likely, said Gavin Hayes, a research geophysicist at the U.S. Geological Survey's National Earthquake Information Center.
"Mexico is very prone to earthquakes," he said, "so earthquakes of this size in Mexico are not unusual.
Getting two in a row of this size so close together is unusual but not unexpected."
In the grand, slow-moving world of tectonic plates, Mexico is situated at an unfortunate location: It rests at the southern edge of the North American Plate, putting it right at the point where it meets the Pacific Plate, the Cocos Plate and the Caribbean Plate.
The quakes occur because all of these plates are moving in different directions, and as they collide or rub against each other, this movement can unleash destructive forces.
While these tectonic events usually occur along coastlines, like near Pijijiapan, the Cocos Plate has a unique conformation that explains why so many earthquakes are hitting Mexico City, which lies farther inland, according to the U.S. Geological Survey (USGS).
While the North American landmass is slowly moving west, the Cocos Plate is traveling northeast.
As they push against each other, the Cocos Plate, which carries the seafloor and is denser than plates carrying land, is forced underneath, into the Earth's mantle, according to the USGS.
But Hayes said that although most of these above-below collisions, called subduction zones, involve one point of descent, the Cocos Plate sinks a bit and then flattens out for a long expanse before it begins to sink again.
Because the location at which it sinks is spread out, the resulting earthquakes often occur farther inland than they would at a typical subduction zone.
"I think this perhaps facilitated the shaking we saw two days ago," Hayes said.
Some large earthquakes can trigger large aftershocks, but that's almost certainly not what happened here, according to Hayes.
For one, the two epicenters are too far away from each other to be causally related.
Even though both earthquakes occurred on the same subduction slab that goes beneath Central America, they were caused by different fault lines, he said.
As such, it was more of a coincidence than anything else that both fault lines were "ready to go," Hayes said.
But because there are so many fault lines along the subduction zone that runs down the coast of Mexico, Hayes thinks it's reasonable to assume that there will be more large earthquakes in the region in the future, but not any more than one might normally expect.
"It's still a significant hazard," he said.
Original article on Live Science.
The end is still nigh -- just not as nigh as it was earlier this week, a Doomsday writer says.
David Meade, who claimed the world is ending Saturday when a mysterious planet collides with Earth, is now backtracking on the calamitous claim.
Meade said the world won't end on Sept. 23 after all, but instead Saturday will only mark the beginning of a series of catastrophic events to occur over several weeks.
The world is not ending, but the world as we know it is ending, he told the Washington Post.
A major part of the world will not be the same the beginning of October.
Meade said his prediction is based on verses and numerical codes found in the Bible, specifically in the apocalyptic Book of Revelation.
He said recent events, such as the solar eclipse and Hurricanes Irma and Harvey, are omens of the approaching apocalypse.
The significant number is 33, according to Meade.
Jesus lived for 33 years.
The name Elohim, which is the name of God for the Jews, was mentioned 33 times [in the Bible], he said.
Its a very biblically significant, numerologically significant number.
Im talking astronomy.
Im talking the Bible...and merging the two.
Sept. 23 is also 33 days since the Aug. 21 solar eclipse.
Meade has also built his theory on the so-called Planet X, which is also known as Nibiru, which he believes will pass Earth on Sept. 23.
This will cause volcanic eruptions, tsunamis and earthquakes, he claims.
NASA has repeatedly said Planet X does not exist.
Meades prediction has been dismissed by people of faith including the Roman Catholic and Protestant branches of Christianity.
Ed Stetzer, a professor and executive director of Wheaton Colleges Billy Graham Center for Evangelism, slammed Meades theory on Friday, calling it fake news and asked Christians to be critical.
Its simply fake news that a lot of Christians believe the world will end on September 23, Stetzer wrote in Christianity Today.
Yet, it is still a reminder that we need to think critically about all the news.
A mass extinction which wipes out humanity will be underway by the year 2100, scientists have claimed.
By the end of the century, its feared that so much carbon will have been added to the oceans that the planet will have passed a threshold of catatastrophe which leads to the destruction of our species.
In the past 540 million years the planet has endured five such wipeouts  including the extinction of the dinosaurs.
The worst took place 252 million years ago and is known as the Great Dying.
This disaster killed off more than 95 per cent of marine life when the seas suddenly became more acidic.
Now geophysicist Professor Daniel Rothman says we are seeing a disturbing parallel today  this time because of man-made global warming.
He came up with a simple mathematic formula which predict that the oceans will soon hold so much carbon that a mass extinction is inevitable.
It showed the critical extra amount required is about 310 gigatons  which is the best case scenario projected by the Intergovernmental Panel on Climate Change (IPCC).
And it's well below the worst of more than 500 gigatons - which would far exceed the line.
In all scenarios, the study found by the end of the century the carbon cycle will either be close to - or well beyond - the threshold for catastrophe.
Although mass extinction won't soon follow at the turn of the century the world may have tipped into "unknown territory".
Professor Rothman, of the Massachusetts Institute of Technology, says it would take some time - about 10,000 years - for such ecological disasters to play out.
He said: "This is not saying disaster occurs the next day.
"It's saying - if left unchecked - the carbon cycle would move into a realm which would be no longer stable and would behave in a way that would be difficult to predict.
"In the past this type of behaviour is associated with mass extinction."
In the modern era CO2 emissions have risen steadily since the 19th century but deciphering whether this could lead to mass extinction has been challenging.
Humans have emitted 1,540 billion tonnes of CO2 since the industrial revolution - equivalent to burning enough coal to form a square tower 72 feet wide stretching 240,000 miles from Earth to the Moon.
Half of these have remained in the atmosphere causing a rise in levels at least 10 times faster than any known natural increase during Earth's long history.
Most of the other half has dissolved into the ocean - causing acidification.
Will this lead to the destruction of humanity?
Your grandchildren will probably find out, unless something changes now.
This story originally appeared in The Sun.
Turks and Caicos, parts of the Dominican Republic, and the southeastern Bahamas are under a hurricane warning as Hurricane Maria continues to rage in the Caribbean.
When the threat of a hurricane looms, its important for residents to know if hurricane warnings or watches have been issued for the areas they live in -- as well as what the two terms indicate.
Whats the difference?
Hurricane warnings and watches have slightly different meanings concerning hurricane conditions, or sustained winds of 74 mph or above, the National Oceanic and Atmospheric Administrations National Ocean Service (NOS) says.
A warning means that hurricane conditions are expected whereas a watch means that conditions are possible, the office explains.
When are hurricane warnings and watches issued?
Hurricane warnings and watches are issued 36 hours and 48 hours, respectively, before tropical-storm-force winds may strike, according to the NOS.
Because hurricane preparedness activities become difficult once winds reach tropical storm force (sustained winds of 39 to 73 mph), the hurricane warning is issued 36 hours in advance of the anticipated onset of tropical-storm-force winds to allow for important preparation, it says.
CATEGORY 2 HURRICANE PUMMELS NAPLES, FLORIDA

What does it mean when tropical storm warnings and watches are issued for areas?
Warnings mean tropical storm conditions are expected, while tropical storm watches indicate that theyre possible, the National Weather Service (NWS) says online.
What else should I know about weather warnings?
During a weather warning, it is important to take action: grab the emergency kit you have prepared in advance and head to safety immediately, the NWS advises, adding that warnings are more urgent than watches.
Fox News' Travis Fedschun and The Associated Press contributed to this report.
The Church of Latter Day Saints in Salt Lake City, UT.
has recent acquired the near 200-year-old printer's manuscript of the Book of Mormon, making it the earliest surviving copy in existence.
Elder Steven E. Snow, Church historian and recorder, said the Book is a revered text in the community.
We hold the Book of Mormon to be a sacred text like the Bible," Snow said in a press release.
"The printers manuscript is the earliest surviving copy of about 72 percent of the Book of Mormon text, as only about 28 percent of the earlier dictation copy survived decades of storage in a cornerstone in Nauvoo, Illinois.
ARCHAEOLOGISTS UNCOVER THE LOST ROYAL PALACE OF HENRY VIII

George Schweich, a grandson of early Church member David Whitmer, Mormon.
Schweich inherited the manuscript from his grandfather and sold it in 1903 to the Reorganized Church of Jesus Christ of Latter Day Saints.
The modern day Church purchased the manuscript on Sept. 18 for $35 million, which was provided by "generous donors."
Plans are currently under way to display the manuscript to the public at the Church History Library in the coming months, the release added.
2017 FOX News Network, LLC.
All rights reserved.
This material may not be published, broadcast, rewritten, or redistributed.
All market data delayed 20 minutes.
A mysterious letter written more than 300 years ago by a Sicilian nun who claimed to be possessed by Satan has finally been deciphered.
Scientists used a deep-web code breaker to read the letter.
The message  indeed devilish  describes God, Jesus and the Holy Spirit as "dead weights," the researcher said.
It was penned by Sister Maria Crocifissa della Concezione, a 31-year-old nun living at the convent of Palma di Montechiaro in Sicily.
On Aug. 11, 1676, she was found on the floor of her cell, her face covered in ink, holding a note written in an incomprehensible mix of symbols and letters, according to historical records.
Sister Maria apparently said the letter was written by the devil in an attempt to get her to turn away from God and toward evil, historical accounts suggest.
[In Photos: 'Demon Burials' Discovered in Poland Cemetery]

The message, just 14 lines of jumbled, archaic letters, has for centuries defied every attempt at understanding its meaning.
Now, scientists at the Ludum science museum in Sicily have used an intelligence-grade code-breaking software to solve the mystery.
They also looked at historical records of the nun and her life, to learn more about the woman.
"When working on historical decryption, you cannot ignore the psychological profile of the writer.
We needed to know as much as possible about this nun," Ludum Director Daniele Abate told Live Science.
Sister Maria Crocifissa della Concezione, born Isabella Tomasi (she was an ancestor of Italian writer Giuseppe Tomasi di Lampedusa), entered the Benedictine convent when she was only 15 years old, according to historical records.
"The letter appeared as if it was written in shorthand.
We speculated that Sister Maria created a new vocabulary using ancient alphabets that she may have known," Abate said.
To find out for sure, the researches first tested the software they used with some standard shorthand symbols from different languages.
They found that the nun's letter contained a mix of words from ancient alphabets such as Greek, Latin, Runic and Arabic.
"We analyzed how the syllables and graphisms [or thoughts depicted as symbols] repeated in the letter in order to locate vowels, and we ended up with a refined decryption algorithm," Abate said.
He said the team did not have great expectations for the outcome.
"We thought we could just come out with a few words making sense.
But the nun had a good command of languages," he said, adding "the message was more complete than expected."
Rambling in nature and not entirely understandable, the letter, in addition to calling the Holy Trinity "dead weights," goes on to say that "God thinks he can free mortals ...
The system works for no one ... Perhaps now, Styx is certain."
In Greek and Roman mythology, Styx is the river separating the netherworld from the world of the living.
Abete said the letter suggests that Sister Maria suffered from schizophrenia or bipolar disorder.
"The image of the devil is often present in these disorders.
We learned from historical records that every night she screamed and fought against the devil," Abate said.
For the church of that time, the letter was instead considered the outcome of her struggle against "innumerable evil spirits," according to a written account about the occurrence by Abbess Maria Serafica.
According to Serafica's account of the nun's behavior written shortly after the incident, the devil would have forced Sister Maria (who was later blessed) to sign the letter.
She heroically opposed the demand by writing, "Ohim" (oh me), which is the only comprehensible word in the letter, Serafica wrote.
The research has not been published in a peer-reviewed scientific journal.
Original article on Live Science.
A Dartmouth-led study has demonstrated how the latest aerial thermal imagery is transforming archaeology due to advancements in technology.
Today's thermal cameras, commercial drones and photogrammetric software has introduced a new realm of possibilities for collecting site data.
The findings, published in Advances in Archaeological Practice, serve as a manual on how to use aerial thermography, as the co-authors hope to inspire other researchers to apply this methodology in their work.
Archaeologists have long used thermal infrared images to locate buried architecture and other cultural landscape elements.
The thermal infrared radiation associated with such archaeological features depends on several variables, including the make-up of the soil, its moisture content and vegetation cover.
Past conventional geophysics methods, such as fieldwalking, enabled archaeologists to obtain field data across one hectare of a site per day.
But now, aerial thermography makes it possible to gather field survey data across a much larger area in much less time.
New aerial thermography has other advantages, as well.
Older cameras were unable to record full spectrum data or temperature data for every pixel of an image.
Today's radiometric thermal cameras coupled with small inexpensive, easy to fly drones, which can be controlled by a smartphone or tablet, have made aerial thermography more accurate, comprehensive and accessible.
Mapping multiple aerial images together has also become easier through new photogrammetric software, which automatically aligns images and features ortho-image capabilities, which corrects an image to make the scale uniform.
The researchers conducted case studies at six archaeological sites in North America, the Mediterranean and the Middle East, to assess the effectiveness of aerial thermal surveys.
They analyzed how weather, environment, time of day, ground cover, and archaeological features may affect the results, and compared their findings to earlier research and historical images.
For example, at an ancestral Pueblo settlement in Blue J, N.M, the researchers were able to map detailed architectural plans of a dozen ancient house compounds-- a discovery enabled by the site's optimal conditions, the soil matrix, low density ground cover, and the environmental conditions at the time of the aerial thermography.
They were also able to recognize traces of long-removed historic buildings and pathways at the Shaker Village in Enfield, N.H.

"A lot of what we've learned from our research to date shows how much local environmental conditions and the timing of surveys can impact how well thermal imagery will reveal archaeological remains.
Yet, the more we understand these issues, the better we are able to deploy the technology.
I think our results demonstrate aerial thermography's potential to transform how we explore archaeological landscapes in many parts of the world," says Jesse Casana, an associate professor of anthropology at Dartmouth, who has been using drones in aerial thermography for five years in his archaeological research.
Casana is available for comment at: jesse.j.casana@dartmouth.edu.
A study conducted by researchers in Brazil shows patients with chronic migraine are three times as likely to suffer from severe temporomandibular disorder.
In a study, researchers at the University of So Paulo's Ribeiro Preto School of Medicine (FMRP-USP), in Brazil, finds that the more frequent the migraine attacks, the more severe will be the so-called temporomandibular disorder, or TMD.
The temporomandibular joint acts like a sliding hinge connecting the jawbone to the skull, therefore the disorder's symptoms includes difficulty chewing and joint tension.
"Our study shows that patients with chronic migraine, meaning attacks occurring on more than 15 days per month, are three times as likely to report more severe symptoms of TMD than patients with episodic migraine," said Lidiane Florencio, the first author of the study, which is part of the Thematic Project "Association study of clinical, functional and neuroimaging in women with migraine", supported by the So Paulo Research Foundation - FAPESP.
Previous studies already indicated that migraine is somehow associated with pain in the chewing muscles.
However, this research was the first to consider the frequency of migraine attacks when analyzing its connection with TMD: eighty-four women in their early to mid-thirties were assessed, being that 21 were chronic migraine patients, 32 had episodic migraine, while 32 with no history of migraine were included as controls - the results were published in the Journal of Manipulative and Physiological Therapeutics.
Signs and symptoms of TMD were observed in 54% of the control participants without migraine, 80% of participants with episodic migraine, and 100% of those with chronic migraine.
For Florencio, central sensitization may explain the association between the frequency of migraine attacks and the severity of TMD.
"The repetition of migraine attacks may increase sensitivity to pain," she said.
"Our hypothesis is that migraine acts as a factor that predisposes patients to TMD.
On the other hand, TMD can be considered a potential perpetuating factor for migraine because it acts as a constant nociceptive input that contributes to maintaining central sensitization and abnormal pain processes."
Nociceptive pain is caused by a painful stimulus on special nerve endings called nociceptors.
Migraine and TMD have very similar pathological mechanisms.
Migraine affects 15% of the general population, and progression to the chronic form is expected in about 2.5% of migraine sufferers.
On the other hand TMD is stress-related as much as it has to do with muscle overload.
Patients display joint symptoms - such as joint pain, reduced jaw movement, clicking or popping of the temporomandibular joint - but also develop a muscular condition, including muscle pain and fatigue, and/or radiating face and neck pain.
Which came first?
TMD and migraine are comorbidities.
However, while people who suffer from migraine are predisposed to have TMD, people with TMD will not necessarily have migraine.
"Migraine patients are more likely to have signs and symptoms of TMD, but the reverse is not true.
There are cases of patients with severe TMD who don't present with migraine," said Dbora Grossi, the lead researcher for the study and principal investigator for the Thematic Project.
The researchers believe that TMD may increase the frequency and severity of migraine attacks, even though it does not directly cause migraine.
"We do know migraine isn't caused by TMD," Florencio said.
"Migraine is a neurological disease with multifactorial causes, whereas TMD, like cervicalgia - neck pain - and other musculoskeletal disorders, is a series of factors that intensify the sensitivity of migraine sufferers.
Having TMD may worsen one's migraine attacks in terms of both severity and frequency."
The journal article concludes that an examination of TMD signs and symptoms should be clinically conducted in patients with migraine.
"Our findings show the association with TMD exists but is less frequent in patients with rare or episodic migraine," Grossi said.
"This information alone should change the way clinicians examine patients with migraine.
If migraine sufferers tend to have more severe TMD, then health professionals should assess such patients specifically in terms of possible signs and symptoms of TMD."
###

About So Paulo Research Foundation (FAPESP)
NASA's asteroid sample return spacecraft successfully used Earth's gravity on Friday to slingshot itself on a path toward the asteroid Bennu, for a rendezvous next August.
At 12:52 p.m. EDT on Sept. 22, the OSIRIS-REx (Origins, Spectral Interpretation, Resource Identification, and Security - Regolith Explorer) spacecraft came within 10,711 miles (17,237 km) of Antarctica, just south of Cape Horn, Chile, before following a route north over the Pacific Ocean.
OSIRIS-REx launched from Cape Canaveral Air Force Station in Florida on Sept. 8, 2016, on an Atlas V 411 rocket.
Although the rocket provided the spacecraft with the all the momentum required to propel it forward to Bennu, OSIRIS-REx needed an extra boost from the Earth's gravity to change its orbital plane.
Bennu's orbit around the Sun is tilted six degrees from Earth's orbit, and this maneuver changed the spacecraft's direction to put it on the path toward Bennu.
As a result of the flyby, the velocity change to the spacecraft was 8,451 miles per hour (3.778 kilometers per second).
"The encounter with Earth is fundamental to our rendezvous with Bennu," said Rich Burns, OSIRIS-REx project manager at NASA's Goddard Space Flight Center in Greenbelt, Maryland.
"The total velocity change from Earth's gravity far exceeds the total fuel load of the OSIRIS-REx propulsion system, so we are really leveraging our Earth flyby to make a massive change to the OSIRIS-REx trajectory, specifically changing the tilt of the orbit to match Bennu."
The mission team also is using OSIRIS-REx's Earth flyby as an opportunity to test and calibrate the spacecraft's instrument suite.
Approximately four hours after the point of closest approach, and on three subsequent days over the next two weeks, the spacecraft's instruments will be turned on to scan Earth and the Moon.
These data will be used to calibrate the spacecraft's science instruments in preparation for OSIRIS-REx's arrival at Bennu in late 2018.
"The opportunity to collect science data over the next two weeks provides the OSIRIS-REx mission team with an excellent opportunity to practice for operations at Bennu," said Dante Lauretta, OSIRIS-REx principal investigator at the University of Arizona, Tucson.
"During the Earth flyby, the science and operations teams are co-located, performing daily activities together as they will during the asteroid encounter."
The OSIRIS-REx spacecraft is currently on a seven-year journey to rendezvous with, study, and return a sample of Bennu to Earth.
This sample of a primitive asteroid will help scientists understand the formation of our solar system more than 4.5 billion years ago.
NASA's Goddard Space Flight Center provides overall mission management, systems engineering and the safety and mission assurance for OSIRIS-REx.
Dante Lauretta of the University of Arizona, Tucson, is the principal investigator, and the University of Arizona also leads the science team and the mission's science observation planning and data processing.
Lockheed Martin Space Systems in Denver built the spacecraft and is providing flight operations.
Goddard and KinetX Aerospace are responsible for navigating the OSIRIS-REx spacecraft.
OSIRIS-REx is the third mission in NASA's New Frontiers Program.
NASA's Marshall Space Flight Center in Huntsville, Alabama, manages the agency's New Frontiers Program for the Science Mission Directorate in Washington.
INDIANAPOLIS -- A new IUPUI study funded by the U.S. Department of Agriculture answers a long-debated agricultural question: whether no-tillage alone is sufficient to prevent water pollution from nitrate.
The answer is no.
Researchers in the Department of Earth Sciences in the School of Science at IUPUI conducted a meta-analysis to compare runoff and leaching of nitrate from no-till and conventional tillage agricultural fields.
Surface runoff and leaching are two major transportation pathways for nitrate to reach and pollute water.
Due to its mobility and water solubility, nitrate has long been recognized as a widespread water pollutant.
"What we found is that no-till is not sufficient to improve water quality," said Lixin Wang, an assistant professor and corresponding author of the paper.
"In fact, we found that no-till increased nitrogen leaching."
The study suggests that no-till needs to be complemented with other techniques, such as cover cropping and intercropping or rotation with perennial crops, to improve nitrate retention and water-quality benefits.
After studying concentration of nitrate -- nitrate amount per water volume unit -- and nitrate load, or total amount of nitrate, researchers found surface runoff from no-till fields to contain a similar nitrate load to surface runoff from conventional tillage fields.
In contrast, nitrate load via leaching was greater with no-till fields than with conventional tillage fields.
No-till leaves crop residue on the soil surface and limits soil disturbance except for small slits to add fertilizer.
An estimated 20 percent of all croplands in the U.S. are under no-till management.
It reduces soil erosion by avoiding tilling year after year, which leads to soil getting washed away into lakes and rivers.
Because reducing soil loss reduces nutrient loss, it was assumed that no-till would reduce water pollution, Wang said.
"Overall, we found the adoption of no-till resulted in increased nitrate loss via leaching due to the frequent occurrence of macropores, such as those created by dead roots and earthworm burrows, in soils that have been under long-range no-tillage management," Wang said.
Researchers examined how nitrate loss through surface runoff and leaching were impacted by other factors, including aridity, rainfall variability, soil texture, crop species, duration of tillage and fertilizer type.
###

The research findings are presented in a paper, "Impacts of no-tillage management on nitrate loss from corn, soybean and wheat cultivation: A meta analysis," that was published Sept. 21 in the journal Scientific Reports.
The research presented is in collaboration with Pierre-Andr Jacinthe, the lead principal investigator of the USDA project and a professor in the Department of Earth Sciences; Lin Li, a professor in the Department of Earth Sciences; Pam Martin, a professor in the Department of Earth Sciences; and Stefani Daryanto, a postdoctoral researcher, who is the leading author of this paper.
This knowledge can provide targets in the search for novel bone-loss therapeutics to treat osteoporosis.
BIRMINGHAM, Ala. - A major health problem in older people is age-associated osteoporosis -- the thinning of bone and the loss of bone density that increases the risk of fractures.
Often this is accompanied by an increase in fat cells in the bone marrow.
University of Alabama at Birmingham researchers have now detailed an underlying mechanism leading to that osteoporosis.
When this mechanism malfunctions, progenitor cells stop creating bone-producing cells, and instead create fat cells.
Knowledge of this mechanism can provide targets in the search for novel bone-loss therapeutics to treat human osteoporosis with minimal side effects.
The UAB researchers found that a protein called Cbf-beta plays a critical role in maintaining the bone-producing cells.
Furthermore, examination of aged mice showed dramatically reduced levels of Cbf-beta in bone marrow cells, as compared to younger mice.
Thus, they propose, maintaining Cbf-beta may be essential to preventing human age-associated osteoporosis that is due to elevated creation of fat cells.
Bone is a living tissue that constantly rebuilds.
Bones need a constant new creation of cells specific to their tissue, including the bone-producing cells called osteoblasts.
Osteoblasts live only about three months and do not divide.
The progenitor cells for osteoblasts are bone marrow mesenchymal stem cells.
Besides osteoblasts, mesenchymal stem cells can also differentiate into the chondrocyte cells that make cartilage, the myocyte cells that help form muscles and the adipocytes, or fat cells.
Thus, the same progenitor cell has four possible tracks of differentiation.
UAB researchers and colleagues focused on the molecular mechanism that controls the lineage commitment switch between the osteoblast and adipocyte tracks.
Led by Yi-Ping Li, Ph.D., UAB professor of pathology, and Wei Chen, M.D., UAB associate professor of pathology, they investigated the key role played by Cbf-beta, or core-binding factor subunit beta.
Study details

The team led by Li and Chen generated three mouse models by deleting Cbf-beta at various stages of the osteoblast lineage.
All three mouse models showed severe osteoporosis with accumulation of fat cells in the bone marrow, a pathology that resembles aged bone from enhanced adipocyte creation.
Bone marrow mesenchymal stem cells and bone cells from the skulls of Cbf-beta-deficient mice showed increased expression of adipocyte genes.
Looking at the mechanism downstream, the researchers found that the loss of Cbf-beta impeded the canonical Wnt signaling pathway, particularly through decreased Wnt10b expression.
In nonmutant mice, they found that the protein complex composed of Cbf-beta and the Runx2 transcription factor binds to the Wnt10b promoter to drive Wnt10b expression.
The Cbf-beta/Runx2 complex also inhibited expression of the enhancer protein C/EBP-alpha that promotes differentiation of adipocytes.
In addition, the researchers showed that Cbf-beta maintains the osteoblast lineage commitment in two ways -- through the Wnt paracrine pathway to affect nearby cells and through endogenous signaling within the cell to suppress adipogenesis gene expression.
Altogether, this knowledge of the mechanism driven by Cbf-beta can help explain the imbalance in bone maintenance seen in older people.
###

Besides Li, corresponding author, and Chen, co-corresponding author, co-authors of the paper, "Cbf-beta governs osteoblast-adipocyte lineage commitment through enhancing beta-catenin signaling and suppressing adipogenesis gene expression," published in Proceedings of the National Academy of Sciences, are Mengrui Wu and Yiping Wang, UAB Department of Pathology; Jian-Zhong Shao, Zhejiang University, Hangzhou, China; and Jue Wang, UAB Department of Pathology.
Proper health care is more difficult in remote parts of India.
But one UTA business professor has published a study showing how to make telemedicine affordable and sustainable in those remote areas through micro-entrepreneurship.
RadhaKanta Mahapatra, a professor in the Department of Information Systems and Operations Management in the UTA College of Business, conducted the study, A Collaborative Approach to Creating ICT-based Sustainable Development, which was published as part of the Americas Conference on Information Systems' proceedings earlier this year.
ICT is Information and Communication Technology.
Former Odisha Chief Secretary Sahadeva Sahoo co-authored the study. "
We discovered that one key was making telemedicine sustainable, from technological and job skills standpoints but especially from a financial standpoint," Mahapatra said.
"Creating public-private partnerships to establish these telemedicine centers is another key to lasting, thriving telemedicine outposts."
A telemedicine outlet could cost between $9,000 and $12,000 to start in one of these remote areas, a large amount of money considering the average income level of rural India.
Mahapatra looked at the strategy and operations of OTTET Telemedicine for his case study.
OTTET is a non-profit organization based in the state of Odisha in India.
It promotes the use of telemedicine technology to expand the reach of healthcare to rural areas.
Odisha, one of the 29 states of India, covers about 60,000 square miles with a population of about 42 million.
About 83 percent of the population lives in rural areas, according to the 2011 Census of India and Mahapatra's study.
The state of healthcare delivery in India is very poor, especially in these remote areas.
The public health system is run by the state government.
A major hurdle in successful implementation of ICT-based development projects is lack of local ownership.
What Mahapatra discovered was that when funding agencies' grants expire, the system suffered or failed and people's healthcare was often sacrificed.
"One key to OTTET's success in implementing telemedicine projects in rural areas is getting someone in the community to invest in a telemedicine project's success," Mahapatra said.
"OTTET also tackles the lack of technical manpower in rural areas by training unemployed rural youths on telemedicine technology, another factor essential in the project's success."
What the study calls for is effective public-private partnership.
"We discovered that OTTET Telemedicine offers a viable approach to incremental and sustainable implementation of Information and Communications Technology-based development projects as long as there is local ownership and the public-private partnership model at work," Mahapatra said.
Chandra Subramaniam, interim dean of the UTA College of Business, said Mahapatra's work speaks directly to health and the human condition, one of the pillars of UTA's strategic plan.
"The findings of this paper will help create sustainable health delivery models in less developed regions around the world," Subramaniam said.
"Citation of this study by a major newspaper (the New Indian Express) in India brings positive publicity to UTA and helps extend its influence around the world."
###

Mahapatra started at UTA in 1998.
His research interests include ICT for global development, healthcare information systems, data warehousing, data quality, healthcare information systems, agile software development and IT project management.
His research publications have appeared in various journals including MIS Quarterly, Decision Support Systems, Information & Management and Communications of the ACM.
He is a recipient of the Distinguished Research Publication Award and the Distinguished Professional Publication Award from the College of Business.
Collaboration between the University of Maryland, College Park, and the University of Maryland, Baltimore, finds two group A Streptococcus genes involved in invasive, spreading infection underneath skin.
Group A Streptococcus bacteria cause a variety of illnesses that range from mild nuisances like strep throat to life-threatening conditions including pneumonia, toxic shock syndrome and the flesh-eating disease formally known as necrotizing fasciitis.
The life-threatening infections occur when the bacteria spread underneath the surface of the skin or throat and invade the underlying soft tissue.
A 2005 study published in The Lancet attributed half a million deaths worldwide each year to group A Streptococcus.
"In 24 to 48 hours, you can go from being healthy to having a limb amputated to save your life," said Kevin McIver, professor of cell biology and molecular genetics at the University of Maryland, College Park.
"And we don't really know why or how the bacteria do that."
In a new study, McIver's laboratory and researchers at the University of Maryland School of Medicine identified two genes important for invasive group A Streptococcus infections in mice.
The genes, subcutaneous fitness genes A (scfA) and B (scfB), may prove to be promising clinical targets in the fight against these infections, as there are no vaccines against group A Streptococcus or effective treatments for invasive infections.
The study was published online on August 23, 2017, in the journal PLOS Pathogens.
Led by Yoann Le Breton, the study's first author and a research assistant professor in McIver's group, the researchers discovered scfA and scfB by performing transposon sequencing on the entire group A Streptococcus genome.
Transposons, also known as jumping genes, are short sequences of DNA that physically move within a genome, mutating genes by jumping into them.
If the mutation causes an interesting effect, scientists can identify the mutated gene by locating the transposon, sequencing the DNA surrounding the transposon and mapping its location in the genome.
"Invasion under the skin, or subcutaneously, is not the norm for group A Streptococcus bacteria; it's actually very rare," McIver explained.
"We hypothesized that there must be genes in the bacteria important for invading soft tissues and surviving under the skin.
And we tested that theory by using transposons to make thousands of different individual mutants that we used to infect a subcutaneous environment in mice."
McIver and his colleagues used a transposon called Krmit--which they created in a previous study--to generate a collection of approximately 85,000 unique mutants in a group A Streptococcus strain.
They injected the mutant strains into mice, which resulted in humanlike infections.
The transposon was named for the Muppets character Kermit the frog, whose creator Jim Henson, a 1960 College Park alumnus, died of toxic shock syndrome following group A Streptococcal pneumonia.
"We were particularly interested in the mutations that didn't come out the other end--the ones not found in the surviving bacteria from the infected tissue," McIver said.
"These genes would be good targets for a vaccine or treatment because the bacteria missing these genes did not flourish in the infection site."
The researchers identified 273 scf genes as potentially involved in establishing infection under the skin, but two genes stood out: scfA and scfB.
Based on patterns in their DNA sequences, these genes likely encode proteins in the bacterial membrane.
This is a prime location for gene products involved in infection because many dangerous bacteria secrete toxins or proteins through the membrane to attack the host.
Additional experiments showed that bacteria lacking scfA or scfB had difficulty spreading from under the skin to the bloodstream and other organs.
The results suggest that these two genes are involved in the invasion process and may be potential targets for therapeutics.
"The next steps will be to expand the study to include multiple animal models, and these experiments are already underway," said Mark Shirtliff, a co-author of the study and a professor in the Department of Microbiology and Immunology at the University of Maryland School of Medicine and the Department of Microbial Pathogenesis at the University of Maryland School of Dentistry.
"We can also begin to formulate improved therapies and vaccines against group A streptococcus infections and their complications such as rheumatic heart disease, pneumonia and necrotizing fasciitis."
McIver also looks forward to using transposon sequencing to study other ways bacteria attack humans.
"Transposon sequencing can be used to probe how bacteria infect humans in any environment you can think of," McIver said.
"Like group A Streptococcus, many pathogenic bacteria have completely sequenced genomes, but we don't know what most of the genes are doing.
We're excited to have a method to interrogate all that unknown genetic material to better understand human infections."
###

Other study co-authors affiliated with the UMD Department of Cell Biology and Molecular Genetics include Professor Najib El-Sayed, postdoctoral fellow Ashton Belew, graduate student Ganesh Sundar and laboratory technician Emrul Islam.
This work was supported by the National Institute of Allergy and Infectious Diseases at the National Institutes of Health (Award Nos.
AI047928, AI134079 and AI094773) and a University of Maryland, Baltimore and University of Maryland, College Park Seed Grant.
The content of this article does not necessarily reflect the views of these organizations.
The research paper, "Genome-wide discovery of novel M1T1 group A streptococcal determinants important for fitness and virulence during soft-tissue infection," Yoann Le Breton, Ashton Belew, Jeffrey Freiberg, Ganesh Sundar, Emrul Islam, Joshua Lieberman, Mark Shirtliff, Herv Tettelin, Najib El-Sayed and Kevin McIver, was published online in the journal PLOS Pathogens on August 23, 2017.
Media Relations Contact: Irene Ying, 301-405-5204, zying@umd.edu

University of Maryland

College of Computer, Mathematical, and Natural Sciences

2300 Symons Hall

College Park, MD 20742

http://www.
edu

@UMDscience

About the College of Computer, Mathematical, and Natural Sciences?
The College of Computer, Mathematical, and Natural Sciences at the University of Maryland educates more than 7,000 future scientific leaders in its undergraduate and graduate programs each year.
The college's 10 departments and more than a dozen interdisciplinary research centers foster scientific discovery with annual sponsored research funding exceeding $150 million.
After an election year marked by heated exchanges and the distribution of fake news, Twitter bots earned a bad reputation--but not all bots are bad, suggests a new study co-authored by Emilio Ferrara, a USC Information Sciences Institute computer scientist and a research assistant professor at the USC Viterbi School of Engineering's Department of Computer Science.
In a large-scale experiment designed to analyze the spread of information on social networks, Ferrara and a team from the Technical University of Denmark deployed a network of algorithm-driven Twitter accounts, or social bots, programmed to spread positive messages on Twitter.
"We found that bots can be used to run interventions on social media that trigger or foster good behaviors," says Ferrara, whose previous research focused on the proliferation of bots in the election campaign.
But it also revealed another intriguing pattern: information is much more likely to become viral when people are exposed to the same piece of information multiple times through multiple sources.
"This milestone shatters a long-held belief that ideas spread like an infectious disease, or contagion, with each exposure resulting in the same probability of infection," says Ferrara.
"Now we have seen empirically that when you are exposed to a given piece of information multiple times, your chances of adopting this information increase every time."
To reach these conclusions, the researchers first developed a dozen positive hashtags, ranging from health tips to fun activities, such as encouraging users to get the flu shot, high-five a stranger and even Photoshop a celebrity's face onto a turkey at Thanksgiving.
Then, they designed a network of 39 bots to deploy these hashtags in a synchronized manner to 25,000 real followers during a four-month period from October to December 2016.
Each bot automatically recorded when a target user retweeted intervention-related content and also each exposure that had taken place prior to retweeting.
Several hashtags received more than one hundred retweets and likes, says Ferrara.
"We also saw that every exposure increased the probability of adoption - there is a cumulative reinforcement effect," says Ferrara.
"It seems there are some cognitive mechanisms that reinforce your likelihood to believe in or adopt a piece of information when it is validated by multiple sources in your social network."
This mechanism could explain, for example, why you might take one friend's movie recommendation with a grain of salt.
But the probability that you will also see that movie increases cumulatively as each additional friend makes the same recommendation.
Aside from revealing the hidden dynamics that drive human behavior online, this discovery could also improve how positive intervention strategies are deployed on social networks in many scenarios, including public health announcements for disease control or emergency management in the wake of a crisis.
"The common approach is to have one broadcasting entity with many followers, but this study implies that it would be more effective to have multiple, decentralized bots share synchronized content," says Ferrara.
He adds that many communities are isolated from certain accounts due to Twitter's echo chamber effect: social media users tend to be exposed to content from those whose views match their own.
"What if there is a health crisis and you don't follow the Centers for Disease Control and Prevention account?
By taking a grassroots approach, we could break down the silos of the echo chamber for the greater good," says Ferrara.
###

The study, entitled "Evidence of complex contagion of information in social media: An experiment using Twitter bots," was published in PLOS ONE on Sept. 22.
In a paper to be published in Science on 22 September, the Pierre Auger Collaboration reports observational evidence demonstrating that cosmic rays with energies a million times greater than that of the protons accelerated in the Large Hadron Collider come from much further away than from our own Galaxy.
Ever since the existence of cosmic rays with individual energies of several Joules was established in the 1960s, speculation has raged as to whether such particles are created there or in distant extragalactic objects.
The 50 year-old mystery has been solved using cosmic particles of mean energy of 2 Joules recorded with the largest cosmic-ray observatory ever built, the Pierre Auger Observatory in Argentina.
It is found that at these energies the rate of arrival of cosmic rays is ~6% greater from one half of the sky than from the opposite one, with the excess lying 120?
away from the Galactic centre.
In the view of Professor Karl-Heinz Kampert (University of Wuppertal), spokesperson for the Auger Collaboration, which involves over 400 scientists from 18 countries, "We are now considerably closer to solving the mystery of where and how these extraordinary particles are created, a question of great interest to astrophysicists.
Our observation provides compelling evidence that the sites of acceleration are outside the Milky Way."
According to Professor Luis Anchordoqui, one of three Lehman College collaborators, the results are a fantastic achievement for astrophysics.
"It is the first time an experiment is able to discover patterns in the sky that could help track the origin of the most energetic particles in the Universe," he said.
Cosmic rays are the nuclei of elements from hydrogen (the proton) to iron.
Above 2 Joules the rate of their arrival at the top of the atmosphere is only about 1 per sq km per year, equivalent to one hitting the area of a football pitch about once per century.
Such rare particles are detectable because they create showers of electrons, photons and muons through successive interactions with the nuclei in the atmosphere.
These showers spread out, sweeping through the atmosphere at the speed of light in a disc-like structure, similar to a dinner-plate, several kilometres in diameter.
They contain over ten billion particles and, at the Auger Observatory, are detected through the Cherenkov light they produce in a few of 1600 detectors, each containing 12 tonnes of water, spread over 3000 km2 of Western Argentina, an area comparable to that of Rhode Island.
The times of arrival of the particles at the detectors, measured with GPS receivers, are used to find the arrival directions of events to within ~1?.
By studying the distribution of the arrival directions of more than 30000 cosmic particles the Auger Collaboration has discovered an anisotropy, significant at 5.2 standard deviations (a chance of about two in ten million), in a direction where the distribution of galaxies is relatively high.
Although this discovery clearly indicates an extragalactic origin for the particles, the actual sources have yet to be pinned down.
The direction of the excess points to a broad area of sky rather than to specific sources as even particles as energetic as these are deflected by a few 10s of degrees in the magnetic field of our Galaxy.
The direction, however, cannot be associated with putative sources in the plane or centre of our Galaxy for any realistic configuration of the Galactic magnetic field.
Cosmic rays of even higher energy than the bulk of those used in this study exist, some even with the kinetic energy of well-struck tennis ball.
As the deflections of such particles are expected to be smaller, the arrival directions should point closer to their birthplaces.
These cosmic rays are even rarer and further studies are underway using them to try to pin down which extragalactic objects are the sources.
Knowledge of the nature of the particles will aid this identification and work on this problem is targeted in the upgrade of the Auger Observatory to be completed in 2018.
Lehman College is a collaborating institution in The Pierre Auger Observatory in Pampa Amarilla, Argentina, the largest cosmic ray observatory in the world.
The observatory tracks and observes particle showers produced by ultra-high energy cosmic rays.
###

The City University of New York is the nation's leading urban public university.
Founded in New York City in 1847, the University comprises 24 institutions: 11 senior colleges, seven community colleges, and additional professional schools.
The University serves nearly 275,000 degree-credit students and 218,083 adult, continuing, and professional education students.
Fires that span across the Northern Territory and Western Australia appear to have broken out in areas that have already been burned in previous fires.
Areas that sport "burn scars", those areas that are a darker, almost red-brown color, are surrounded by fires that are anywhere from a few hours old to 7 days old.
The areas that are seven days old can be attributed to fires that spread but areas that are just a few hours old may be fires that have presumably been put out only to have them break out again.
The Northern Territory of Australia experienced a higher than normal amount of rain this past season allowing the plants and trees that fuel fires to become even more overgrown and subject to becoming fire fodder.
The fire map from the Northern Australia and Rangelands Fire Information site has been superimposed over the Suomi NPP fire image.
The red marks are from the Suomi NPP image showing fires that are currently burning.
The other colors come from the NAFI map that shows areas burned at other times.
The legend on the lower right-hand side show which colors correspond to the months in 2017 where other fires made their marks on the landscape.
###

The Suomi NPP satellite's Visible Infrared Imaging Radiometer Suite (VIIRS) instrument captured this image on September 21, 2017.
NASA image courtesy Jeff Schmaltz, MODIS Rapid Response Team.
Caption: NASA/Goddard, Lynn Jenner with information from the Northern Australia and Rangelands Fire Information site.
AURORA, Colo. (Sept. 22, 2017) -- Efforts to remove barriers to accessing emergency contraception (EC) scored victories in 2013, when the U.S. Food and Drug Administration removed age restrictions on over-the-counter sales of the levonogestrel drug Plan B.
But those who need EC can still encounter cost and availability barriers.
Researchers at the University of Colorado School of Medicine discovered this when they asked 633 Colorado pharmacies in 2014 about EC access.
They found EC completely accessible to just 23 percent of those who use them.
They report their findings in the latest issue of the journal Women's Health Issues, "Barriers to Single-Dose Levonorgestrel-Only Emergency Contraception Access in Retail Pharmacies."
The study was selected by the editor of Women's Health Issues as an Editor's Choice article for the September/October 2017 edition.
Women's Health Issues is the official journal of the Jacobs Institute of Women's Health, which is based in the Department of Health Policy and Management at Milken Institute School of Public Health (Milken Institute SPH) at the George Washington University.
Study author Van (Mimi) Chau, a student at CU School of Medicine, under the mentorship of Carol Stamm, MD, along with colleagues that included Laura Borgelt, PharmD, a professor at the University of Colorado Skaggs School of Pharmacy and Pharmaceutical Sciences used the Little Blue Book 2014, which physicians use for referrals, to identify Colorado pharmacies, and then had three researchers call the pharmacies posing as women seeking levonogestrel-only emergency contraception (LNG-EC).
Chau was part of the University's Leadership, Education, Advocacy and Development (LEADS) track while she worked on the project.
They asked each pharmacy whether they had LNG-EC in stock, whether it was located on the shelf or had to be requested from the pharmacy, whether a generic version was available, how much the product cost, and whether any additional documentation -- such as proof of age or a prescription -- was required to purchase the drug.
The authors defined EC as being "completely accessible" at a pharmacy if the responding employee reported having it available on store shelves that day for purchase without presenting an ID or prescription.
Accessibility is important because EC must be taken within 120 hours of intercourse, and research suggests it is most effective within the first 24 hours.
Chau and her colleagues found that 87 percent of pharmacies reported having LNG-EC in stock, but it was only completely accessible at 23 percent of the stores surveyed.
Of the stores with the drug in stock, 42 percent reported it was behind the counter -- i.e., had to be requested from a pharmacy employee -- and 56 percent told callers an ID or prescription was required for purchase.
Independent pharmacies were significantly less likely to have EC in stock (58 percent of independent stores vs. 90 percent of chain stores and 100 percent of 24-hour stores) or demonstrate complete access (10 percent vs. 25 percent and 15 percent), the authors report.
Requiring EC purchasers to request the drug from a pharmacy employee and present additional documentation are potentially substantial barriers, the authors note, because people may find it embarrassing to interact with an employee about reproductive healthcare and may lack the requested documents.
Adolescents may not have identification or may not meet the age limit pharmacy employees believe to be in place.
When considering why pharmacy employees report outdated policies for documentation and behind-the-counter access, the authors point out that the age cutoff for LNG-EC products changed four times before being lifted completely, and suggest "delays in updating store policies or lag in information dissemination may explain the variability in knowledge among pharmacy staff about FDA regulations and requirements."
"Although federal policy restrictions on LNG-EC have been removed, this study demonstrates that retail pharmacy-level policies can still create tangible hindrances in obtaining appropriate health care," Chau and her co-authors write.
The study, "Barriers to Single-Dose Levonorgestrel-Only Emergency Contraception Access in Retail Pharmacies," has been published in the September/October issue of Women's Health Issues.
Pearls are among nature's most beautiful creations, and have been treasured for countless centuries.
Beneath one's iridescent surface lies a tough and resilient structure made of intricately arranged tiles of calcium carbonate organized by a crew of proteins that guide its formation and repair.
While it is known that pearls are made of calcium carbonate with an organic matrix core, the role of the proteins modulating the organization of these crystals has, until recently, been unclear.
Researchers at New York University College of Dentistry (NYU Dentistry) reported the role of two such proteins, the first two-protein study of its kind, that regulate the processes leading up to the formation of pearl.
The study was published online in July in the journal Biochemistry, a journal of the American Chemical Society.
A pearl is a byproduct of an oyster's defense mechanism, formed in response to injury to the mantle tissue by an irritant, such as a parasite or grain of sand.
Detached cells fall into the inner tissue where they multiply and form an enclosed sac-like structure to seal off the injured remnants.
This cavity is then filled with matrix proteins followed by mineral.
The mineral consists of two calcium carbonate components: an inner prismatic layer known as calcite and an outermost layer known as aragonite or the lustrous layer.
Both layers are chemically similar to the oyster shell itself.
"In the case of Pinctada fucata, a Japanese pearl oyster that creates precious pearls for the pearl industry, the pearl formation process is mediated by a 12-member protein family known as Pinctada Fucata Mantle Gene, or PFMG.
PFMG1 and PFMG2 are part of this PFMG proteome that not only forms the pearl, but also acts as 'maintenance crew' participating in the formation and repair of the shell," explained John S. Evans, DMD, PhD, professor of basic science and craniofacial biology at NYU Dentistry and the study's corresponding author.
Little is known about these proteins except that they are expressed in mantle tissue of the oyster.
Using the recombinant versions of PFGM1 and PFMG2, the authors used several characterization techniques to study the behavior of proteins and crystals in various conditions that mimic the ocean water.
"What we found is that PFMG1 and PFMG2 combine to form a hydrogel, and within this hydrogel each protein plays a specific role.
PFMG2 determines the size of the hydrogel assemblies and regulates the internal structure of the protein films, whereas PFMG1 enhances the stability of tiny ionic clusters that combine to form calcium carbonate layers of pearl," said Gaurav Jain, PhD, a postdoctoral associate in Dr. Evans's lab and the study's lead author.
"However, once mineral crystals form, PFMG1 and PFMG2 work together and put the finishing touches to the pearl by synergistically modifying the mineral crystal surfaces and creating internal porosities.
The interactions between both proteins is enhanced by calcium ions possibly due to interactions between different domains of PFMG1 and PFMG2," said Martin Pendola, PhD, also a postdoctoral associate in Dr. Evans's lab a study co-author.
"Pearl - which is essentially an inside-out version of the mollusk shell - consists of 95 percent calcium carbonate and 5 percent organic matrix.
This composition makes pearl approximately 1,000 times tougher than pure calcium carbonate - and one of the most resilient and lightweight materials found in a living organism," said Jain.
This research not only advances the understanding of underlying molecular mechanisms of pearl formation, which could have implications for quality and productivity in the pearl industry, but could also aid in the development of fracture resistant materials.
These resilient materials could have a variety of applications, including in the manufacturing of improved dental implants, materials for aerospace applications, or energy transmission.
###

In addition to Evans, Jain, and Pendola of NYU Dentistry, study authors include Yu-Chieh Huang and Denis Gebauer of Universitt Konstanz and Jose Juan Colas of University of York.
Portions of this research (mineralization assays, LM/EM/AFM visualization, flow cytometry, molecular modeling) were supported by the U.S. Department of Energy, Office of Basic Energy Sciences, Division of Materials Sciences and Engineering (Award DE-FG02-03ER46099).
QCM-D studies were supported by grants from the EPSRC (EP/M028127/1) and the MRC (Discovery Grant MCPC15073).
About NYU College of Dentistry
The ability to successfully navigate in the environment is essential both for animals searching for food or escaping predators, as well as for human urban dwellers.
It is something we take for granted, but under the hood, it is supported by still incompletely understood brain networks that continuously calculate our position in the environment.
Moreover, the location where certain experience occurred is an indispensable building block of memory.
In the study, which appears in the September issue of the journal Neuron, the team led by Bruce McNaughton, UCI distinguished professor of neurobiology and behavior at the Ayala School of Biological Sciences, presents the findings that improve our understanding of the brain's ability to tell how fast and in which direction our location is changing.
"The parietal cortex is part of the brain that processes visual and other sensory information in order to continuously update the speed and direction of movement", said Dr. Ivan Skelin, co-first author of the study and postdoctoral researcher at the Canadian Centre for Behavioural Neuroscience at the University of Lethbridge and the Department of Neurobiology and Behavior at the Ayala School of Biological Sciences.
"In this study, we found that there is a division of work between large groups of cells, or modules, each being active when the experimental rat's speed/direction were in a certain range [e.g.
10-20 cm/sec and heading north-east]."
Based solely on the activity of these cell modules, researchers were able to predict animal speed and direction with high accuracy.
The newly acquired knowledge of where and how this information is organized in the brain is a potentially useful guidance for the development of brain-machine interfaces, which are already helping paralyzed people interact with the environment using their thoughts.
###

Other researchers who contributed to this work were Aaron Wilber and Wei Wu from Florida State University.
The study was supported by the National Institutes of Health and Alberta Innovates - Health Solutions.
About the University of California, Irvine: Founded in 1965, UCI is the youngest member of the prestigious Association of American Universities.
The campus has produced three Nobel laureates and is known for its academic achievement, premier research, innovation and anteater mascot.
Led by Chancellor Howard Gillman, UCI has more than 30,000 students and offers 192 degree programs.
It's located in one of the world's safest and most economically vibrant communities and is Orange County's second-largest employer, contributing $5 billion annually to the local economy.
For more on UCI, visit http://www.
Media access: Radio programs/stations may, for a fee, use an on-campus ISDN line to interview UCI faculty and experts, subject to availability and university approval.
For more UCI news, visit news.uci.edu.
Additional resources for journalists may be found at communications.uci.edu/for-journalists.
A research led by Jordi Surralls, professor of the Department of Genetics and Microbiology at the Universitat Autnoma de Barcelona, director of the Genetics Unit at the Hospital de la Santa Creu i Sant Pau and lead researcher at the Centre for Biomedical Network Research on Rare Diseases (CIBERER), has identified a new genetic syndrome caused by mutations in both copies of the FANCM gene, also known as biallelic mutations.
The results, published in Genetics in Medicine, the official journal of the American College of Medical Genetics and part of the Nature group, suggest that these mutations predispose the body to early formations of tumours and chemotherapy toxicity.
In the article, lead author Massimo Bogliolo from the CIBERER research group led by Jordi Surralls analysed biallelic mutations in the FANCM gene in three individuals.
Despite the number of patients always being low in these types of studies, given that they deal with rare diseases, it was observed that there was an early onset of cancer and toxicity to chemotherapy, but the patients did not present any congenital malformations or haematological phenotype which could suggest being affected by Fanconi anaemia, a rare disease which affects one out of every 100,000 children.
Until now it was believed that the FANCM gene was related to this disease, given that in 2005 the biallelic mutation was observed in patients suffering from Fanconi anaemia.
In another article published in the same volume of the journal, researchers from Dr Surralls' group and the research group led by Javier Bentez at the CNIO and the CIBERER confirmed that women with biallelic mutations in the FANCM gene did not develop Fanconi anaemia, but did present a higher risk of breast cancer, chemotherapy toxicity and chromosomal fragility.
This article was coordinated by Paolo Peterlongo of the Milan Institute of Molecular Oncology and included the participation of several hospitals and research centres of Italy, Germany, Spain and Sweden.
"Until now it was thought that biallelic mutations in the FANCM gene caused Fanconi anaemia, but we have now demonstrated that it is not so, given that in the two studies there were eight patients with these mutations and none of them had anaemia", affirms Jordi Surralls.
The patients however had suffered from cancer at very early ages and also presented chemotherapy toxicity.
Therefore, in view of the new syndrome, the authors recommend modifying the clinical monitoring of patients with biallelic mutations in the FANCM gene and taking precautions when using chemotherapy and radiation therapies due to the acute toxicity they may produce.
Genetic Complementation Test

For the study, researchers conducted functional complementation tests, a very important type of analysis in mass sequencing projects in which there are several mutated genes and it is not clear which ones are the source of the disease.
The patient's cells have a clear phenotype of chemical hypersensitivity to DEB, an agent which causes damage to DNA (patient's cells do not survive high doses of DEB).
In contrast, when a healthy FANCM gene copy was transferred into the cells of patients with the help of a virus (using lentiviral transductions), researchers observed the reversal of this phenotype and cells behaving as if they were healthy (a response similar to that of a healthy donor).
This functional study is the genetic demonstration that the gene causing the disease is FANCM and, therefore, the mutations observed in this gene are of a pathogenic nature.
WASHINGTON, D.C., September 22, 2017 -- Pure diamond consists of carbon atoms in a perfect crystal lattice.
But remove a few carbons and swap some others for nitrogen, and you get a diamond with special quantum-sensing properties.
These properties are useful for quantum information applications and sensing magnetic fields, and as a platform for probing the mysteries of quantum physics.
When a nitrogen atom is next to the space vacated by a carbon atom, it forms what is called a nitrogen-vacancy (NV) center.
Now, researchers have shown how they can create more NV centers, which makes sensing magnetic fields easier, using a relatively simple method that can be done in many labs.
They describe their results this week in Applied Physics Letters, from AIP Publishing.
Magnetic field sensing presents a prime example for the importance of this sensing.
Green light can induce the NV centers to fluoresce and emit red light, but the amount of this fluorescence changes in the presence of a magnetic field.
By measuring the brightness of the fluorescence, diamond NV centers can help determine magnetic field strength.
Such a device can make magnetic images of a range of sample types, including rocks and biological tissue.
The sensitivity of this type of magnetic detection is determined by the concentration of NV centers while vacancies that are not paired with nitrogen create noise.
Efficient conversion of vacancies into NV centers, therefore, as well as maximizing the concentration of NV centers, plays a key role in advancing these detection methods.
Researchers typically purchase nitrogen-doped diamonds from a separate company.
They then bombard the diamond with electrons, protons or other particles, which strip away some of the carbon atoms, leaving behind vacancies.
Finally, a heating process called annealing nudges the vacancies next to the nitrogen atoms to form the NV centers.
The problem is that irradiation often requires sending your sample to a separate facility, which is expensive and time-consuming.
"What is special about our approach is that it's very simple and very straightforward," said Dima Farfurnik of the Hebrew University of Jerusalem in Israel.
"You get sufficiently high NV concentrations that are appropriate for many applications with a simple procedure that can be done in-house."
Their method uses high energy electron bombardment in a transmission electron microscope (TEM), an instrument accessible to many researchers, to locally create NV centers.
Normally, a TEM is used to image materials down to subnanometer resolutions, but its narrow electron beam can also irradiate diamonds.
Others have shown TEMs can create NV centers in specialized diamond samples, but the researchers in this study successfully tested the method on several commercially available diamond samples.
In a typical, untreated sample, less than 1 percent of the nitrogen atoms form NV centers.
But by using a TEM, the researchers increased this conversion efficiency to as high as 10 percent.
In certain cases, the samples reached their saturation limit, and more irradiation was no longer effective.
For other samples, however, the researchers didn't hit this limit, suggesting that additional irradiation could boost efficiencies further.
With higher conversion efficiencies, and small irradiation volumes possible with a TEM, devices like magnetic sensors could be more compact.
To make sure the method didn't hinder the effectiveness of NVs in applications like sensing magnetic fields, the researchers confirmed that the length of time the NV centers remain in their states -- the coherence time -- didn't change.
Packing enough NV centers in a diamond would allow physicists to probe the quantum interactions among the centers themselves.
This research could enable the creation of a unique quantum state called a squeezed state, which has never been demonstrated before in a solid and could push the sensing capabilities of these systems beyond today's classical limits.
"We hope the enhanced number of NV centers due to irradiation will serve as a stepping stone for this long-term and ambitious goal," Farfurnik said.
###

The article, "Enhanced concentrations of nitrogen-vacancy centers in diamond through TEM irradiation," is authored by D. Farfurnik, N. Alfasi, S. Masis, Y. Kauffmann, E. Farchi, Y. Romach, Y. Hovav, E. Buks and N. Bar-Gill.
The article appeared in Applied Physics Letters Sept. 19, 2017 [DOI: 10.1063/1.4993257] and can be accessed at http://aip.
scitation.
org/ doi/ full/ 10.
1063/ 1.
4993257 .
ABOUT THE JOURNAL
CHICAGO--The nation's emergency departments had low rates of complying with recommended HIV and syphilis screening for at-risk adolescents, though larger hospitals were more likely to provide such evidence-based care, according to a study presented during the 2017 American Academy of Pediatrics (AAP) national conference.
Nearly 1 million cases of pelvic inflammatory disease (PID) are diagnosed each year, and 20 percent of those diagnoses are for females younger than 21.
PID is a complication of undiagnosed or undertreated sexually transmitted infection and can signal patients at heightened risk for syphilis or HIV, according to a study led by Monika Goyal, M.D., M.S.C.E., director of research in the Division of Emergency Medicine at Children's National Health System.
"Adolescents account for half of all new sexually transmitted infections (STIs) and often view the emergency department (ED) as the primary place to receive health care.
If we are able to increase screening rates for sexually transmitted infections in the ED setting, we could have a tremendous impact on the STI epidemic," Dr. Goyal says.
Although gonorrhea and chlamydia are implicated in most cases of PID, The Centers for Disease Control and Prevention (CDC) recommend that all women diagnosed with PID be screened for HIV and also recommends syphilis screening for all people at high risk for infection.
The research team conducted a cross-sectional study using a database that captures details from 48 children's hospitals to determine how often the CDC's recommendations are carried out within the nation's EDs.
The research team combed through records from 2010 to 2015 to identify all ED visits by adolescent women younger than 21 and found 10,698 PID diagnoses.
The girls' mean age was 16.7.
Nearly 54 percent were non-Latino black, and 37.8 percent ultimately were hospitalized.
"It is encouraging that testing for other sexually transmitted infections, such as gonorrhea and chlamydia, occurred for more than 80 percent of patients diagnosed with PID.
Unfortunately, just 27.7 percent of these young women underwent syphilis screening, and only 22 percent were screened for HIV," Dr. Goyal says.
Cosmic rays are atomic nuclei that travel through space at speeds close to that of light.
Low-energy cosmic rays come from the Sun or from our own Galaxy, but the origin of the highest-energy particles has been the subject of debate ever since they were first discovered fifty years ago: do they come from our Galaxy or from distant extragalactic objects?
The question has now been settled by studying 30 000 cosmic-ray particles with energies a million times greater than those of the protons accelerated in the LHC .
They were detected from 2004 to 2016 at the largest cosmic ray observatory ever built, the Pierre Auger Observatory in Argentina.
Analysis of the arrival directions of the particles showed that at such energies the flux of cosmic rays coming from a region of the sky located 120 degrees from the galactic center is approximately 6% higher than if the flux were perfectly uniform.
This direction cannot be associated with potential sources in either the galactic plane or galactic center, providing the first convincing evidence that these cosmic rays have an extragalactic origin.
The flux of these very high-energy cosmic rays (exceeding 2 joules) is about one particle per square kilometer per year .
When the cosmic rays collide with molecules in the upper atmosphere, they create cascades of over 10 billion secondary particles, known as air showers, which can cover an area exceeding 40 square kilometers by the time they reach the ground.
The Pierre Auger Observatory detects some of these secondary particles (electrons, photons and muons) by means of an array of 1 600 detectors, i.e.
tanks of pure water spaced 1.5 kilometers apart and covering 3 000 square kilometers in the Argentinian pampas, an area slightly larger than Luxembourg.
By comparing the arrival times of particles at the different detectors it is possible to determine where the cosmic ray particle that produced the air shower came from.
This discovery clearly indicates an extragalactic origin for these cosmic rays, since there is a probability of only one in five million that the pattern observed in the sky is due to chance.
However, the study has not yet succeeded in locating the sources precisely.
This is because the region where cosmic rays are brightest covers a large part of the sky, where the number of galaxies is relatively high.
In addition, our Galaxy's magnetic field deflects the paths of these charged particles , making it more difficult to locate their sources.
Some cosmic rays have even higher energies than those focused on in this survey.
They have the disadvantage of being even more unusual, but also the advantage that they are not as deflected by the magnetic field of our own Galaxy.
Their direction of arrival may therefore more accurately indicate the region where they were produced.
In 2007, an earlier study pointed to a correlation between active galactic nuclei and the arrival directions of the highest-energy cosmic rays then detected , but this correlation subsequently turned out to be not very significant.
Research is currently being carried out on a much larger sample of ultrahigh-energy cosmic rays, and may provide some answers.
At the same time, an upgrade program is underway at the Pierre Auger Observatory, which should make it easier to identify the sources.
400 scientists from 18 countries take part in the Pierre Auger Collaboration, which develops and runs the observatory of the same name.
The CNRS is the observatory's principal French funding agency.
The following French laboratories contribute to the collaboration:

the Institut de Physique Nuclaire d'Orsay (CNRS/Universit Paris-Sud) ;

the Laboratoire de Physique Nuclaire et des Hautes Energies (CNRS/UPMC/Universit Paris Diderot) ;

the Laboratoire de Physique Subatomique et de Cosmologie (CNRS/Universit Grenoble Alpes/ Grenoble INP).
NASA-NOAA's Suomi NPP satellite provided a look at Maria's temperatures to find the strongest sides of the storm, while NOAA's GOES satellite revealed the extent of the storm in a visible image as it moved toward the Bahamas.
On Sept. 22 at 3:18 a.m. EDT (0718 UTC) the VIIRS instrument aboard NASA-NOAA's Suomi NPP satellite provided a thermal image of Hurricane Maria north of Hispaniola and nearing the Bahamas.
The image showed highest coldest clouds around the eyewall and in bands of thunderstorms to the northeast and south and southeast of the center, stretching over Hispaniola and Puerto Rico.
Those clouder clouds have the capability of producing heavy rainfall.
At 5:04 a.m. AST/EDT the National Weather Service (NWS) in San Juan, Puerto Rico reported those bands of thunderstorms were still dropping heavy rain.
Satellite estimates indicate heavy rain over eastern Puerto Rico and heavier rain about to move into western Puerto Rico.
The heavy rain will cause flooding.
NWS noted "Some locations that are or will experience flooding include San Juan, Ponce, Arecibo, Yauco, Fajardo, Guayama, Coamo, Jayuya, Adjuntas, Santa Isabel, Canovanas, Sabana Seca, San Sebastian, Naranjito, Humacao, Mayaguez, San German, Lajas, Hatillo and Penuelas."
Flood warnings are in effect until 5:45 p.m. EDT today, Friday, September 22, 2017.
In hilly terrain there are hundreds of low water crossings which are potentially dangerous in heavy rain.
A visible image of Hurricane Maria was taken from NOAA's GOES East satellite on Sept. 22 at 10 a.m. EDT (1400 UTC) showed the storm just north of Turk Island and nearing the Bahamas.
The National Hurricane Center (NHC) reported "Maria is still producing 125-mph winds as it passes northeast of the Turks and Caicos Islands.
Both the Suomi NPP and GOES East images were created at NASA's Goddard Space Flight Center in Greenbelt, Md.
NOAA manages the GOES series of satellites and the NASA/NOAA GOES Project uses the data to create images and animations.
The Rapid Response Team at Goddard produces imagery from the Suomi NPP satellite.
A Hurricane Warning is in effect for Turks and Caicos Islands and the Southeastern Bahamas and a Tropical Storm Warning is in effect for the Central Bahamas.
At 11 a.m. EDT (1500 UTC), the eye of Hurricane Maria was located near 22.3 degrees north latitude and 71.0 degrees west longitude.
That's about 55 miles (90 km) north of Grand Turk Island, and 445 miles (715 km) east-southeast of Nassau.
Maria was moving toward the northwest near 8 mph (13 kph).
Data from an Air Force Reserve Hurricane Hunter aircraft indicate that maximum sustained winds remain near 125 mph (205 kph) with higher gusts.
Maria is a category 3 hurricane on the Saffir-Simpson Hurricane Wind Scale.
A gradual weakening is forecast during the next 48 hours.
The minimum central pressure based on data from the reconnaissance aircraft is 958 millibars.
NHC said a turn toward the north-northwest is expected later today, followed by a turn toward the north by late Saturday.
On the forecast track, Maria's core will move away from the Turks and Caicos Islands today, and pass northeast and east of the Bahamas through Sunday, Sept. 24.
###

For updated forecasts on Maria, visit: http://www.
By Rob Gutro

NASA's Goddard Space Flight Center
One of the few large studies to report long-term outcomes in cardiac patients treated in childhood with extracorporeal membrane oxygenation (ECMO) has found overall favorable outcomes among survivors, as reported by families.
ECMO provides short-term breathing and heart support for critically ill children while doctors treat the underlying illness.
A research team from Children's Hospital of Philadelphia (CHOP) published the ECMO study in the August 2017 issue of Pediatric Critical Care Medicine.
The team analyzed a cohort of 396 patients with cardiac disease treated with ECMO at CHOP from 1995 to 2012.
Overall mortality was 66 percent at a median follow-up of 6 years after ECMO therapy, which remains consistent with outcomes seen in previous decades.
In phone surveys or written surveys among the families of survivors, a majority reported positive outcomes regarding health and physical limitations.
Over 90 percent of families reported good or excellent health, and approximately 86 percent reported no or mild physical limitations.
However, the authors noted a discrepancy between family-reported favorable outcomes and a relatively high rate of medical and behavioral issues revealed by more detailed questioning.
Almost 25 percent of patients had below-average school performance and required special education, and almost 50 percent had parental-reported learning disabilities.
These results may help families define realistic expectations regarding long-term outcomes for children supported with ECMO due to an underlying cardiac condition.
Matthew D. Elias, MD, a pediatric cardiologist at CHOP and first author of the study, noted that ECMO use in children with congenital heart disease (CHD) has increased markedly over the past several decades, as increased experience in pediatric cardiology and cardiac surgery has allowed ECMO use to expand to more complex patients.
Senior author Matthew J. O'Connor, MD, also a CHOP pediatric cardiologist, added that "several factors have potentially improved long-term outcomes, such as increasing experience with ECMO and CHD in general.
But the inclusion of a more medically complex population in the recent era may mitigate these improvements in outcomes, accounting for the fact that overall mortality rates haven't changed much."
Although this single-center study represents one of the largest cohorts of ECMO patients undergoing detailed assessments of outcomes and quality of life, Elias said that further research in larger, multicenter studies should further investigate family experiences and long-term patient outcomes.
He added, "In the meantime, our findings should allow for improved family counseling in discussing long-term quality-of-life for children with heart disease."
###

The ECMO Center at Children's Hospital of Philadelphia recently received the "Platinum Level ELSO Award for Excellence in Life Support" from the Extracorporeal Life Support Organization (ELSO), an international consortium of centers offering ECMO (extracorporeal membrane oxygenation) for support of failing organ systems in infants, children and adults.
CHOP's ECMO Center has been recognized as an ELSO Center of Excellence since 2008.
The Platinum Level is the highest awarded honor, and is rarely achieved by ELSO member institutions, especially pediatric centers.
The ECMO Center at CHOP is the only ECMO center in the Philadelphia region designated by ELSO as a Platinum Center of Excellence, and is one of the most active in the country.
It has supported more than 1,300 patients since it was established in 1990.
The program's multidisciplinary team is comprised of pediatric surgeons, neonatologists, intensivists, anesthesiologists, perfusionists, specially trained nurses and respiratory therapists.
Matthew D. Elias, et al.
"Long-Term Outcomes of Pediatric Cardiac Patients Supported by Extracorporeal Membrane Oxygenation," Pediatric Critical Care Medicine, August 2017. http://doi.
org/ 10.
1097/ PCC.
0000000000001227
Jose continues to bring tropical storm conditions to southern New England although the storm has become post-tropical.
NASA's Terra satellite caught a view of the storm sitting almost stationary about 100 miles from Nantucket Island, Massachusetts.
On Sept. 21 at 11:25 a.m. EDT (1525 UTC), the MODIS instrument or Moderate Resolution Imaging Spectroradiometer aboard NASA's Terra satellite took a visible picture of Jose.
The image showed Jose's clouds in the northwestern quadrant continued sweep over southern New England, southeastern New York, and northeastern New Jersey.
Jose is a large storm and the clouds in its northeastern quadrant are just south of Nova Scotia, Canada.
Tropical-storm-force winds extend outward up to 220 miles (350 km) from the center.
Jose formed on Sept. 2 and has been around 20 days.
The National Hurricane Center issued their 68th advisory on Jose on Sept. 22.
A Tropical Storm Warning is in effect for Woods Hole to Sagamore Beach, including Cape Cod, Massachusetts, Block Island, Martha's Vineyard and Nantucket Island.
At 5 a.m. EDT, National Hurricane Center (NHC) forecaster Zelinsky noted "Since the last advisory, a small burst of deep convection has been observed near the center of Jose.
The cyclone is still embedded within a dry environment and located over cold sea surface temperatures, so it will be a little surprising if the convection is maintained for an extended period of time this morning."
NASA's Aqua satellite observed Jose in infrared light on Sept. 22 at 2:40 a.m. EDT (6:40 UTC) that provided temperatures.
The coldest clouds were the strongest storms.
The Moderate Resolution Imaging Spectroradiometer or MODIS instrument aboard NASA's Aqua satellite found two areas where cloud top temperatures were coldest and as cold as minus 50 degrees Fahrenheit (minus 45.5 degrees Celsius).
Those areas of coldest cloud tops and strongest storms were located in Jose's northeastern quadrant around the center of circulation and in a fragmented band of thunderstorms that stretched from New Jersey to western Massachusetts and northeast to southeastern Maine.
At 8 a.m. EDT (1200 UTC) on Sept. 22 the center of Post-Tropical Cyclone Jose was located near 39.7 degrees north latitude and 69.0 degrees west longitude.
That's about 115 miles (185 km) south-southeast of Nantucket, Massachusetts.
The post-tropical cyclone is moving slowly toward the west near 2 mph (4 kph).
Jose is expected to meander well off the coast of New England for the next several days.
Maximum sustained winds are near 50 mph (85 kph) with higher gusts.
Gradual weakening is forecast for the next 48 hours.
The estimated minimum central pressure is 993 millibars.
Minor coastal flooding is possible along portions of the coast of southern New England during the next few days.
Swells generated by Jose are affecting Bermuda and much of the U.S. east coast, and will likely cause dangerous surf and rip current conditions for the next couple of days in these areas

All of the dynamical models remain in good agreement that Jose will remain trapped in weak steering flow while gradually spinning down for the next several days.
Hearing loss, sometimes associated with other disorders such as balance defects, is the most common sensory deficit, affecting more than 280 million people worldwide, according to WHO.
In France, one child in 700 is born with severe or profound hearing loss, and one in every 1,000 will lose their sense of hearing before adulthood.
Over the past 20 years, scientists have made remarkable progress in deciphering the genetic origins of congenital hereditary hearing loss, which is usually caused by inner ear dysfunction.
The inner ear comprises the hearing organ or cochlea, together with the five balance organs (the saccule, utricle and three semicircular canals), which contain the sensory cells, or hair cells, that detect mechanical vibrations and convert them into electrical signals.
To date, mutations in more than 100 genes have been associated with inner ear defects, and it is estimated that mutations in more than 100 genes can cause genetic forms of deafness.
The various hereditary forms of hearing loss include Usher syndrome type 1 (USH1), a particularly severe clinical form of deaf-blindness, and specifically the USH1G genetic form.
USH1G patients are profoundly deaf and have no balance function at birth, and they subsequently suffer from prepubertal-onset sight loss leading to blindness.
USH1G syndrome is due to mutations in the gene encoding the scaffold protein sans, which is essential for the cohesion of the hair bundle of the inner ear hair cells.
Patients with hearing loss and balance dysfunction are currently fitted with auditory prostheses and may be given balance rehabilitation therapy, but the outcomes are variable.
One possible alternative for treating such hereditary inner ear defects is gene therapy.
This approach entails transferring a healthy (non-mutant) copy of the defective gene to restore the expression of the missing protein.
So far, gene therapy attempts have only resulted in partial improvements of hearing in mouse models of specific human deafness forms that did not include severe anomalies in hair cell structure.
In this context, scientists from the Institut Pasteur, Inserm, the CNRS, Collge de France, University Pierre et Marie Curie, and University Clermont Auvergne*, have now succeeded in restoring hearing and balance in a mouse model of USH1G syndrome using gene therapy.
With a single local injection of the USH1G gene just after birth, the scientists observed a restoration of the structure and mechanosensory function of the inner ear hair bundles - profoundly damaged before birth -, resulting in a long-term partial recovery of hearing, and complete recovery of vestibular function in these mice.
These results unexpectedly establish that inner ear defects due to major morphogenetic abnormalities of the hair bundle can be reversed even after birth, with durable efficacy, by gene therapy.
The scientists injected the USH1G gene into the inner ear using the innocuous AAV8 virus, which enabled them to specifically target the hair cells.
The expression of the therapeutic gene was detected 48 hours after injection.
The team demonstrated that a single injection to restore the production and localization of the missing protein in hair cells successfully improved hearing and balance functions in the young mice.
These findings suggest that the therapeutic protein was able to interact normally with its binding partners among the USH1 molecular complex (the proteins cadherin 23, protocadherin 15, myosin VIIA and harmonin), as required for the mechanoelectrical transduction apparatus of the hair bundle to function correctly.
As Saad Safieddine, CNRS Director of Research at the Institut Pasteur and co-senior author of the study with Prof. Christine Petit (head of the Genetics & physiology hearing unit at the Institut Pasteur), explains, "we have just shown that it is possible to partially correct a specific form of hereditary hearing loss accompanied by balance problems using local gene therapy performed after the embryogenesis of the ear, which is primarily affected by the mutation responsible for the disorder.
This suggests that the time window for effectively treating USH1 syndrome using gene therapy may be larger than initially thought."
This study represents a significant step towards the development of clinical trials in gene therapy for the curative treatment of hereditary deafness and balance loss in humans.
###

*From the Genetics & Physiology of Hearing Laboratory (Institut Pasteur/Inserm/UPMC), the Genes, Synapses and Cognition Laboratory (CNRS/Institut Pasteur, the Center for Neurophysics, Physiology and Pathology (CNRS/Paris-Descartes University), and the Sensory Biophysics Laboratory (University Clermont Auvergne).
Antibiotic resistance continues to grow around the world, with sometimes disastrous results.
Some strains of bacteria no longer respond to any currently available antibiotic, making death by infections that were once easily treatable a renewed reality.
Avoiding this fate is possible, research suggests, if antibiotic prescribers do five essential things correctly: Give the right patient the right medication at the right dose through the right route at the right time.
Medical residents -- doctors who have finished medical school but are still receiving training at clinics and hospitals by working under more experienced physicians -- are key to this strategy since they often are part of the frontline care team that selects and initiates antibiotic therapies.
However, it has been unclear whether their prescribing patterns match these five "rights," says Geovanny F. Perez, M.D., a pulmonologist at Children's National Health System.
"Residents often decide which antibiotics to start a patient on, so they could become the first line of defense against antibiotic resistance," Dr. Perez says.
"They also could be an important target for education efforts if their prescribing patterns aren't aligned with current guidelines."
To determine whether residents are prescribing in ways that best avoid antibiotic resistance, Dr. Perez and colleagues sent an email survey to all 189 residents at two large children's hospitals: Children's National, a tertiary care center that serves patients throughout the greater Metropolitan Washington area at its main campus and network of primary care clinics; and Nicklaus Children's Hospital, the largest freestanding pediatric hospital in South Florida.
The survey was divided into two parts.
The first aimed to assess the knowledge of these residents about which antibiotics are most appropriate to treat five common pediatric infections: Acute otitis media (ear infection), group A streptococcal pharyngitis (strep throat), sinusitis (sinus infection), pneumonia and urinary tract infections.
The second part of the survey was meant to ascertain how residents acquired their antibiotic knowledge and prescribing behaviors.
It asked about their awareness of antibiograms -- a profile of which medications are effective against different local bacterial strains that is updated periodically at most hospitals -- whether residents ever prescribed antibiotics for viral infections and the major influences on their prescribing decisions.
About one-half of the residents returned their surveys.
Their answers suggested that most of them followed prescribing guidelines for the recommended drugs to treat otitis media, streptococcal pharyngitis and urinary tract infections.
However, there were significant variations from guidelines for treating sinusitis and pneumonia, with many residents choosing antibiotics that were against current recommendations.
Additionally, only 3 percent of respondents indicated that they frequently used antibiograms, an important tool in selecting the most effective antibiotics.
About one-half indicated that they sometimes used antibiograms, and one-quarter said that they never used an antibiogram.
An additional 17 percent disclosed that they did not know what an antibiogram was.
Even among those that knew about this important resource, about one-half said that they didn't know where to access antibiograms specific to their hospitals.
Three-quarters of respondents indicated that they had prescribed antibiotics to patients who they considered to have a viral infection, rather than a bacterial one -- a scenario in which antibiotics have no effect.
In a follow-up question assessing the reasons for these decisions, 63 percent answered that they were following instructions from an attending physician or senior resident.
More experienced physicians also played a more general role in shaping residents' antibiotic knowledge: About 54 percent of residents said that their general pediatric inpatient attending physician--who oversees their training efforts -- was their most influential source of knowledge in this area.
The findings, published in the September 2017 issue of Hospital Pediatrics, provide eye-opening insights into how residents prescribe antibiotics and their motivations for these choices, says Dr. Perez -- particularly how the training they receive from mentors steers decisions many residents must make multiple times a day.
He adds that antibiotic stewardship programs, which provide instruction to health care providers about current prescribing guidelines and practices, should focus on both residents and their resident charges for maximum impact.
"Ideally, we should be matching the guidelines 100 percent or at least close to it," Dr. Perez says.
"We think this goal is definitely attainable with the right training for both residents and their mentors alike."
COLUMBUS, Ohio - New research led by The Ohio State University Wexner Medical Center found a potential therapeutic strategy to prevent infections in patients with spinal cord injuries.
This research using mice with spinal cord injuries breaks new ground in the development of treatments to prevent and reduce the incidence of infections without the use of antibiotics, and its results have been published online in the journal Nature Neuroscience.
The study builds on previous Ohio State-led research that found spinal cord injury causes the immune system to become "paralyzed," and thus less able to fight off infections such as pneumonia.
Pneumonia is the main cause of death in patients both after acute and chronic spinal cord injury.
Decreasing disability infections has a strong impact on the lives of people with spinal cord injury.
"Despite its clinical relevance, the underlying mechanisms of how spinal cord injury causes a systemic immune shut down are far from being understood.
After eight years of work, we were able to identify an entirely new mechanism for how spinal cord injury weakens the immune system," said principal investigator Dr. Jan M. Schwab, neurologist and physician at Ohio State's Neurological Institute, who collaborated with researchers from several institutes in Germany, along with the University of Alabama in Birmingham, Harvard Medical School and Boston's Children's Hospital.
Researchers demonstrated that susceptibility to spontaneous pneumonia and severe lymphopenia after spinal cord injury resulted from a maladaptive sympathetic-neuroendocrine reflex involving the adrenal glands.
Lymphopenia is an abnormally low level of lymphocytes or white blood cells that manage microbial host defense.
The identification of this two-stage pathological reflex arc - consisting of nerve pathways between the spinal cord and the adrenal glands, as well as a hormone-mediated link with the immune system - helps to deepen our understanding of the interconnections between the nervous and immune system.
The discovery of this 'immune system paralysis' and its underlying mechanisms represents an important step on the path to improving the treatment of spinal cord injury patients.
Rather than merely experiencing the more obvious symptom of motor-sensory paralysis, paraplegic patients also experience a paralysis of the immune system.
"Based on our findings, we hypothesize that therapeutic normalization of the glucocorticoid and catecholamine imbalance in spinal cord injury patients could be a promising treatment strategy," Schwab said.
"This could lead to new treatments to prevent or reduce infections in patients suffering with these injuries without antibiotics, thereby reducing disability and mortality."
Disrupting nerve fibers to the adrenal glands by high-level but not low-level thoracic spinal cord transection resulted in almost complete suppression of circulating norepinephrine levels and profound stimulation of systemic corticosterone levels.
Identical findings were seen in human patients with traumatic complete spinal cord injury, researchers wrote.
Given that infections are highly prevalent in spinal cord injured patients, orthodox antibiotic treatments start to lose their effectiveness with time due to the development of resistances.
###

The research team included members from Charit - Universitatsmedizin Berlin and German Center for Neurodegenerative Diseases, both in Germany, and the National Spinal Cord Injury Statistical Center at the University of Alabama at Birmingham.
The study received funding from the German Academic Exchange Service, German Research Foundation, Wings for Life Spinal Cord Research Foundation, Else Krner Fresenius Sifting, German legal accident insurance, the Era-Net-NEURON Program of the European Union, The Ohio State University Discovery Theme and the W.E.
Hunt & C.M.
Curtis Endowment to Jan M. Schwab.
The National Spinal Cord Injury Database is funded by the National Institute on Disability, Independent Living and Rehabilitation Research, U.S. Department of Health and Human Services.
Researchers have presented the first report of a new microfluidics-based approach for detecting circulating cancer biomarkers in blood samples

Future Science Group (FSG) today announced the publication of an article in Future Science OA presenting early data from a novel assay for the non-invasive detection of PD-L1 and other biomarkers in patient blood samples.
Response rates to immunotherapies targeting the PD-1 pathway vary, and efforts are ongoing to improve the discovery of those who will and will not benefit from such therapies.
Expression of PD-L1, among other biomarkers, is associated with response; however, owing to tumor heterogeneity and the fact this biomarker is not static, biopsies are not suitable.
Furthermore, biopsies are invasive and unsuitable for repeated testing.
Novel research from an international team led by Jinkai Teo (Merck Research Laboratories, Singapore) sought to solve this problem using peripheral blood samples, and a less-invasive approach.
Whole blood from both healthy donors and breast cancer patients underwent circulating tumor cell enrichment and was loaded onto a microfluidic chip, undergoing chipcytometry.
The results demonstrated that the workflow had a mean detection rate of 22.8%, and could determine PD-L1 and PD-L2 expression levels.
"We believe the main advantages of chipcytometry lie in the iterative staining process that allows retrospective evaluation of additional markers and the potential to measure a large number of parameters without the spillover/compensation problems encountered with flow cytometry," commented the authors.
"This approach allows the analysis of additional immunomodulatory targets on tumor cells beyond PD-L1 and PD-L2, which is particularly critical, considering high dimensional analysis of these markers is likely to become increasingly relevant as immunotherapy moves beyond the administration of single immunomodulatory agents toward combinations that synergize in their antitumor immune response."
Furthermore, the potential to include more positive or negative markers could allow increased confidence that identified cells are CTCs.
However, the authors note that these data are preliminary, and further experimentation is needed to fully establish feasibility of the approach.
###

Available from: https:/ / www.
future-science.
com/ doi/ 10.
4155/ fsoa-2017-0079

About Future Science OA

Launched in March 2015, Future Science OA is the inaugural gold open access journal from Future Science Group.
It publishes articles covering research of application to human health, and utilizes a CC-BY license.
Future Science OA embraces the importance of publishing all good-quality research with the potential to further the progress of medical science.
Both negative and early-phase research is considered.
The journal also features review articles, editorials and perspectives, providing readers with a leading source of commentary and analysis.
More open access oncology research can be found at https:/ / www.
future-science.
com/ journals/ fso/ category/ oncology

About Future Science Group
"It can be considered an instance of 'embodiment' in which our brain interacts with our body".
This is the comment made by Raffaella Rumiati, neuroscientist at the International School for Advanced Studies - SISSA in Trieste, on the results of research carried out by her group which reveals that the way we process different foods changes in accordance with our body mass index.
With two behavioural and electroencephalographic experiments, the study demonstrated that people of normal weight tend to associate natural foods such as apples with their sensory characteristics such as sweetness or softness.
On the other hand, processed foods such as pizzas are generally associated with their function or the context in which they are eaten such as parties or picnics.
The results are in line with the theory according to which sensory characteristics and the functions of items are processed differently by the brain, comments Giulio Pergola, the work's primary author.
They represent an important step forward in our understanding of the mechanisms at the basis of the assessments we make of food.
But that's not all.
Recently published in the Biological Psychology journal, the research also highlighted the ways in which underweight people pay greater attention to natural foods and overweight people to processed foods.
Even when subjected to the same stimuli, these two groups show different electroencephalography signals.
These results show once again the importance of cognitive neuroscience also in the understanding of extremely topical clinical fields such as dietary disorders.
###

USEFUL LINK:
Fifty years ago, scientists discovered that the Earth is occasionally hit by cosmic rays of enormous energies.
Since then, they have argued about the source of those ultra-high energy cosmic rays -- whether they came from our galaxy or outside the Milky Way.
The answer is a galaxy or galaxies far, far away, according to a report published Sept. 22 in Science by the Pierre Auger Collaboration.
The internationally run observatory in Argentina, co-founded by the late University of Chicago Nobel laureate James Cronin, has been collecting data on such cosmic rays for a more than a decade.
The collaboration found that the rate of such cosmic particles, whose energies are a million times greater than that of the protons accelerated in the Large Hadron Collider, is about six percent greater from one side of the sky than the other, in a direction where the distribution of galaxies is relatively high.
"We are now considerably closer to solving the mystery of where and how these extraordinary particles are created -- a question of great interest to astrophysicists," said University of Wuppertal Prof. Karl-Heinz Kampert, spokesperson for the Auger Collaboration, which involves more than 400 scientists from 18 countries.
"Our observation provides compelling evidence that the sites of acceleration are outside the Milky Way."
Cosmic rays are the nuclei of elements from hydrogen to iron.
The highest-energy cosmic rays, those of interest in this study, only strike about once per square kilometer per year -- equivalent to hitting the area of a soccer field about once per century.
Such rare particles are detectable because they create showers of secondary particles -- including electrons, photons and muons--as they interact with the nuclei in the atmosphere.
These cosmic ray showers spread out, sweeping through the atmosphere at the speed of light in a disc-like structure, like a dinner plate but several kilometers in diameter.
At the Auger Observatory, the shower particles are detected through the light they produce in several of 1,600 detectors, spread over 3,000 square kilometers of western Argentina -- an area comparable to that of Rhode Island -- and each containing 12 tons of water.
Tracking these arrivals tells scientists the direction from which the cosmic rays came.
After racking up detections of more than 30,000 cosmic particles, the Auger Collaboration found one section of the sky was producing significantly more than its share.
The probability of this happening by a random fluctuation is extremely small, the collaborators said: a chance of about two in ten million.
"This result unequivocally establishes that ultra-high energy cosmic rays are not just random wanderers of our nearby universe," said Paolo Privitera, UChicago professor in astronomy and astrophysics, who heads the U.S. groups participating in the project.
Privitera credited Cronin, who died last year, with the original vision for the Auger observatory back in 1992.
"The imprint detected in their arrival directions -- a tantalizing evidence for extragalactic origin -- required several years of observations with a detector working, in Jim Cronin's words, 'like a Swiss clock.'
It was a tribute to Jim's vision to build an observatory and unveil the mystery of the origin of the most energetic particles in the universe," he said.
Even at these high energies, cosmic rays may be significantly deflected by magnetic fields in outer space; thus the excess found by the Auger Collaboration in a broad section of the sky cannot yet determine which extragalactic objects might be the specific sources, the authors said.
The observatory is looking to examine even higher-energy cosmic rays -- rarer, but less likely to be deflected -- which may provide a clearer route to their sources.
Work on this problem is targeted for the observatory's upgrade, scheduled to be completed in 2018.
###

Citation: "Observation of a Large-scale Anisotropy in the Arrival Directions of Cosmic Rays above 81018 eV."
Science, Sept. 22, 2017.
New Rochelle, NY, Sept. 22, 2017 -- Researchers added a scaffold/matrix attachment region (S/MAR) to a conventional adeno-associated virus (AAV) vector used for gene transfer, and the modified vectors were able to establish colonies and maintain long-term transgene expression in HeLa cells, as reported in Human Gene Therapy, a peer-reviewed journal from Mary Ann Liebert, Inc., publishers.
The article is available free on the Human Gene Therapy website until October 22, 2017.
Hildegard Bning, PhD, Hannover Medical School, Germany and colleagues from University of Witten/Herdecke and University of Cologne, University Hospital Cologne, and German Center for Infection Research, Germany, and Cairo University, Egypt coauthored the article entitled " S/MAR Element Facilitates Episomal Long-Term Persistence of Adeno-Associated Virus Vector Genomes in Proliferating Cells."
This novel approach, if applicable in other cell types, could help overcome the limitation of being able only to use AAV vectors for gene transfer to proliferating cells.
In an unexpected finding, the researchers also showed that even AAV vectors lacking the S/MAR element were able to establish stable transgene-expressing colonies in HeLa cells.
"AAV vectors have so far been most useful in terminally differentiated cells, like neurons and photoreceptor cells, but this advance could greatly expand the utility of AAV vectors in actively dividing cells," says Editor-in-Chief Terence R. Flotte, MD, Celia and Isaac Haidak Professor of Medical Education and Dean, Provost, and Executive Deputy Chancellor, University of Massachusetts Medical School, Worcester, MA.
###

About the Journal

Human Gene Therapy, the Official Journal of the European Society of Gene and Cell Therapy, British Society for Gene and Cell Therapy, French Society of Cell and Gene Therapy, German Society of Gene Therapy, and five other gene therapy societies, is an authoritative peer-reviewed journal published monthly in print and online.
Led by Editor-in-Chief Terence R. Flotte, MD, Celia and Isaac Haidak Professor of Medical Education and Dean, Provost, and Executive Deputy Chancellor, University of Massachusetts Medical School, Human Gene Therapy presents reports on the transfer and expression of genes in mammals, including humans.
Related topics include improvements in vector development, delivery systems, and animal models, particularly in the areas of cancer, heart disease, viral disease, genetic disease, and neurological disease, as well as ethical, legal, and regulatory issues related to the gene transfer in humans.
Its companion journals, Human Gene Therapy Methods, published bimonthly, focuses on the application of gene therapy to product testing and development, and Human Gene Therapy Clinical Development, published quarterly, features data relevant to the regulatory review and commercial development of cell and gene therapy products.
Tables of contents for all three publications and a free sample issue may be viewed on the Human Gene Therapy website.
About the Publisher

Mary Ann Liebert, Inc., publishers is a privately held, fully integrated media company known for establishing authoritative peer-reviewed journals in many promising areas of science and biomedical research, including Nucleic Acid Therapeutics, Tissue Engineering, Stem Cells and Development, and Cellular Reprogramming.
Its biotechnology trade magazine, GEN (Genetic Engineering & Biotechnology News), was the first in its field and is today the industry's most widely read publication worldwide.
A complete list of the firm's 80 journals, books, and newsmagazines is available on the Mary Ann Liebert, Inc., publishers website.
Scientists confirm that the age and content of an old sack is in accordance with a medieval myth about Saint Francis of Assisi.
For more than 700 years the Friary of Folloni near Montella in Italy has protected and guarded some small fragments of textile.
According to the legend the textile fragments originate from a sack that appeared on the doorstep of the friary in the winter of 1224 containing bread sent from Saint Francis of Assisi, who at that time was in France.
The bread was allegedly brought to the friary by an angel.
Ever since that cold winter's night the sack has been guarded by the friary, and today the last few remaining fragments are kept as a relic in a well protected shrine.
In line with the legend

A Danish/Italian/Dutch team of reseachers led by Associate Professor Kaare Lund Rasmussen from University of Southern Denmark has had the opportunity to conduct scientific studies of the alleged bread sack fragments.
Their study is published in the journal Radiocarbon.
C-14 analysis revealed that the textile can be dated to 1220-1295.
The age is in line with the legend, says Kaare Lund Rasmussen, a chemist, and specialized in archaeo-chemical analyses.
There was probably bread in the sack

The researchers also looked for traces of bread in the textile.
They did this by looking for ergosterol, a sterol for the fungal kingdom and encountered in several types of mould.
Ergosterol can be a potential biomarker for brewing, baking or agriculture.
Our studies show that there was probably bread in the sack.
We don't know when, but it seems unlikely that it was after 1732, where the sack fragments were inmured in order to protect them.
It is more likely that bread was in contact with the textile in the 300 years before 1732; a period, where the textile was used as altar cloth -- or maybe it was indeed on the cold winter's night in 1224 -- it is possible, says Rasmussen.
Scientific measurements cannot prove a legend or belief.
What they can do, is either to de-authenticiate the object or show accordance between the physical/chemical evidence and the legend, say the researchers in their paper, published in the journal Radiocarbon.
Belief versus science

The researchers have not addressed the issue of how the bread sack ended up on the doorstep of the friary.
This is maybe more a question of belief than science, says Rasmussen.
The bread sack: According to legend the bread sack miraculously appeared on the doorstep of the friary in 1224.
For 300 years it was used as an altar cloth.
During this time pieces were cut off and given to other religious institutions in Italy.
After an earthquake in 1732 a new friary was built and the remaining sack fragments were inmured.
I 1807 the fragments were moved to the main church, Santa Maria del piano.
In 1817 half of the textile was returned to the friary.
In 1999 the remaining half returned.
Today the fragments of the textile are kept in a reliquary.
###

Kaare Lund Rasmussen is a chemist.
He often uses his expertise for solving archaeological mysteries.
He has been involved in investigating the dead sea scrolls, the death of Renaissance astronomer and alchemist Tycho Brahe and skeletons from cemeteries in Denmark, Germany and Italy.
Beginning models should choose independent magazines in order to be successful in the fashion industry, but they should also keep in mind that the fashion business is becoming increasingly closed off every year.
This is one of the conclusions drawn by Margarita Kuleva, Research Fellow at the Centre for Youth Studies, HSE St. Petersburg, and her student, Daria Maglevanaya.
They plan to present the results of their study at the 9th International Conference on Social Informatics (SocInfo 2017), which will take place in Oxford in September.
Margarita Kuleva and Daria Maglevanaya studied the evolution of status groups in the fashion industry and published the results of this research in their paper 'The Dynamics of Professional Prestige in Fashion Industries of Europe and the US: Network Approach'.
They looked at this from the perspective of collaboration between models and journals.
The models.com website served as the source for the study.
Their analysis included 13,961 covers of 106 fashion and lifestyle magazines dating from 1975 to January 2017.
In their study, the authors noticed a decreasing level of collaboration between magazines.
In comparison with earlier years, fewer and fewer new models appear on the covers of the same magazines.
This is likely a sign of a decline in the magazine industry and the growing popularity of new media, such as fashion blogs.
This trend is causing the fashion world to become more closed off.
Year by year, it is becoming more difficult for beginning models who lack significant amounts of human capital and haven't had time to achieve a certain status in fashion and gain recognition.
Kuleva and Maglevanaya also note the probable diversification of beauty standards in the fashion industry.
They conclude this from the fact that magazines are increasingly showcasing models who are older, plus-size and have unusual appearances.
The researchers refer to studies by Pierre Bourdieu, a French sociologist who looks at prestige as symbolic capital as part of capital theory.
Bourdieu said that in a creative market, participants who have the most prestige are the most successful.
'We can talk about the Dazed & Confused magazine, which is a trendsetter, and about Marie Claire and Cosmopolitan, which offer a wide and simple snapshot of the lifestyle industry', explains Margarita Kuleva.
The study says that some models are ready to appear in Dazed & Confused for a small fee, or even for free in a more unconventional magazine.
But these very models are more likely to achieve prestige and appear on a Vogue cover than those who work for Cosmopolitan or Marie Claire, earning higher pay and broader recognition, but less cultural capital.
'Surprisingly enough, the models' world turned out to be much like less commercialized areas such as classical music or visual arts', she added.
The scholars also confirmed the theory that the world of arts is like a sand pile: those who climb the sand pile change the shape of the pile, meaning that the indicators of prestige change together with the players who shape the field.
The researchers investigated the Western model market, including most European and American magazines, as well as several from Asia.
They are not yet able to say how their conclusions relate to Russia.
HSE experts are planning to carry out further research, especially on such parts of the fashion industry as participation in shows and special projects.
When the strong winds that circle the Arctic slacken, cold polar air can escape and cause extreme winter chills in parts of the Northern hemisphere.
A new study finds that these weak states have become more persistent over the past four decades and can be linked to cold winters in Russia and Europe.
It is the first to show that changes in winds high up in the stratosphere substantially contributed to the observed winter cooling trend in northern Eurasia.
While it is still a subject of research how the Arctic under climate change impacts the rest of the world, this study lends further support that a changing Arctic impacts the weather across large swaths of the Northern Hemisphere population centers.
"In winter, the freezing Arctic air is normally 'locked' by strong circumpolar winds several tens of kilometers high in the atmosphere, known as the stratospheric polar vortex, so that the cold air is confined near the pole," says Marlene Kretschmer from PIK, lead-author of the study to be published in the Bulletin of the American Meteorological Society.
"We found that there's a shift towards more-persistent weak states of the polar vortex.
This allows frigid air to break out of the Arctic and threaten Russia and Europe with cold extremes.
In fact this can explain most of the observed cooling of Eurasian winters since 1990."
Warm Arctic, cold continents

Despite global warming, recent winters in the Northeastern US, Europe and especially Asia were anomalously cold - some regions like Western Siberia even show a downward temperature trend in winter.
In stark contrast, the Arctic has been warming rapidly.
Paradoxically, both phenomena are likely linked: When sea-ice North of Scandinavia and Russia melts, the uncovered ocean releases more warmth into the atmosphere and this can impact the atmosphere up to about 30 kilometers height in the stratosphere disturbing the polar vortex.
Weak states of the high-altitude wind circling the Arctic then favors the occurrence of cold spells in the mid-latitudes.
Previous work by Kretschmer and colleagues identified this causal pathway in observational data and it is further supported by several climate computer simulation studies.
"Our latest findings not only confirm the link between a weak polar vortex and severe winter weather, but also calculated how much of the observed cooling in regions like Russia and Scandinavia is linked to the weakening vortex.
It turns out to be most," says co-author Judah Cohen from Atmospheric and Environmental Research/Massachusetts Institute of Technology (US).
"Several types of weather extremes are on the rise with climate change, and our study adds evidence that this can also include cold spells, which is an unpleasant surprise for these regions."
The effect is stronger over Asia and Europe than over the US.
"Circulation patterns drive our weather"

"It is very important to understand how global warming affects circulation patterns in the atmosphere," says co-author Dim Coumou from Vrije Universiteit Amsterdam, Netherlands.
"Jet Stream changes can lead to more abrupt and surprising disturbances to which society has to adapt.
The uncertainties are quite large, but global warming provides a clear risk given its potential to disturb circulation patterns driving our weather - including potentially disastrous extremes."
###

Article: Marlene Kretschmer, Dim Coumou, Laurie Agel, Mathew Barlow, Eli Tziperman, Judah Cohen (2017): More frequent weak stratospheric polar vortex states linked to cold extremes.
Bulletin of the American Meteorological Society.
[DOI: 10.1175/BAMS-D-16-0259.1]
An international collaboration involving the Earlham Institute, Norwich, UK, and the Iwate Biotechnology Research Centre, Japan, has for the first time provided a genome sequence for the white Guinea yam, a staple crop with huge economic and cultural significance on the African continent and a lifeline for millions of people.
Yams are a staple part of the Nigerian diet, with Nigeria accounting for around 70% of world yam production, but at current rates of consumption demand is beginning to outstrip supply of this economically important crop with huge cultural significance.
Deciphering the yam genome is of vital importance because, unlike other staple crops such as wheat, maize and rice, the crop is relatively undomesticated.
Domesticated crops have advantages compared to their wild relatives when it comes to farming them, including easier usability and higher yields.
Understanding the genomics of this crucial plant will help farmers increase yields and sustainability of yams.
The novel research entitled "Genome sequencing of the staple food crop white Guinea yam enables the development of a molecular marker for sex determination," is openly accessible in the journal BMC Biology, shows just how that can be made possible.
The high quality draft genome sequence is available in the public databases DDBJ and NCBI.
The big breakthrough from an international collaboration of institutes spanning the UK, Germany, Japan and Nigeria, has been in identifying the regions of the genome that determine sex in yams (dioecy), and knowledge of this rare feature is vital for improving the speed of marker-assisted breeding projects.
Dioecy, plants having separate males and females, is relatively rare and occurs only in about 5-6% of flowering plants, including yams and asparagus.
Therefore, understanding the process in yams could help in improving other economically important crops.
Most importantly for Central and West Africa, this new knowledge will help transform yams from being a neglected "orphan" crop.
With assisted breeding programmes, the crop can be better domesticated, boosting food security and economic well-being in an area undergoing the world's most rapid population expansion.
Benjamen White, who led Earlham Institute's contribution, said, "Having a reference sequence for the white Guinea yam gives us the unique opportunity to gain a better understanding of dioecy, a very rare trait in flowering plants, in a species that's very evolutionarily differentiated from most of what's been sequenced so far.
Understanding this trait and having a genomic resource for white Guinea yam will be invaluable in breeding a better yam, one that will improve food security in West and Central Africa, and the livelihood of smallholder farmers there."
Dr. Robert Asiedu, Director, Research for Development, for The International Institute of Tropical Agriculture-West Africa, Ibadan, Nigeria, said, "This is an important breakthrough.
It means that yam has joined those crops with a full DNA sequence, a development which started with rice some years ago.
The implications are profound.
The full DNA sequence will greatly facilitate our understanding of the genetic control of key traits such as flowering, diseases, and others including quality traits, and this in turn will make the breeding of new varieties both faster and more precise".
Professor Ryohei Terauchi, lead author, of Kyoto University and Iwate Biotechnology Research Centre, Japan, said, "This will help to overcome some of the many challenges facing yam farmers in Africa and other parts of the world.
These include pests and diseases, post-harvest losses and the need to develop more sustainable systems of farming for the crop".
###

Notes to Editors

The international collaboration featured various institutes throughout the United Kingdom, Germany, Japan and Nigeria.
In order of authors on the paper: Iwate Biotechnology Research Centre, Kitakami, Japan; The Earlham Institute, Norwich, UK; Kobe University, Kobe, Japan; Okinawa Agricultural Research Centre, Okinawa, Japan; Shinshu University, Nagano, Japan; Tokyo University of Agriculture, Tokyo, Japan; Japan International Research Centre for Agricultural Sciences, Tsukuba, Japan; International Institute of Tropical Agriculture, Ibadan, Nigeria; Kyoto Sangyo University, Kyoto, Japan; The Sainsbury Laboratory, Norwich, UK; University of Frankfurt, Frankfurt, Germany; Kyoto University, Kyoto, Japan.
Further facts of interest:

West and Central Africa, the main region for yam production worldwide, contributed approximately 96% of the 63 million tons of yam produced globally in 2013.
The value of yam production exceeds all other African staple crops and is worth more than maize, rice and sorghum, combined.
Nigeria is set to become the third largest country in the world by 2050, with a population of over 300 million, surpassing the US.
It is vital we work on breeding improved crops to help feed these and the other 9 billion people expected in 2050.
Yam cultivation is constrained by many factors.
Seeds are not often used as starting materials; instead, yams are commonly propagated clonally using small whole tubers (referred to as "seed yams") or tuber pieces.
Yams are also highly vulnerable to a plethora of pests and diseases that can reduce yields by as much as 90%.
There are 600 odd species of yam and 10 have been independently domesticated in West Africa, Southeast Asia, and the Pacific and Caribbean islands.
Yam tubers can grow to over 1.5 m and weight 70 kg.
In June 2017, Nigeria began exporting certified yam to the UK and US for the first time.
Further technical detail:

The study identified the genomic region associated with sex in yams, found yam sex to be to be female heterogametic (male=ZZ, female=ZW), and developed a molecular marker for sexing yams at the seedling stage.
Phylogentic analysis also showed yam to likely have a unique lineage within the monocots.
Sequencing of the 594 Mb genome was carried out using the Illumina MiSeq and HiSeq 2500 platforms, using mate-pair, BAC-end, paired-end and RAD-tag libraries.
Assembly was done using the ALLPAHTS-LG pipeline and a linkage-map was used to anchor the scaffolds into pseudo-molecules.
Whether or not we consciously perceive the stimuli projected onto our retina is decided in our brain.
A recent study by the University of Bonn shows how some signals dissipate along the processing path to conscious perception.
This process begins at rather late stages of signal processing.
By contrast, in earlier stages there is hardly any difference in the reaction of neurons to conscious and unconscious stimuli.
The paper is published in Current Biology.
The researchers are basing their study on a well-known phenomenon: When presented with two images in rapid succession, humans can only consciously perceive the second one if there is sufficient time between the two presentations.
In this study the participants saw a series of pictures on a computer screen, where each image was presented for just over one tenth of a second.
Before each series the participants were instructed to pay special attention to two target stimuli, and they were asked if those images were part of the series afterwards.
"We varied the time between the two attended images," explained Dr. Thomas P. Reber, one of the authors.
"Sometimes they were presented directly one after the other, and sometimes there was one or even several images between them.
Whenever both target stimuli were presented in close succession, participants reported in a little under half of the cases to only have seen the first one.
This allowed us to compare conscious and unconscious processing of identical picture presentations."
A look inside the epileptic brain

Reber works in the Department of Epileptology at the University Hospital of Bonn - one of the biggest epilepsy centers in Europe.
Among its patients are severe cases of so-called medial temporal lobe epilepsy.
A last resort for them can be the removal of brain tissue triggering epileptic seizures.
In some cases, electrodes are implanted into the patient's brain to localize the epileptic focus for later resection.
As a byproduct, researchers can make use of this circumstance to virtually 'watch' the patients think.
This was also the case during the latest study - the 21 participants were all epilepsy patients with special microelectrodes implanted in the temporal lobe.
"That way we were able to measure the reaction of single nerve cells to visual stimuli," explains Dr. Florian Mormann, Professor of Cognitive and Clinical Neurophysiology.
"We wanted to investigate how the processing of images differs depending on whether they have been perceived consciously or not."
Seen: Yes.
Consciously perceived: No.
When an image is projected onto the retina, the respective information is transmitted along the optic nerve to the so-called visual cortex at the back of the skull.
From here the signal branches out and part of it is projected back towards the forehead.
The measurements show how the electric impulses change along this pathway.
"In the back part of the temporal lobe, where the earlier processing steps take place, there are hardly any differences between consciously and unconsciously processed images", says Dr. Reber.
"The distinction of 'conscious' and 'unconscious' follows significantly further down the processing stream than many researchers have been suspecting: On their way to the frontal areas of the temporal lobe, the impulses in response to unconsciously perceived images weaken, and they occur with an increasing delay."
The eye registers an image and generates a corresponding signal.
However, in some cases this signal seems to be "disintegrating" before reaching the viewer's consciousness, in this case resulting in the patient not perceiving the image.
"It is remarkable," says Reber, "We can show that the patient has been presented with a certain image -- even if they have no conscious perception of it."
This basic research paper provides new insights on the border between conscious and unconscious perception.
###

Publication: Thomas P. Reber, Jennifer Faber, Johannes Niediek, Jan Bostrm, Christian E. Elger, Florian Mormann: Single-neuron correlates of conscious perception in the human medial temporal lobe; Current Biology; DOI: 10.1016/j.cub.2017.08.025

Contact:

Prof. Dr. Dr. Florian Mormann

Klinik fr Epileptologie

Universittsklinikum Bonn

Tel.
0228/28715738

eMail: fmormann@yahoo.de

Dr. Thomas Reber

Klinik fr Epileptologie

Universittsklinikum Bonn

Tel.
0228/28715742

eMail: treber@live.com
Tracing the history of individual cells in the developing organism can reveal functional differences among seemingly uniform cells.
This knowledge is important for defining the characteristics of highly regenerative cells in order to target them for cellular therapies, as well as to prevent the formation of unfit cells, which compromise the overall health of the organism.
The study introduced here presents a new method for tracing the history of -cells, which perform the essential function of secreting insulin in response to glucose.
The authors traced -cells with regards to their proliferation, function and time of differentiation in the zebrafish.
The study shows that -cells with different developmental histories co-exist together, which leads to the formation of dynamic sub-populations that differ in their potential for undergoing proliferation and performing functional tasks.
The study also reveals the onset of -cell function in zebrafish, which opens new avenues to investigate how -cells acquire a functional state using this powerful genetic model.
Recently, the heterogeneity among -cells has become evident, and it is believed that this heterogeneity might play a role in the progression of diabetes.
"For example, even 20 years after the onset of Type 1 diabetes, some -cells can survive in the pancreas, perhaps because these cells are different from the rest, which allows them to hide from the immune system and to escape autoimmune destruction", Nikolay Ninov says.
The ability to directly visualize the evolution of -cell heterogeneity in zebrafish will help to understand the dynamic regulation of -cell sub-populations at the molecular level.
This knowledge is of crucial importance for the subsequent development of effective strategies for -cell regeneration and protection in diabetes.
"As a next step, we will use our model and cell tracing methods to understand the signals that instruct -cells to acquire a functional state.
In particular, we found that in zebrafish this process takes only a few days after the birth of the cells, whereas it is difficult to achieve the formation of functional -cells from human stem cells in vitro.
Thus, our hypothesis is that the in vivo environment in the zebrafish pancreas provides powerful signals for rapid -cell functional maturation.
We will now identify these signals, as this knowledge can help to produce functional human -cells in vitro for transplantation purposes", Nikolay Ninov explains.
The project, which was envisioned about 3.5 years ago, was led by CRTD Postdoc Sumeet Pal Singh.
In addition, Sharan Janjuha (PhD-student, DIGS-BB) established the assay for calcium imaging.
Additional researchers include collaborators from Japan (Daiichi Sankyo Co.,Ltd), the UK (Oxford University) and Germany (CRTD).
"Curiosity, and the drive to make an original contribution towards a cure for diabetes by learning more about the basic biology of -cells" motivates Nikolay Ninov in his daily work.
Since 2013 Nikolay Ninov has been a Group Leader for "-cell biology and regeneration" at the CRTD and the Paul Langerhans Institut Dresden (PLID) of Helmholtz Zentrum Mnchen at University Hospital Dresden and Medical Faculty Carl Gustav Carus of TU Dresden - a partner of the German Center for Diabetes Research (DZD).
In 2008, Nikolay Ninov completed his PhD at the University of Barcelona (Spain, Parc Cientific de Barcelona).
After that he worked as a Postdoc at the University of Toronto (Canada, Department of Cell and Systems Biology, 2008-2009), the University of California at San Francisco (USA) and the Max Planck Institute for Heart and Lung Research in Bad Nauheim (Germany) (2009-2013).
###

Publication

Title: Different developmental histories of beta-cells generate functional and proliferative heterogeneity during islet growth

DOI: 10.1038/s41467-017-00461-3
Researchers from the People's Friendship University of Russia (RUDN University) have studied the mechanism of drug resistance for ovarian and breast cancer cells.
They discovered that these cancer cells have redox-dependent mechanism which is tasked with sustaining their drug resistance.
The results have been published in two articles in the journal of Free Radical Biology and Medicine.
Researchers from the RUDN University have found out one of reasons why chemotherapy (in particular, cisplatin) gradually stops affecting the cells of ovarian and breast tumors.
The authors study the biochemical mechanisms which allow tumor cells to develop resistance to antitumor drugs.
During chemotherapy, when using certain drugs, the tumor cells are affected by toxic and oxidative stress, which stop their functioning.
Sometime later, however, the cells "get used" to the drug action, which necessitates using stronger doses of the drug, which, in turn, negatively affects the patient's organism due to its toxic effect.
To stop the development of drug resistance, researchers need to learn operating the expression (the process of transferring hereditary information from DNA) of genes that control the cell viability.
Many mechanisms allow it, including the redox processes which regulate, in particular, the cell antioxidant defense, which protects the cell against oxidative stress so that it could function properly.
Without those "defender genes", it would be far easier for drugs to kill cancer cells.
The researchers hope that the process could eventually be controlled.
Some of these genes' expression changes happen when human ovarian cancer (SKOV-3) cells and human breast cancer (MCF-7) cells develop resistance to an antitumor drug, cisplatin.
Antitumor action of cisplatin is achieved in no small part by its pro-oxidant effect, meaning that it uses oxidative stress to destroy cells.
"As a result of development of the drug resistance in cancer cells, it was observed an increase in the gene expression encoding isoforms of thioredoxin and peroxiredoxin, which play an important role in the antioxidant defense system and the redox-dependent signaling.
Significant increase in expression of such genes substantially contributes to forming a high level of antioxidant defense under development of cancer cell resistance to pro-oxidant action of cisplatin.
Thus, the growth of expression of the Prx6 gene was observed in the resistant cells.
The data obtained also points to a significant role of Prx1, Prx2 and Prx3 isoforms in the redox-dependent mechanisms of the resistance development of the cell lines", - Elena Kalinina, one of the article's authors, D.Sc., professor of T.T.
Berezov Department of Biochemistry (RUDN University Institute of Medicine), told us.
The increase in gene expression points to the fact that isoforms of thioredoxin and peroxiredoxin participate in the development of cancer cell drug resistance.
The researchers note that this effect can also be considered as a part of a redox-dependent adaptive antioxidant response to the oxidative stress caused by cisplatin's pro-oxidant action.
"The results obtained significantly expand our fundamental knowledge of the sum total of molecular events in the mechanisms of death and formation of drug resistance for cancer cells and of the role redox-dependent systems in these processes" - Elena Kalinina concluded.
These results, obtained by the researchers, in the future will enable us to improve the drug treatment programs for oncology patients.
Textiles represent one of the earliest human craft technologies and applied arts, and their production would have been one of the most important time, resource and labour consuming activities in the ancient past.
In archaeological contexts, textiles are relatively rare finds, especially in Mediterranean Europe where conditions are unfavourable for organic material preservation.
Many archaeological textile fragments do, however, survive in mineralised form, which forms the basis of a new study published today in Antiquity.
Detailed analysis of several hundred textile fragments has provided, for the first time, a much more detailed definition of the textile cultures in Italy and Greece during the first half of the first millennium BC.
According to Dr Margarita Gleba, the study's author and researcher at the McDonald Institute for Archaeological Research, University of Cambridge, "Luckily for us, during the Iron Age (c. 1000-400 BC) people were buried with a lot of metal goods such as personal ornaments, weapons and vessels.
These metals are conducive to the preservation of textiles as the metal effectively kills off the micro-organisms which would otherwise consume the organic materials, while at the same time metal salts create casts of textile fibres, thereby preserving the textile microstructure."
"This is how we get such a large number of textiles, even though they only exist now in tiny fragments.
Through meticulous analysis using digital and scanning electron microscopy, high performance liquid chromatography and other advanced methods we are able to determine a lot of information including the nature of the raw materials and structural features such as thread diameter, twist direction, type of weaving or binding, and thread count."
The technical differences suggest that during the Iron Age, textiles in Italy more closely resembled those found in Central Europe (associated with the Hallstatt culture that was prevalent in modern-day Germany, Austria and Slovenia) while the textile culture of Greece was largely connected with the Near East.
Dr Gleba added, "There is overwhelming evidence for frequent contact between Italy and Greece during the first half of the first millennium BC, but this evidence shows that their textile traditions were technically, aesthetically and conceptually very different.
This means that the populations in these two regions are making an active decision to clothe themselves in a certain way and it may have to do with traditions set up already in the Bronze Age."
"Textiles have been and still are widely considered one of the most valuable indicators of individual and group identity.
Even in societies today, we frequently form opinions of others based on the type of cloth they are wearing: tweed is associated with Irish and British country clothing, cashmere with Central Asia and silk with the Far East for example."
"Curiously, by Roman times, the establishment of Greek colonies in southern Italy and more general oriental influences observed in material culture of Italic populations leads towards gradual disappearance of the indigenous textile tradition.
Our future research will attempt to understand the cause behind this change in textile culture."
It has always been the Holy Grail of materials science to describe and control the material's structure-function relationship.
Nanoparticles are an attractive class of components to be used in functional materials because they exhibit size-dependent properties, such as superparamagnetism and plasmonic absorption of light.
Furthermore, controlling the arrangement of nanoparticles can result in unforeseen properties, but such studies are hard to carry out due to limited efficient approaches to produce well-defined three-dimensional nanostructures.
According to scientists from the Biohybrid Materials Group of Aalto University Finland led by Prof. Mauri Kostiainen, nature's own charged nanoparticles -- protein cages and viruses -- can be utilized to determine the structure of composite nanomaterials.
Viruses and proteins are ideal model particles to be used in materials science, as they are genetically encoded and have an atomically precise structure.
These well-defined biological particles can be used to guide the arrangement of other nanoparticles in an aqueous solution.
In the present study, the researchers show that combining native Tobacco Mosaic Virus with gold nanoparticles in a controlled manner leads to metal-protein superlattice wires.
"We initially studied geometrical aspects of nanoparticle superlattice engineering.
We hypothesized that the size-ratio of oppositely charged nanorods (TMV viruses) and nanospheres (gold nanoparticles) could efficiently be used to control the two-dimensional superlattice geometry.
We were actually able to demonstrate this.
Even more interestingly, our structural characterization revealed details about the cooperative assembly mechanisms that proceeds in a zipper-like manner, leading to high-aspect-ratio superlattice wires," Kostiainen says.
"Controlling the macroscopic habit of self-assembled nanomaterials is far from trivial," he adds.
Wires potential to form new materials

The results showed that nanoscale interactions really controls the macroscopic habit of the formed superlattice wires.
The researchers observed that the formed macroscopic wires undergo a right-handed helical twist that was explained by the electrostatic attraction between the asymmetrically patterned TMV virus and the oppositely charged spherical nanoparticles.
As plasmonic nanostructures efficiently affect the propagation of light, the helical twisting resulted in asymmetric optical properties (plasmonic circular dichroism) of the material.
"This result is ground breaking in the sense that it demonstrates that macroscopic structures and physical properties can be determined by the detailed nanostructure, i.e.
the amino acid sequence of the virus particles.
Genetical engineering routinely deals with designing the amino acid sequence of proteins, and it is a matter of time when similar or even more sophisticated macroscopic habit and structure-function properties are demonstrated for ab-initio designed protein cages," explains Dr. Ville Liljestrm who worked on the project during three years of his doctoral studies.
The research group demonstrated a proof-of-concept showing that the superlattice wires can be used to form materials with physical properties controlled by external fields.
By functionalizing the superlattice wires with magnetic nanoparticles, the wires could be aligned by a magnetic field.
In this manner they produced plasmonic polarizing films.
The purpose of the demonstration was to show that electrostatic self-assembly of nanoparticles can potentially be used to form processable materials for future applications.
###

Research article:

Liljestrm, V.; Ora, A.; Hassinen, J.; Rekola, H.; Nonappa; Heilala, M.; Hynninen, V.; Joensuu, J.; Ras, R. H. A.; Trm, P.; Ikkala, O.; Kostiainen, M. A.
Cooperative Colloidal Self-Assembly of Metal-Protein Superlattice Wires.
Nature Communications, 2017, X, XXXX.
DOI: 10.1038/s41467-017-00697-z.
The German National Academy of Sciences Leopoldina today opened its 2017 Annual Assembly in Halle (Saale), with this year's theme being "Genome Editing - Challenges for the Future".
The two-day event sees distinguished international scientists come together to address new molecular biological methods that enable targeted genetic interventions.
At the heart of the lectures and discussions are the ethical, legal and technological questions surrounding genome editing.
Participants will also discuss the use of genome editing techniques in plants and animals and in the context of human therapies.
"We are addressing a field that has developed very rapidly over the past several years.
Without exaggeration, we can say that a revolution has taken place in molecular biological research.
We are experiencing the dawn of a new age of genome editing," said Jrg Hacker, President of the Leopoldina, in his opening speech to the Annual Assembly, adding: "It is expected that the political debate about regulations needed in this area will gain considerable momentum in the coming months and years."
In lectures and discussions, more than 20 outstanding international researchers will examine, together with some 400 members and guests, the opportunities and risks of genome editing.
The Munich-based biochemist Ernst-Ludwig Winnacker will introduce participants to this year's theme in his keynote lecture, "Evolution -- natural or man-made?".
This is followed by a programme, coordinated by the pharmacologist Franz Hofmann, that explores topics such as the "Basics of programmable gene scissors" (Emmanuelle Charpentier, Berlin; Jens Boch, Hanover; and Rudolf Jaenisch, Cambridge/USA), "Would there be a market for genetically modified food in Germany?"
(Wolfgang Stroebe, Groningen/Netherlands) and the "Pros and cons of genome editing in human embryos" (Robin Lovell-Badge, London/UK).
The panel discussion addresses the pros and cons of germline gene therapy, while Jochen Taupitz, Mannheim, addresses genome editing from a legal perspective and in the context of the German Embryo Protection Act.
In the Leopoldina Lecture, which takes place on Friday at 8:15 p.m., Axel Meyer will explain "How genes determine our lives, and why women and men are different".
The evolutionary biologist seeks to outline what is known about the genetic differences between men and women while also stimulating dialogue between the natural and cultural sciences.
During the opening ceremony on Friday morning, the Leopoldina recognised outstanding scientists for their achievements.
The Cothenius Medal, the Carus Medal, the Mendel Medal, the Schleiden Medal, the Georg Uschmann Award for the History of Science and the Leopoldina Prizes for Junior Scientists are awarded every two years at the Annual Assembly.
On Thursday, 21 September, the day before the Annual Assembly opened, the Leopoldina Senate elected Regina Riphahn as Vice-President of the Leopoldina.
The economist, a member of the Leopoldina since 2007, is Professor of Statistics and Empirical Economic Research at Friedrich-Alexander-Universitt Erlangen-Nrnberg.
She succeeds the lifespan psychologist and aging researcher Ursula Staudinger, who had served as Vice-President of the Leopoldina since 2007.
The mechanical engineer Sigmar Wittig was re-elected for his second term as the secretary of class I Mathematics, Natural Sciences and Engineering.
This year, some 50 gifted schoolchildren from across Germany will once again be attending the Annual Assembly at the invitation of the Leopoldina and the Society of German Natural Scientists and Doctors (GDN).
They will have the opportunity to talk to the researchers and sit in on the scientific lectures.
The school programme is funded by the Wilhelm and Else Heraeus Foundation.
###

The complete programme for the Annual Assembly and additional information are available at: http://www.
leopoldina.
org/ en/ jv-2017

Information about the various prizes and medals is available at: http://www.
leopoldina.
org/ en/ about-us/ distinctions-of-the-academy/

Regina Riphahn's member profile is available at: http://www.
leopoldina.
org/ en/ members/ list-of-members/ member/ 1210/

Sigmar Wittig's member profile is available at: http://www.
leopoldina.
org/ en/ members/ list-of-members/ member/ 641/
Professor Tsumoru Shintake at the Okinawa Institute of Science and Technology Graduate University (OIST) yearns for a clean future, one that is affordable and powered by sustainable energy.
Originally from the high-energy accelerator field, in 2012 he decided to seek new energy resources -- wind and solar were being explored in depth, but he moved toward the sea instead.
That year, Professor Shintake and the Quantum Wave Microscopy Unit at OIST began a project titled "Sea Horse," aiming to harness energy from the Kuroshio ocean current that flows from the eastern coast of Taiwan and around the southern parts of Japan.
This project uses submerged turbines anchored to the sea floor through mooring cables that convert the kinetic energy of sustained natural currents in the Kuroshio into usable electricity, which is then delivered by cables to the land.
The initial phase of the project was successful, and the Unit is now searching for industry partners to continue into the next phase.
But the OIST researchers also desired an ocean energy source that was cheaper and easier to maintain.
This is where the vigor of the ocean's waves at the shoreline comes into play.
"Particularly in Japan, if you go around the beach you'll find many tetrapods," Professor Shintake explains.
Tetrapods are concrete structures shaped somewhat like pyramids that are often placed along a coastline to weaken the force of incoming waves and protect the shore from erosion.
Similarly, wave breakers are walls built in front of beaches for the same purpose.
"Surprisingly, 30% of the seashore in mainland Japan is covered with tetrapods and wave breakers."
Replacing these with "intelligent" tetrapods and wave breakers, Shintake explains, with turbines attached to or near them, would both generate energy as well as help to protect the coasts.
"Using just 1% of the seashore of mainland Japan can [generate] about 10 gigawats [of energy], which is equivalent to 10 nuclear power plants," Professor Shintake explains.
"That's huge."
In order to tackle this idea, the OIST researchers launched The Wave Energy Converter (WEC) project in 2013.
It involves placing turbines at key locations near the shoreline, such as nearby tetrapods or among coral reefs, to generate energy.
Each location allows the turbines to be exposed to ideal wave conditions that allow them not only to generate clean and renewable energy, but also to help protect the coasts from erosion while being affordable for those with limited funding and infrastructure.
The turbines themselves are built to withstand the forces thrust upon them during harsh wave conditions as well as extreme weather, such as a typhoon.
The blade design and materials are inspired by dolphin fins--they are flexible, and thus able to release stress rather than remain rigid and risk breakage.
The supporting structure is also flexible, "like a flower," Professor Shintake explains.
"The stem of a flower bends back against the wind," and so, too, do the turbines bend along their anchoring axes.
They are also built to be safe for surrounding marine life--the blades rotate at a carefully calculated speed that allows creatures caught among them to escape.
Now, Professor Shintake and the Unit researchers have completed the first steps of this project and are preparing to install the turbines--half-scale models, with 0.35-meter diameter turbines--for their first commercial experiment.
The project includes installing two WEC turbines that will power LEDs for a demonstration.
"I'm imagining the planet two hundred years later," Professor Shintake says.
"I hope these [turbines] will be working hard quietly, and nicely, on each beach on which they have been installed."
The genome of a typical organism consists of many genes that are stringed like beads.
This alignment has been surprisingly stable even over very long evolutionary periods.
In addition to these genes, there are also many mobile elements, referred to as parasitic, that are spread across the whole genome and aggregated into different families according to their relatedness.
These jumping genes, the transposons, can easily change their position.
Therefore, their position has not been evolutionarily conserved.
When they change their position, they can, for instance, jump directly into functional genes, which changes the function of these genes or even inactivates them completely.
Thus, host organisms have learned to control and reduce jumping.
However, despite all protective measures, there can be massive mobilisations of transposon families in stress situations.
They have to provide specific tools (RNAs) for these situations.
But what is the decisive information to produce these tools?
Researchers from the Institute of Population Genetics of the University of Veterinary Medicine, Vienna have now shown for the first time that each transposon family interprets the signals in a cell in a different way and uses different strategies to decide about when to activate the tools for jumping in the genome.
Jumping genes are parasites

Although the share of transposon sequences in the genome of organisms may be high - about 45 per cent in humans -, they are discredited.
Their jumping behaviour mostly damages the structure of the genome.
Uncontrolled spread would result in the death of the cell.
Therefore, the focus of transposon research was on strategies organisms use to suppress jumping.
Despite these protective measures, transposons jump under specific environmental conditions or stress.
This observation shows that transposons must have mechanisms to avoid this control.
Transposons need suitable tools for jumping.
But it has not yet been understood, nor investigated in all transposon families how the production of these tools is regulated.
Therefore, the study by Ana Marija Jakic investigated in a genome-wide analysis how transposons get prepared for jumping.
For this purpose, the researchers exposed two different fruit fly populations to different temperatures.
Then they mapped out the sequences of the jumping genes, using the "next generation sequencing" methods.
They could show that almost all families produce tools that enable jumping, but the extent depends on two different factors.
"Our study has shown that the activity of transposons does not only depend on themselves but also on factors which the host cells produce," explained Jakic.
In the gene sequence of transposons there is a binding site for host-specific factors which positively regulate the transcription of genes in the cells.
Thus, two factors cooperate - the family-specific binding site and the host factors that are regulated through the environment and genetic background.
"As all members of a family have the same binding sequences, all copies of the family members, spread across the genome, react in the same way to environmental influences," said the lead author.
Party discipline for related transposable elements

"It was important for us to see that the position in the genome does not have a strong influence on the activity of a transposon," said last author Christian Schltterer.
"As the members of a transposon family strongly resemble each other, they also share most of the binding sites.
This means: When the signal for jumping is given, this affects the whole family - party discipline in a certain sense."
Preparation for jumping can provide valuable information, not only about the transposons themselves but also about the effects of the change in position.
The insertion of jumping genes is not necessarily bad for the structure of the genome.
"Although transposons are discredited due to their mainly harmful mutagenic effect, their new position can have a positive influence on neighbouring genes.
This can quickly lead to functional innovations.
A very good example is resistance against insecticides in fruit flies: They became resistant to DDT because of a jumping transposon," said Jakic.
###

Service: The article Regulation of transposable elements: Interplay between TE-encoded regulatory sequences and host-specific trans-acting factors in Drosophila melanogaster" by Ana Marija Jakic, Robert Kofler and Christian Schltterer was published in Molecular Ecology.
http://onlinelibrary.
wiley.
com/ doi/ 10.
1111/ mec.
14259/ abstract

About the University of Veterinary Medicine, Vienna

The University of Veterinary Medicine, Vienna in Austria is one of the leading academic and research institutions in the field of Veterinary Sciences in Europe.
About 1,300 employees and 2,300 students work on the campus in the north of Vienna which also houses five university clinics and various research sites.
Outside of Vienna the university operates Teaching and Research Farms.
http://www.
vetmeduni.
at

Scientific Contact:

Ana Marija Jakic

Institute of Population Genetics

University of Veterinary Medicine Vienna (Vetmeduni Vienna)

AnaMarija.Jaksic@vetmeduni.ac.at

and

Christian Schltterer

Institute of Population Genetics

University of Veterinary Medicine Vienna (Vetmeduni Vienna)

T +43 1 25077-4300

christian.schloetterer@vetmeduni.ac.at

Released by:

Georg Mair

Science Communication / Corporate Communications

University of Veterinary Medicine Vienna (Vetmeduni Vienna)

T +43 1 25077-1165

georg.mair@vetmeduni.ac.at
New Australian-led research has confirmed that smartphone apps are an effective treatment option for depression, paving the way for safe and accessible interventions for the millions of people around the world diagnosed with this condition.
Depression is the most prevalent mental disorder and a leading cause of global disability, with mental health services worldwide struggling to meet the demand for treatment.
In an effort to tackle this rising challenge, researchers from Australia's National Institute of Complementary Medicine (NICM), Harvard Medical School, The University of Manchester, and the Black Dog Institute in Australia examined the efficacy of smartphone-based treatments for depression.
The researchers systematically reviewed 18 randomised controlled trials which examined a total of 22 different smartphone-delivered mental health interventions.
The studies involved more than 3400 male and female participants between the ages of 18-59 with a range of mental health symptoms and conditions including major depression, mild to moderate depression, bipolar disorder, anxiety and insomnia.
The first of its kind research, published today in World Psychiatry found that overall smartphone apps significantly reduced people's depressive symptoms, suggesting these new digital therapies can be useful for managing the condition.
Lead author of the paper, NICM postdoctoral research fellow Joseph Firth says this was an important finding which presented a new opportunity for providing accessible and affordable care for patients who might not otherwise have access to treatment.
"The majority of people in developed countries own smartphones, including younger people who are increasingly affected by depression," said Mr Firth.
"Combined with the rapid technological advances in this area, these devices may ultimately be capable of providing instantly accessible and highly effective treatments for depression, reducing the societal and economic burden of this condition worldwide."
Co-author, NICM deputy director, Professor Jerome Sarris highlighted the importance of the findings for opening up non-stigmatising and self-managing avenues of care.
"The data shows us that smartphones can help people monitor, understand and manage their own mental health.
Using apps as part of an 'integrative medicine' approach for depression has been demonstrated to be particularly useful for improving mood and tackling symptoms in these patients," said Professor Sarris.
When it comes to the question of "Which app is best?"
and "For who?
", the results suggested these interventions so far may be most applicable to those with mild to moderate depression, as the benefits in major depression have not been widely studied as of yet.
The researchers found no difference in apps which apply principles of mindfulness compared to cognitive behavioural therapy or mood monitoring programs.
However, interventions that used entirely 'self-contained' apps - meaning the app did not reply on other aspects such as clinician and computer feedback - were found to be significantly more effective than 'non-self-contained' apps.
The authors suggested this might be due to the comprehensiveness of these particular stand-alone apps rather than the combination of therapies.
Despite the promising early results, there is currently no evidence to suggest that using apps alone can outperform standard psychological therapies, or reduce the need for antidepressant medications.
According to co-author and co-director of the digital psychiatry program at Beth Israel Deaconess Medical Center and a clinical fellow in the department of psychiatry at Harvard Medical School, Dr John Torous, the research is a timely and promising step forward in the use of smartphones in mental health.
"Patients and doctors are faced with a vast array of mental health apps these days, and knowing which ones are actually helpful is imperative," said Dr Torous.
"This research provides much needed information on the effectiveness of apps for depression, and offers important clues into the types of apps which can help patients manage their condition."
Jennifer Nicholas, a PhD Candidate at Black Dog Institute and co-author of the paper says with the knowledge that apps can be effective for managing depression, future research must now investigate which features produce these beneficial effects.
"Given the multitude of apps available - many of them unregulated - it's critical that we now unlock which specific app attributes reap the greatest benefits, to help ensure that all apps available to people with depression are effective."
Since ancient times, philanthropy or unconditional contribution, and reciprocity or retribution, such as "an eye for an eye," have been and remain common human actions.
Thus far, many researchers support the promotion of reciprocity and the suppression of philanthropism, as the latter is favorable to evil.
However, Soka University researcher Isamu Okada and his collaborators Tatsuya Sasaki (University of Vienna) and Yutaka Nakai (Shibaura Institute of Technology) have found that the solidarity of philanthropism and reciprocity is necessary to maintain cooperative societies.
Their paper was published in Scientific Reports on August 29, 2017.
Most theoretical studies on reciprocity assume a condition of perfect observation.
In this situation, every action by every person has a simultaneous effect and no one is permitted to have a different assessment.
Although the perfect observation assumption is an unrealistic constraint, this assumption cannot be completely disregarded because analysis then becomes extremely difficult owing to an increased number of variables.
Okada's team succeeded in analyzing a model that has no assumption of perfect observation using computer simulations.
According to their results, a norm of solo reciprocity is not sufficient to maintain cooperation, but it can maintain cooperation in solidarity with unconditional cooperators.
Moreover, they reveal that a society with a solidarity between norms is more cooperative than that with solo reciprocity.
"So far, philanthropy is excluded by researchers because it is a second-order free-rider that does not punish non-cooperative actions .
However, the discussion is solely under an assumption of perfect observation," says Okada.
"The solidarity of good and justice is not only a moral statement, but also has shown its importance from an academic perspective."
Charged particles may be small, but they matter to astronauts.
NASA's Human Research Program (HRP) is investigating these particles to solve one of its biggest challenges for a human journey to Mars: space radiation and its effects on the human body.
"One of our biggest challenges on a mission to Mars is protecting astronauts from radiation," said NASA Space Radiation Element Scientist Lisa Simonsen, Ph.D.. "You can't see it; you can't feel it.
You don't know you're getting bombarded by radiation."
A common misconception of space radiation is that it's similar to radiation on Earth.
It's actually quite different.
On Earth, radiation coming from the sun and space is mainly absorbed and deflected by our atmosphere and magnetic field.
The main type of radiation people think of on Earth is found in the dentist's office -- X-rays.
Shielding against X-rays and other types of electromagnetic radiation usually consists of wearing a heavy, lead blanket.
Space radiation, however, is different because it has sufficient energy to collide violently with the nuclei that make up shielding and human tissue.
These so-called nuclear collisions cause both the incoming space radiation and shielding nuclei to break-up into many different types of new particles, referred to as secondary radiation.
"In space, there is particle radiation, which is basically everything on the periodic table, hydrogen all the way up through nickel and uranium, moving near the speed of light," said NASA Research Physicist Tony Slaba, Ph.D. "NASA doesn't want to use heavy materials like lead for shielding spacecraft because the incoming space radiation will suffer many nuclear collisions with the shielding, leading to the production of additional secondary radiation.
The combination of the incoming space radiation and secondary radiation can make the exposure worse for astronauts."
The HRP is focused on investigating these effects of space radiation on the human body especially those associated with galactic cosmic rays (GCRs).
"There are three main sources of space radiation, but GCRs are of most concern to researchers for a mission to Mars," said NASA Research Physicist John Norbury, Ph.D. "GCRs that come from exploding stars known as supernovae outside the solar system are the most harmful to the human body."
Other space radiation sources include the Van Allen Belts where radiation particles are trapped around the Earth and solar particle events (SPEs) which are associated with solar flares and coronal mass ejections and are more likely to occur during times of intense solar activity.
But GCRs are first in mind for the HRP researchers who create countermeasures to protect astronauts from space radiation.
The challenge is obtaining adequate data on the GCR exposure and biological consequences.
Researchers use NASA's Space Radiation Laboratory (NSRL) to investigate the effects of ionizing radiation but space radiation is difficult to simulate on Earth.
A radiation dose in a lab setting could be more concentrated and given over a shorter timeframe than what an astronaut actually experiences during a year in space.
As NASA prepares for a journey to Mars, it will continue to use, enhance and develop a variety of technologies to protect astronauts.
International Space Station dosimeters, Orion's Hybrid Electronic Radiation Assessor, and the Radiation Assessment Detector can measure and identify high-energy radiation.
Protons, neutrons and electrons may be small but they will always matter to NASA.
###

NASA's Human Research Program (HRP) is dedicated to discovering the best methods and technologies to support safe, productive human space travel.
HRP enables space exploration by reducing the risks to astronaut health and performance using ground research facilities, the International Space Station, and analog environments.
This leads to the development and delivery of a program focused on: human health, performance, and habitability standards; countermeasures and risk mitigation solutions; and advanced habitability and medical support technologies.
HRP supports innovative, scientific human research by funding more than 300 research grants to respected universities, hospitals and NASA centers to over 200 researchers in more than 30 states.
Amy Blanchett

Laurie Abadie

NASA Human Research Strategic Communications
After people vote, do they think they made the right choice?
When they abstain, do they regret not voting?
New research by Universit de Montral political scientist Andr Blais and PhD students Fernando Feitosa and Semra Sevi answers those questions for the first time - and finds that in general, people who vote are very happy with their choice and those who abstain doubt they did the right thing.
In a study published in Party Politics, the researchers looked at 22 election-period surveys done in Canada, France, Germany, Spain and Switzerland between 2011 and 2015.
Of the nearly 20,000 people polled, the vast majority (97%) who voted were glad they did, while only 60 per cent of non-voters were glad they abstained.
"This is an encouraging result for those who are concerned with the recent turnout decline that has been observed in most western democracies," Blais and his students say in their study.
"This is consistent with the presence of a social norm according to which citizens have a moral duty to participate in elections; at least some of those who do not follow the norm have doubts about the wisdom of their choice."
The study also shows that people who are interested in politics, who feel that they have a moral duty to vote in elections, and who feel close to a party are more prone to be satisfied with their decision to vote and to be dissatisfied if they chose to abstain.
Older voters, especially, are happy they cast their ballot.
"At every election, people must decide whether to vote or not," the researchers write.
"It is fair to assume that some people are uncertain about whether they should participate or not.
It is not surprising to see that, ex post, some people, especially non-voters, believe that they may have made the wrong choice.
"This raises the very important question of whether that judgment is durable and, consequently, whether it has an impact on the decisions that citizens make in the following elections.
The fact that older respondents feel more positive about their decision suggests that there is indeed a learning effect, and that people correct the mistakes that they possibly made in the first elections ... And this may very well be one of the reasons why turnout increases over the life cycle."
###

The surveys polled 19,452 people (17,561 voters, 1,891 abstainers) in a variety of elections (federal, legislative, state, provincial, regional, municipal and European) in Switzerland (Zurich and Lucerne), France (le-de-France, Provence), Spain (Madrid, Catalonia), Germany (Lower Saxony) and Canada (Quebec, Ontario, British Columbia).
Are voters in new democracies so disenchanted with the political process that more and more are staying away from the polls?
To democracy watchers, the examples are legion.
In the space of only a generation, many countries that went from one-party rule to free elections saw voter turnout decline dramatically, by double digits.
In Romania, for instance, turnout dropped by 47 percentage points between 1990 (the founding election) and 2010.
In South Korea, turnout dropped by 30 points from 1988 to 2008.
In El Salvador, it fell 29 points between 1982 and 2002.
In Portugal, it was down 18 points between 1975 and 1995.
Filip Kostelka has come up with some surprising explanations.
As part of his post-doctoral research in political science at Universit de Montral, the Czech-born polyglot did an exhaustive study of legislative elections in all 91 democracies that were born around the world from 1939 to 2015.
He found that in half of them, there was a substantial decline in voter turnout.
But what actually caused people to stay home depended on what country they lived in and how democratization had happened there.
When it was led by a strong opposition in a country where there was also high voter turnout under dictatorship, voting in the founding election was massive at first, setting a benchmark from which every subsequent turnout will inevitably be a decline.
In most other new democracies, such as those where the regime change occurred at the discretion of the authoritarian regime, voter turnout was no different than in established democracies, where rates have been mildly declining since the 1970s.
All this is good news for democracy, Kostelka believes, since it means that it's not the exposure to the democratic practice itself that makes voters stay away from the polls, but rather a host of other, widely varying factors.
"We should be very careful when we interpret declines in voter turnout; it doesn't necessarily mean that people are dissatisfied," said Kostelka, 33, whose findings are published in the American Political Science Review.
"When voters cease to participate, it's not because they are getting disenchanted with the ideal of democracy as a form of government.
That's something you hear a lot from commentators and pundits, but it's a misconception; they're really mistaken."
Kostelka is himself a product of several democracies.
As a Czech, he was born under Communism but raised under its first post-communist president, Vaclav Havel.
As a Canadian resident, he coordinated the UdeM political science department's Making Electoral Democracy Work project under Professor Andr Blais.
As a European scholar, he is an associate researcher in European studies at the prestigious Institut de sciences politiques (Sciences Po), in Paris, and this September took up a new post as a postdoctoral fellow at the University of Barcelona.
In his new study - the most comprehensive empirical analysis to date of voter turnout dynamics through the 20th century - Kostelka observed wide differences in how voting works between nations.
Even though Spain and Portugal, for instance, both emerged from dictatorship in 1970s, turnout in Spain has decreased by only about 3 percentage points, seven times less than in Portugal.
In Spain, the democratization process was tightly controlled by the country's authoritarian regime, whereas in Portugal it was driven by the democratic opposition, leading to massive voter turnout in the founding election.
Kostelka's study also confirms a number of findings from previous research.
In countries such as Romania where the president is directly elected in a separately-held election, voters often don't put as much stock in legislative elections and don't turn out to vote in as large numbers.
Turnout can also be low in places like Hungary or Serbia where there's currently very little competition between political parties, where the number-one party is much stronger than the opposition.
Conversely, turnout tends to be higher in places like Belgium or Australia where voting is compulsory and strictly enforced.
Post-communist countries appear to be a special case.
There has been some residual voter decline in many of them that is not accounted for by the democratization context or by the global trend of decreased voting.
One of the reasons may be emigration: many people eligible to vote in ex-communist countries, where voter registration is automatic, have actually moved to the West.
Once there, they do not participate in elections back home, in their country of origin.
Overall, exceptionally steep declines in voter turnout in new democracies "appear to be almost entirely a function of what happens before and during regime change, not what happens afterwards," Kostelka concludes in his study.
"It is true that since the 1970s, voter turnout declines have become more frequent ...
Nevertheless, this is a tendency that new democracies share with established democracies."
Scientists from the University of Surrey have developed a rapid and highly sensitive fingerprint test that can take just seconds to confirm whether someone has used cocaine.
This new breakthrough, published in Clinical Chemistry, comes as a result of the first large scale study of cocaine users and could pave the way for the detection of a range of other Class A substances.
The research was carried out with partners from the Netherlands Forensic Institute and Intelligent Fingerprinting.
The team, led by Dr Catia Costa and Dr Melanie Bailey from the University of Surrey, developed a new technique to analyse the levels of cocaine detected in the fingerprints.
They used chromatography paper to take the sample as part of a technique known as paper spray mass spectrometry.
The study involved taking fingerprints from a group of patients seeking treatment at drug rehabilitation centres, as well as a larger group not known to be drug users.
All of those taking part washed their hands before the test in a variety of ways, and then samples were collected on the prepared chromatography paper.
The fingerprint is developed using chemicals, so that the ridges of the fingerprint (and therefore the identity of the donor) can be established prior to analysis.
When someone has taken cocaine, they excrete traces of benzoylecgonine and methylecgonine as they metabolise the drug, and these chemical indicators are present in fingerprint residue.
Importantly, the traces can still be detected even after handwashing.
According to the National Statistics Office, 1 in 12 adults aged 16 to 59 (around 2.7 million people) had taken illicit drugs in 2015/16.
There were also over 8,500 people who were admitted to hospital after being diagnosed with drug-related mental health and behavioural disorder.
In 2015, there were almost 2,500 deaths related to drug misuse - an increase of 10 per cent on 2014.
Dr Costa said: "Paper spray mass spectrometry is gaining increasing popularity in forensic circles because it is incredibly sensitive and is very easy to set up a testing system - the units will save laboratories time.
"This is the first time it has ever been used to detect the presence of drugs in fingerprints, and our results show the technique was 99% effective in detecting cocaine use among the patients."
Dr Bailey said: "This is a real breakthrough in our work to bring a real time, non-invasive drug-testing method to the market that will provide a definitive result in a matter of minutes - we are already working on a 30 second method."
"And, as with previous methods we have developed, it is non-invasive, hygienic and can't be faked - by the nature of the test, the identity of the subject, and their drug use, is all captured within the sample itself."
"This exciting research clearly demonstrates the important role that fingerprints can play in simplifying drug screening, and complements our own parallel developments in portable, point-of-use diagnostic tests.
These activities confirm the value of a fingerprint as a diagnostic matrix," added Dr Jerry Walker, Intelligent Fingerprinting's CEO.
"We have supported the University of Surrey research programmes for the last four years, and Dr Bailey and her team have shown time and again that they are the world's leading group in fingerprint diagnostics research using mass spectrometry.
We congratulate them in continuing to expand knowledge in the revolutionary field of fingerprint-based diagnostics."
It is anticipated that this technology could see the introduction of drug tests for law enforcement agencies to use within the next decade.
Drug testing is used routinely by probation services, prisons, courts and other law enforcement agencies.
However, traditional testing methods have limitations.
Where bodily fluids are tested, there can be biological hazards and often a requirement for particular storage and disposal methods.
A new test that combines the effects of more than two dozen genetic variants, most associated by themselves with only a small risk of Alzheimer's disease, does a better job of predicting which cognitively normal older adults will go on to develop Alzheimer's dementia than testing only for the well-known genetic variant APOE E4, a scientific team led by researchers at UC San Francisco and UC San Diego has found.
APOE E4 has long been considered the strongest genetic predictor of whether someone is likely to develop Alzheimer's, although it is only carried by 10 to 15 percent of the population and recent research suggests its effects have been overstated.
The polygenic hazard score (PHS), a test developed by the research team that carried out the new study, provides risk estimates for the remaining 85 to 90 percent of people who do not carry at least one copy of APOE E4 but still have some combination of other genetic variants that put them at risk of Alzheimer's.
"Beyond APOE E4 by itself, our polygenic hazard score can identify cognitively normal and mildly impaired older folks who are at greatest risk for developing Alzheimer's-associated clinical decline over time," said Chin Hong Tan, PhD, a postdoctoral scholar at UCSF and first author of the paper, published Sept. 22, 2017, in Annals of Neurology.
The researchers looked at five years of data on 1,081 subjects from the National Alzheimer's Coordinating Center (NACC) who did not have dementia, and found the PHS test could predict how long it would take for them to progress to Alzheimer's dementia, as well as how steep their cognitive decline would be, even after taking into account whether they were carriers of APOE E4.
Autopsies of those who did develop Alzheimer's showed that, even among those who did not carry a copy of the APOE E4 variant, a higher PHS was associated with a higher level of amyloid plaque - a protein aggregate that is a hallmark of Alzheimer's -- in the brain.
These patients also showed steeper declines on cognitive tests during their lifetimes.
Older individuals in the highest PHS percentiles also showed the highest incidence of Alzheimer's, which is diagnosed with cognitive tests and brain pathology, regardless of their APOE E4 status.
Many scientists now believe that rather than being a disease of aging, Alzheimer's may be the result of a disease process that begins years, perhaps decades, before symptoms of dementia appear.
This is thought by many to be one reason why so many Alzheimer's drugs tested on older people with dementia have failed in clinical trials.
The new PHS could help in the search for ways to identify those at risk of Alzheimer's long before they show symptoms of dementia, so they can be treated before the disease begins ravaging their brains, the researchers said.
"Our findings have strong implications for disease stratification and secondary prevention trials in Alzheimer's, as well as direct-to-consumer genetic tests, some of which have recently received FDA clearance," said Anders Dale, PhD, Professor of Neurosciences and Radiology at UC San Diego and co-author of the new study.
The PHS test enables researchers to calculate an age-specific risk of developing Alzheimer's, based upon each person's share of 31 genetic variants, plus APOE E4.
The test makes its predictions by using genetic data from more than 70,000 people in the NACC database, the International Genomics of Alzheimer's Disease Project and the Alzheimer's Disease Genetics Consortium.
"Unlike other polygenic risk scores, the continuous PHS measure is based on a survival framework and incorporates US-based Alzheimer's incidence rates," said Rahul Desikan, MD, PhD, an assistant professor in the Department of Radiology and Biomedical Imaging at UCSF, and co-senior author of the paper.
"Rather than a diagnostic test, PHS may serve as a genetic 'risk factor' for preclinical Alzheimer's disease."
###

Other authors include Jacinth Tan, PhD, Christopher Hess, MD, PhD, and William Dillon, MD, of UCSF; Bradley Hyman, MD, PhD, of Massachusetts General Hospital; Gerard Schellenberg, PhD, of the University of Pennsylvania Perelman School of Medicine; Lilah Besser, PhD, and Walter Kukull, PhD, of the University of Washington; Karolina Kauppi, PhD, and Linda McEvoy, PhD, of UC San Diego; Ole Andreassen, MD, PhD, of the University of Oslo; and Chun Fan, MD, PhD, of UC San Diego.
Bottom Line: A pre-existing diagnosis of dementia was associated with increased risk of death for older patients with advanced colon cancer; however, some of the effects of dementia on survival could be mediated by receipt of chemotherapy.
Journal in Which the Study was Published: Cancer Epidemiology, Biomarkers & Prevention, a journal of the American Association for Cancer Research.
Author: Yingjia Chen, PhD, a postdoctoral fellow in the Memory and Aging Center in the Department of Neurology at University of California, San Francisco.
How the Study Was Conducted and Results: Chen and colleagues started by performing a retrospective cohort study using SEER-Medicare data for 3,903 adults over the age of 65 with confirmed diagnoses of stage 3 colon cancer and dementia.
Of them, 60.9 percent were women, and 79.7 percent were white.
A pre-existing dementia diagnosis was confirmed by a formal entry in medical records or prescription records for one of four FDA-approved drugs for temporarily improving dementia symptoms: donepezil, galantamine, memantine, and rivastigmine.
The researchers found that a pre-existing diagnosis of dementia was associated with increased risk of death by 45 percent and the average mean survival time for patients with stage 3 colon cancer and pre-existing dementia was only 57 percent that of their cognitively healthy counterparts.
Next, Chen and colleagues examined the impact of the receipt of chemotherapy on survival outcome in patients with dementia.
"We assessed the mediating effect of chemotherapy using a statistical method called accelerated failure time model in the context of the counterfactual framework and found that the receipt of chemotherapy was significantly associated with survival," explained Chen.
"This type of analysis allowed us to determine that not receiving chemotherapy accounted for 13 percent of the poorer survival outcomes for patients with pre-existing dementia.
Author Comment: "Both colon cancer and dementia are prevalent among the growing elderly population and have a high risk of co-occurrence," said Chen.
"Chemotherapy may be challenging for older adults with dementia, but our research shows that some may still benefit."
"In general, dementia patients with advanced colon cancer are being undertreated.
There are many good reasons why physicians, patients, and families may decide to forgo chemotherapy, including toxicity, functional limitations of the patient, or if patients are diagnosed with colon cancer at later stages," Chen explained.
"However, our findings suggest that chemotherapy may increase survival and should be considered for advanced colon cancer patients with dementia in a similar fashion as for those without dementia."
Limitations: Limitations of the study include that detailed information about dementia diagnoses or functional status were not available, so the researchers were not able to identify the extent of dementia.
The investigators were also unable to know the reasons why chemotherapy was or was not chosen, nor the regimens administered.
###

Funding & Disclosures: The study was supported by the Biostatistics Shared Resource of the UC Davis Comprehensive Cancer Center, which is funded by a grant awarded by the National Cancer Institute.
Chen declares no conflicts of interest.
To interview Yingjia Chen, contact Julia Gunther at julia.gunther@aacr.org or 215-446-6896.
Follow us: Cancer Research Catalyst http://blog.
org ; Twitter @AACR; and Facebook http://www.
facebook.
com/ aacr.
org

About the American Association for Cancer Research
Many extreme events -- from a rogue wave that rises up from calm waters, to an instability inside a gas turbine, to the sudden extinction of a previously hardy wildlife species -- seem to occur without warning.
It's often impossible to predict when such bursts of instability will strike, particularly in systems with a complex and ever-changing mix of players and pieces.
Now engineers at MIT have devised a framework for identifying key patterns that precede an extreme event.
The framework can be applied to a wide range of complicated, multidimensional systems to pick out the warning signs that are most likely to occur in the real world.
"Currently there is no method to explain when these extreme events occur," says Themistoklis Sapsis, associate professor of mechanical and ocean engineering at MIT.
"We have applied this framework to turbulent fluid flows, which are the Holy Grail of extreme events.
They're encountered in climate dynamics in the form of extreme rainfall, in engineering fluid flows such as stresses around an airfoil, and acoustic instabilities inside gas turbines.
If we can predict the occurrence of these extreme events, hopefully we can apply some control strategies to avoid them."
Sapsis and MIT postdoc Mohammad Farazmand have published their results today in the journal Science Advances.
Looking past exotic warnings

In predicting extreme events in complex systems, scientists have typically attempted to solve sets of dynamical equations -- incredibly complex mathematical formulas that, once solved, can predict the state of a complex system over time.
Researchers can plug into such equations a set of initial conditions, or values for certain variables, and solve the equations under those conditions.
If the result yields a state that is considered an extreme event in the system, scientists can conclude that those initial conditions must be a precursor, or warning sign.
Dynamical equations are formulated based on a system's underlying physics.
But Sapsis says that the physics governing many complex systems are often not well-understood and they contain important model errors.
Relying on these equations to predict the state of such systems would therefore be unrealistic.
Even in systems where the physics are well-characterized, he says there is a huge number of initial conditions one could plug into associated equations, to yield an equally huge number of possible outcomes.
What's more, the equations, based on theory, might successfully identify an enormous number of precursors for extreme events, but those precursors, or initial states, might not all occur in the real world.
"If we just blindly take the equations and start looking for initial states that evolve to extreme events, there is a high probability we will end up with initial states that are very exotic, meaning they will never ever occur for any practical situation," Sapsis says.
"So equations contain more information than we really need."
Aside from equations, scientists have also looked through available data on real-world systems to pick out characteristic warning patterns.
But by their nature, extreme events occur only rarely, and Sapsis says if one were to rely solely on data, they would need an enormous amount of data, over a long period of time, to be able to identify precursors with any certainty.
Searching for hotspots

The researchers instead developed a general framework, in the form of a computer algorithm, that combines both equations and available data to identify the precursors of extreme events that are most likely to occur in the real world.
"We are looking at the equations for possible states that have very high growth rates and become extreme events, but they are also consistent with data, telling us whether this state has any likelihood of occurring, or if it's something so exotic that, yes, it will lead to an extreme event, but the probability of it occurring is basically zero," Sapsis says.
In this way, the framework acts as a sort of sieve, capturing only those precursors that one would actually see in a real-world system.
Sapsis and Farazmand tested their approach on a model of turbulent fluid flow -- a prototype system of fluid dynamics that describes a chaotic fluid, such as a plume of cigarette smoke, the airflow around a jet engine, ocean and atmospheric circulation, and even the flow of blood through heart valves and arteries.
"We used the equations describing the system, as well as some basic properties of the system, expressed through data obtained from a small number of numerical simulations, and we came up with precursors which are characteristic signals, telling us before the extreme event starts to develop, that there is something coming up," Sapsis explains.
They then performed a simulation of a turbulent fluid flow and looked for the precursors that their method predicted.
They found the precursors developed into extreme events between 75 and 99 percent of the time, depending on the complexity of the fluid flow they were simulating.
Sapsis says the framework is generalizable enough to apply to a wide range of systems in which extreme events may occur.
He plans to apply the technique to scenarios in which fluid flows against a boundary or wall.
Examples, he says, are air flows around jet planes, and ocean currents against oil risers.
"This happens in random places around the world, and the question is being able to predict where these vortices or hotspots of extreme events will occur," Sapsis says.
"If you can predict where these things occur, maybe you can develop some control techniques to suppress them."
###

This research was supported, in part, by the Office of Naval Research, the Air Force Office of Scientific Research, and the Army Research Office.
Additional background

ARCHIVE: Rogue wave ahead http://news.
edu/ 2016/ prediction-tool-rogue-waves-0225

ARCHIVE: To capture a wave http://news.
edu/ 2015/ capturing-waves-themistoklis-sapsis-1016
Mathematicians have opened a new chapter in the theory of moonshine, one which begins to harness the power of the pariahs - sporadic simple groups that previously had no known application.
"We've found a new form of moonshine, which in math refers to an idea so farfetched as to sound like lunacy," says Ken Ono, a number theorist at Emory University.
"And we've used this moonshine to show the mathematical usefulness of the O'Nan pariah group in a way that moves it from theory to reality.
It turns out that the O'Nan group knows deep information about elliptic curves."
Nature Communications published the representation theory for the O'Nan group developed by Ono, John Duncan (also a number theorist at Emory) and Michael Mertens (a former post-doctoral fellow at Emory who is now at the University of Cologne).
"We've shown that the O'Nan group, a very large pariah group, actually organizes elliptic curves in a beautiful and systematic way," Duncan says.
"And not only does it organize them, it allows us to see some of their deepest properties.
It sees infinitely many curves, which allows us to then use our moonshine to make predictions about their general behavior.
That's important, because these objects underlie some of the hardest questions at the very horizon of number theory."
Elliptic curves may sound esoteric, but they are part of our day-to-day lives.
They are used in cryptography - the creation of codes that are difficult to break.
An elliptic curve is not an ellipse, rather it is a complex torus, or doughnut shape.
"You can think of it as a doughnut together with specific, delicate configurations of rational points that are very carefully placed," Duncan says.
"So, in the simplest of terms, it's like a doughnut that you eat, that may have sprinkles on it.
The whole game in the math of elliptic curves is determining whether the doughnut has sprinkles and, if so, where exactly the sprinkles are placed."
Unlike an edible doughnut, however, these mathematical doughnuts are not visible.
"Imagine you are holding a doughnut in the dark," Ono says.
"You wouldn't even be able to decide whether it has any sprinkles.
But the information in our O'Nan moonshine allows us to 'see' our mathematical doughnuts clearly by giving us a wealth of information about the points on elliptic curves."
The findings are especially surprising since none of the pariahs, as six of math's sporadic simple groups are known, had previously appeared in moonshine theory, or anywhere else in science.
Math's original moonshine theory dates to a 1979 paper called "Monstrous Moonshine" by John Conway and Simon Norton.
The paper described a surprising connection between a massive algebraic object known as the monster group and the j-function, a key object in number theory.
In 2015, a group of mathematicians - including Duncan and Ono - presented proof of the Umbral Moonshine Conjecture, which revealed 23 other moonshines, or mysterious connections between the dimensions of symmetry groups and coefficients of special functions.
In theoretical math, symmetry comes in groups.
Symmetrical solutions are usually optimal, since they allow you to divide a large problem into equal parts and solve it faster.
The classification of the building blocks of groups is gathered in the ATLAS of Finite Groups, published in 1985.
"The ATLAS is like math's version of the periodic table of the elements, but for symmetry instead of atoms," Duncan explains.
Both the ATLAS and the periodic table contain quirky characters that may - or may not - exist in nature.
Four super heavy elements with atomic numbers above 100, for example, were discovered in 2016 and added to the periodic table.
"People have to work hard to produce these elements in particle accelerators and they vanish immediately after they are constructed," Ono says.
"So you have to wonder if they really are a part of our everyday chemistry."
The pariah groups pose a similar question in math.
Are they natural or simply theoretical constructs?
"Our work proves, for the first time, that a pariah is real," Ono says.
"We found the O'Nan group living in nature.
Our theorem shows that it's connected to elliptic curves, and whenever you find a correspondence between two objects that are seemingly not related, it opens the door to learning more about those objects."
Washington, DC - Sept. 22, 2017 - Antibiotic use on people or pets, and use of biocidal cleaning products such as bleach, are associated with multidrug resistance in methicillin-resistant Staphylococcus aureus (MRSA) in the home.
This contamination of the home environment may contribute to reinfection of both humans and animals with MRSA, and to subsequent failure of treatment.
The research is published September 22nd in Applied and Environmental Microbiology, a journal of the American Society for Microbiology.
Multidrug resistance to MRSA and reinfection with MRSA, said corresponding author Jonathan Shahbazian, MPH, were the most important in this study.
The study also showed that whether used in humans or companion animals, the antibiotic clindamycin was not associated with the risk of multi-drug resistant bacteria in the home.
Treatment with mupirocin, an antibiotic used to treat skin infections and to eradicate MRSA from the nasal passages in order to prevent its spread from sneezes, is weakly associated with mupirocin resistance in the household environment.
That "could complicate decolonization efforts that rely on use of nasal mupirocin ointment," said Mr. Shahbazian, who conducted the study while finishing his masters in public health at Johns Hopkins Bloomberg School of Public Health, Baltimore.
("Decolonization" refers to treatment to eradicate potentially disease-causing bacteria from human carriers.)
Additionally, Mr. Shahbazian said that 100 percent of MRSA isolates the investigators obtained from rural homes were multidrug resistant, "suggesting living in a rural household may be a risk factor for multidrug resistance."
"We also found the presence of domestic pets was associated with multidrug resistant MRSA in the home environment, while the presence of unwanted pests, such as mice or cockroaches, was associated with non-multidrug resistant MRSA strains," said Mr. Shahbazian.
In the study, the investigators collected samples from the home environments and companion animals of households enrolled in a large randomized controlled trial, which took place over a 14 month period.
They tested whether household-wide efforts to eradicate MRSA -- which included daily use of nasal mupirocin ointment and chlorhexidine body wash--were successful in reducing recurrence of MRSA among adults and children who had previously been diagnosed with a MRSA skin or soft tissue infection.
They repeated sampling in 65 homes three months after the residents had been treated for MRSA, or, as a control, after they had been educated about MRSA.
"Based on the evidence, we strongly suspect that environmental contamination of the home with MRSA contributes to recurrence," said Mr. Shahbazian.
The investigators also suspect that household-wide selective pressures on the home environmental reservoir of MRSA promote persistence of multidrug resistant strains.
"We hypothesize that infected or colonized people and companion animals shed MRSA into the home environment," which then re-infect household members.
The investigators concluded that a better understanding of what causes home environmental MRSA to become multidrug resistant, and thus harder to treat, could help in identifying which households are more likely to harbor multidrug resistant MRSA, so that these could be targeted for eradication of the pathogen.
The investigators are involved in One Health research.
One Health examines health problems from a multidisciplinary perspective that includes physicians, veterinarians, environmental experts, and others.
###

The American Society for Microbiology is the largest single life science society, composed of over 50,000 scientists and health professionals.
ASM's mission is to promote and advance the microbial sciences.
ASM advances the microbial sciences through conferences, publications, certifications and educational opportunities.
It enhances laboratory capacity around the globe through training and resources.
It provides a network for scientists in academia, industry and clinical settings.
Additionally, ASM promotes a deeper understanding of the microbial sciences to diverse audiences.
BOULDER, Colo.--Researchers at the National Institute of Standards and Technology (NIST) have demonstrated a potential new tactic for rapidly determining whether an antibiotic combats a given infection, thus hastening effective medical treatment and limiting the development of drug-resistant bacteria.
Their method can quickly sense mechanical fluctuations of bacterial cells and any changes induced by an antibiotic.
Described in Scientific Reports, NIST's prototype sensor provides results in less than an hour, much faster than conventional antimicrobial tests, which typically require days to grow colonies of bacterial cells.
Delayed results from conventional tests allow dangerous infections to progress before effective treatments can be found and provides a time window for bacteria to develop drug resistance.
Improperly prescribed antibiotics and antibiotic-resistant bacteria pose serious threats to public health.
At least 2 million illnesses and 23,000 deaths are attributed to antibiotic-resistant bacterial infections in the United States each year, according to a 2013 report from the Centers for Disease Control and Prevention.
One solution may be the new NIST sensing approach, based on a quartz-crystal resonator whose vibrations vary in measurable ways when particles on the surface change.
The approach, which involves bacterial cells adhered to a resonator, represents a new way of using these super-sensitive crystals, which NIST researchers previously demonstrated for applications such as measuring carbon nanotube purity.
The new NIST technique senses the mechanical motion of microbes and their response to antibiotics.
Other researchers previously found that some bacterial motion becomes weaker in the presence of some antibiotics, but until now such changes have been detected only with microscale sensors and generally in motile bacteria (propelled by threadlike appendages called flagella).
The NIST method may be more useful in clinical settings because it collects electronic data cost-effectively and, since it senses large bacterial colonies, can be macroscopic and robust.
The sensor is piezoelectric, which means its dimensions change when exposed to an electric field.
A thin piezoelectric quartz disk is sandwiched between two electrodes.
An alternating voltage at a stable frequency near the crystal's resonant frequency is applied to one electrode to excite crystal vibrations.
From another electrode on the opposite side of the crystal, researchers record oscillating voltages of the crystal response, a signal that shows fluctuations in the resonant frequency (or frequency noise) arising from microbial mechanical activity coupled to the crystal surface.
Proof of concept tests at NIST used two quartz-crystal resonators coated with several million bacterial cells.
One resonator was used to test the effect of an antibiotic on the cells, while the second resonator was used as a control without the antibiotic.
The ultra-sensitive approach enabled detection of cell-generated frequency fluctuations at a level of less than one part in 10 billion.
The experiments showed that the amount of frequency noise was correlated with the density of living bacterial cells.
When the bacteria were then exposed to antibiotics, frequency noise sharply decreased.
Bacteria with paralyzed flagella were used in the experiments to eliminate effects of swimming motion.
This enabled the researchers to conclude that the detected cell-generated frequency fluctuations arise from vibrations of cell walls.
NIST researchers sensed the response of Escherichia coli (E. coli) to two antibiotics, polymyxin B (PMB) and ampicillin.
Cell-generated frequency noise dropped close to zero within 7 minutes after the introduction of PMB.
Frequency noise began decreasing within 15 minutes of adding ampicillin and then dropped more rapidly as cells broke apart and died.
These time scales reflect the normal speeds at which these antibiotics work.
After the sensor measurements, the effectiveness of the antibiotics was confirmed by growth of colonies from the remaining bacteria.
Both antibiotics greatly reduced the numbers of live cells.
To determine how broadly useful the technique might be, further studies will be needed using a number of bacterial species and antibiotics that work in different ways.
NIST researchers have been granted a patent on the technique: RESONATOR AND PROCESS FOR PERFORMING BIOLOGICAL ASSAY, U. S. Patent No.
9,725,752, issued August 8, 2017.
Companies interested in licensing the patent may contact Don Archer of NIST's Technology Partnerships Office at donald.archer@nist.gov or 301-975-2522.
Ultimately, the NIST sensor may be suitable for rapid antimicrobial susceptibility testing (called AST) in clinical settings and drug development.
###

Paper: W.L.
Johnson, D.C. France, N.S.
Rentz, W.T.
Cordell, and F.L.
Walls.
Sensing bacterial vibrations and early response to antibiotics with phase noise of a resonant crystal.
Scientific Reports.
Sept. 22.
The world's oceans are warming.
The marginal seas display more notable warming than the open ocean due to their proximity to land and other unique regional factors.
The Yellow Sea and East China Sea (YECS, Fig.
1) are marginal seas east of China, and display steadily warming trend in the last century.
In fact, the warming trend of sea surface temperature (SST) in the YECS is pronounced than the global mean state.
The increasing SST can cause sea level rise, change currents in the oceans and air flows in the atmosphere, and affect ecosystem conditions.
Researchers aimed at uncovering the underlying physical mechanisms often faced an array of obstacles: the factors related to SST are in a large numbers, while the corresponding records are limited to the temporal coverage and data quality.
Therefore, the existing explanations on SST trend of the YECS are diverse.
For example, Dr. Liping Zhang from the Ocean University of China and her colleagues found that the increasing SST trend over the China marginal seas was accompanied by increased wind speed and enhanced heat loss (from ocean to atmosphere), which in turn acted to inhibit the warming rate [Zhang L., L. Wu, X. Lin, and D. Wu.
Modes and mechanisms of sea surface temperature low-frequency variation over the coastal China seas.
Journal of Geophysical Research, 2010, 115, C08031]; on the contrary, Professor Sang-Wook Yeh and his colleague from Hanyang University, Ansan, Republic of Korea found the increasing SST trend in the YECS in winter was accompanied by weakened northerly winds over the YECS during winter, which helped increase SST through latent and sensible heat fluxes [Yeh Sang-Wook, and Cheol-Ho Kim.
Recent warming in the Yellow/East Sea during winter and the associated atmospheric circulation.
Continental Shelf Research, 2010, 30: 1428-1434].
These controversial statements prompt other evidences and further deeper investigation.
Studies on regional atmospheric and oceanic environment reveal that the SST warming trend in YECS are accompanied with atmospheric and oceanic changes and influenced by them, according to Hailun He, a scientist at the Second Institute of Oceanography of State Oceanic Administration, in the Chinese city of Hangzhou.
In an article coauthored with Yuhua Pei and Xiaohui Xiu, colleagues at the same institute, the researchers intended to discuss the possible factors that affect the increasing SST trend in the YECS by analyzing associated new data products.
These data include the surface net heat flux, surface wind, temperature, geostrophic current velocity at a section transecting the Kuroshio (PN section), and air temperature in Japan.
"These data can be used to depict some major influencing factors, both from the atmosphere and ocean.
These analyses provide evidence for critical consideration of the mechanisms for increasing SST in the YECS."
As stated by the authors.
The warming is not limited in SST.
These researchers stated: "The warming rate in the specific section decreases steadily with depth and turns to a cooling trend in the intermediate layer, which results in an increase in stratification, and facilitates SST warming."
2)

These three scholars likewise revealed in the study, which was published in the Science China Earth Sciences, that the low-frequency trend in the air-sea flux were hardly used to explain the SST warming trend.
"Accompanying the increasing YECS SST, there is a decreasing surface heat flux (downward positive), as indicated from the "OAFlux" product, which can inhibit the SST increase.
Therefore, SST warming seems to be induced from the oceanic thermal advection but not direct surface forcing."
However, ocean thermal advection cannot be measured directly and its effect cannot be evaluated from current observational data.
"It is a big challenge to adequately evaluate the contribution from thermal advection on the SST warming."
According to Dr. Hailun He, the corresponding author of the research.
"Changes in surface wind can affect SST warming through the turbulent heat flux, downward/upward airflow, and upwelling/downwelling in the ocean.
However, these trends are quite small and have large uncertainties, so their effect on SST warming is uncertain."
the researchers wrote in an article titled "Interpreting the sea surface temperature warming trend in the Yellow Sea and East China Sea."
"In this study," wrote the three researchers, "associated up-to-date data products are analyzed to provide evidence for critical consideration of the mechanisms for increasing SST in the YECS."
The results provide valuable reference for the regional climate change in YECS.
However, the researchers also admitted, it was still challenging to draw firm conclusions on the dominant mechanism of SST warming in the YECS.
They stated, "In the future, climate models that can correctly simulate the western boundary currents and assimilate historical observations would be helpful in solving this problem."
###

This research was funded by the Natural Science Foundation of China (Nos.
41690120, 41690121, 41621064, 91528304 & 41476021), National Program on Global Change and Air-Sea Interaction (No.
GASI-IPOVAI-04), National Basic Research Program (No.
2013CB430302), and Scientific Research Fund of the Second Institute of Oceanography (No.
JG1501).
Orchids are loved by gardeners around the world but are notoriously difficult to cultivate.
Japanese researchers have developed a new orchid cultivation kit that allows seed germination, flowering, and fruiting, and have succeeded in the complete artificial cultivation of an autonomous orchid.
Since this kit can be made from materials costing only a few dollars, it can broaden the range of opportunities for orchid cultivation in general households.
It is also expected to be a useful tool for preserving the genetic diversity of orchidaceous plants, many of which are in danger of extinction.
Background:

Myco-heterotrophic plants germinate and grow through a symbiotic relationship with mycorrhizal fungi.
The fungi coexists on the plant's roots where it is supplied with sugar, and the plant receives energy from the fungi rather than through photosynthesis.
Orchidaceous plants fall into the myco-heterotrophic plant group.
Orchidaceae plants have unique shapes, reproductive styles, and highly diversified ecological features.
Unfortunately, many species of this plant group are on the verge of extinction.
Plants that require symbiotic bacteria, like Orchidaceae, are difficult to germinate and cultivate in an artificial environment where symbiotic bacteria are less likely to be present.
In general, orchid breeding is done by buying seedlings, but it can sometimes take years before they fully flower.
In addition to the labor, orchid cultivation often requires the use of a greenhouse, giving the plant an image of only available to relatively wealthy people.
Additionally, obtaining orchid seeds is challenging and, even if seeds can be acquired, orchid seed germination in an ordinary household is extremely difficult.
For this reason, there are not many people in the general population who have experience germinating orchids to the flowering stage.
Moreover, the efficiency of artificial cultivation is expected to help with orchid seed conservation.
Development:

Orchids are the most species-rich gardening plants in the world, and in the Japanese prefecture of Kumamoto, three kinds of Gastrodia orchids grow naturally.
Scientists at Kumamoto University originally developed a cultivation kit to culture and identify mycorrhizae, fungi that have a symbiotic relationship with many plants and are necessary for cultivating orchidaceous plants in the laboratory.
They quickly found that the kits provided an excellent habitat for the three Gastrodia orchids native to the area.
The new "Orchid Cultivation Kits" are made by simply placing detritus (fallen trees, cones, leaves, branches, and mulch) collected from areas where orchids are found into a plastic case and covering the concoction with a lid.
Result:

Researchers cultivated Gastrodia orchids from seeds using this kit, thereby confirming that the plants can be fully grown artificially from germination to flowering and fruiting.
Cultivation efficiency with the kit is extremely high, with some seeds that normally germinate little in the field germinating with almost 100% probability when using the kit.
In the case of the Gastrodia pubilabiata orchid, the researchers saw the plant successfully grow from seed to flower three times in one year.
The cultivation kit can maintain higher humidity levels since it is a closed plastic container.
It is thought that the high efficiency of the kit was due to mycorrhizal fungi that adhered to the items collected from the natural orchid habitat, which had a favorable effect on the growth of Gastrodia orchids.
Indeed, the same mycorrhizal fungi identified from decomposing trees harvested from the original orchid habitat were also detected in growing orchids; clearly the fungi and Orchidaceae were symbiotic.
It is thought that the combination of high humidity levels and environment that includes mycorrhizal fungi is indispensable for efficient orchid germination and growth.
"Since our orchid cultivation kit is a very simple system, anyone should be able to artificially cultivate the plants anywhere," said Professor Shinichiro Sawa of Kumamoto University, who directed the kit's development.
"By further customizing this system, we expect that the artificial cultivation of various fungal heterotrophic plants will become simplified and highly efficient.
Not only do we expect to commercialize the cultivation kits domestically, but we also hope to see it used in a wide range of applications from the conservation and growth of endangered species to the cultivation of medicinal plants."
###

These findings were reported in the 16th Annual Meeting of the Japanese Society for Plant Systematics KYOTO 2017 and posted online in the "International Journal of Biology" on 16th September 2017.
[Resource] Shimaoka, C.; Fukunaga, H.; Inagaki, S.; Sawa, S., Artificial Cultivation System for Gastrodia spp.
and Identification of Associated Mycorrhizal fungi, International Journal of Biology, Canadian Center of Science and Education, 2017.
DOI: 10.5539/ijb.v9n4p27
LOGAN, UTAH, USA - If you drop an aluminum spoon in a sink full of water, the spoon will sink to the bottom.
That's because aluminum, in its conventional form, is denser than water says Utah State University chemist Alexander Boldyrev.
But if you restructure the common household metal at the molecular level, as Boldyrev and colleagues did using computational modeling, you could produce an ultra-light crystalline form of aluminum that's lighter than water.
Boldyrev, along with scientists Iliya Getmanskii, Vitaliy Koval, Rusian Minyaev and Vladimir Minkin of Southern Federal University in Rostov-on Don, Russia, published findings in the Sept. 18, 2017, online edition of 'The Journal of Physical Chemistry C.'

The team's research is supported by the National Science Foundation and the Russian Ministry of Science and Education.
"My colleagues' approach to this challenge was very innovative," says Boldyrev, professor in USU's Department of Chemistry and Biochemistry.
"They started with a known crystal lattice, in this case, a diamond, and substituted every carbon atom with an aluminum tetrahedron."
The team's calculations confirmed such a structure is a new, metastable, lightweight form of crystal aluminum.
And to their amazement, it has a density of only 0.61 gram per cubic centimeter, in contrast to convention aluminum's density of 2.7 grams per cubic centimeter.
"That means the new crystallized form will float on water, which has a density of one gram per cubic centimeter," Boldyrev says.
Such a property opens a whole new realm of possible applications for the non-magnetic, corrosive-resistant, abundant, relatively inexpensive and easy-to-produce metal.
"Spaceflight, medicine, wiring and more lightweight, more fuel-efficient automotive parts are some applications that come to mind," Boldyrev says.
"Of course, it's very early to speculate about how this material could be used.
There are many unknowns.
For one thing, we don't know anything about its strength."
Still, he says, the breakthrough discovery marks a novel way of approaching material design.
"An amazing aspect of this research is the approach: using a known structure to design a new material," Boldyrev says.
"This approach paves the way for future discoveries."
Think of the relationship between plants and pollinators as a dance -- one that has been taking place, and evolving, for millennia.
The importance of this dance is enormous.
Pollination from bees (and birds, bats, butterflies, moths, beetles, and other animals) is necessary for the successful reproduction of a great number of plants, while pollinators gain sustenance to give birth to their next generations.
These relationships support our natural ecosystems, as well as our cultivated ones, as an incredible amount of food crops worldwide depend on plant-pollinator interaction success.
The advancement of climate change is threatening the plant-pollinator relationship.
There is evidence that a variety of seasonal cues, internal biological timings, and environmental factors currently working in harmony could become unlinked due to shifts in local climate.
To explore the impact of climate change on plant-pollinator interactions, Diane Byers (Illinois State University) and Shu-Mei Chang (University of Georgia) organized a symposium at Botany 2016, the annual meeting of the Botanical Society of America, in Savannah, Georgia.
Participants exchanged ideas and experiences using diverse methods to better understand current plant-pollinator interactions and to reveal how these interactions might be shifting due to climate change.
The results of that symposium, along with invited papers, are recently published in a special issue of Applications in Plant Sciences: Studying Plant-Pollinator Interactions Facing Climate Change and Changing Environments.
The issue focuses on the creative methods being used by researchers to understand the complex changes that are taking place.
Two articles in the issue discuss innovative techniques for measuring and exploring how floral cues and rewards, such as scent and nectar, can vary and why.
Arnold and Michaels (2017) describe a new nectar extraction technique, and present how it can be used to boost butterfly restoration strategies in prairies and oak savannas.
Burkle and Runyon (2017) demonstrate how the components of a flower's scent can be measured with specialized gas chromatography mass spectrometry (GC/MC) sensors in the field to expand our understanding of how changing climates impact a plant's ability to lure different pollinators.
On the pollinator side of the discussion, Pane and Harmon-Threatt (2017) illustrate how optimizing the use of emergence tents can provide insight into factors contributing to successful bee nesting site restoration.
Bell et al.
(2017) describe a proof-of-concept quantitative pollination network using pollen metabarcoding, sampling pollen from 38 bee species from multiple sites.
Two review articles provide overviews of methods within particular areas: Morton and Rafferty (2017) evaluate the use of spatial and temporal transplant experiments to uncover how plants and their pollinators might respond to changing local climates; and Byers (2017) delves into assessments of altered plant and pollinator phenology (the cyclical and seasonal timing in an organism's life cycle) that can shed light on new climate norms.
Together, these articles illustrate the diversity of tactics being used to deepen our understanding of plant-pollinator interactions, which are beginning to unravel in the face of climate change and other anthropogenic disturbances.
As scientists move forward in addressing these changes, their creativity and multi-faceted approaches can help plant-pollinator relationships, as well as humanity, persist.
###

Byers, D. L., and S.-M. Chang.
Studying Plant-Pollinator Interactions Facing Climate Change and Changing Environments [special issue].
Applications in Plant Sciences 5(6).
Articles in the issue: Arnold, P. M., and H. J. Michaels.
Nectar sampling for prairie and oak savanna butterfly restoration.
Applications in Plant Sciences 5(6): 1600148. doi:10.3732/apps.1600148

Bell, K. L., J. Fowler, K. S. Burgess, E. K. Dobbs, D. Gruenewald, B. Lawley, C. Morozumi, and B. J. Brosi.
Applying pollen DNA metabarcoding to the study of plant-pollinator interactions.
Applications in Plant Sciences 5(6): 1600124. doi:10.3732/apps.1600124

Burkle, L. A., and J.
B. Runyon.
The smell of environmental change: Using floral scent to explain shifts in pollinator attraction.
Applications in Plant Sciences 5(6): 1600123. doi:10.3732/apps.1600123

Byers, D. L. 2017.
Studying plant-pollinator interactions in a changing climate: A review of approaches.
Applications in Plant Sciences 5(6): 1700012. doi:10.3732/apps.1700012

Byers, D. L., and S.-M. Chang.
Studying plant-pollinator interactions facing climate change and changing environments.
Applications in Plant Sciences 5(6): 1700052. doi:10.3732/apps.1700052

Morton, E. M., and N. E. Rafferty.
Plant-pollinator interactions under climate change: The use of spatial and temporal transplants.
Applications in Plant Sciences 5(6): 1600133. doi:10.3732/apps.1600133

Pane, A. M., and A. N. Harmon-Threatt.
An assessment of the efficacy and peak catch rates of emergence tents for measuring bee nesting.
Applications in Plant Sciences 5(6): 1700007. doi:10.3732/apps.1700007

Applications in Plant Sciences (APPS) is a monthly, peer-reviewed, open access journal focusing on new tools, technologies, and protocols in all areas of the plant sciences.
It is published by the Botanical Society of America, a nonprofit membership society with a mission to promote botany, the field of basic science dealing with the study and inquiry into the form, function, development, diversity, reproduction, evolution, and uses of plants and their interactions within the biosphere.
APPS is available as part of BioOne's Open Access collection

For further information, please contact the APPS staff at apps@botany.org.
When Zika first buzzed into the continental United States during the 2016 outbreak, Florida was hit first--and hardest--with 1,174 documented cases to date.
So, when Marco Ajelli, associate research scientist at Northeastern and an expert in infectious disease modeling, wanted to study how time spent outside might affect the spread of the epidemic, he chose to focus on the state's most stricken county: Miami-Dade.
What Ajelli found was that the amount of time people spend outdoors impacts their risk for contracting the Zika virus.
Most U.S. Zika infections happen outdoors

Ajelli conducted a survey of 280 Miami-Dade residents and found the vast majority of people spend less than one hour per day outside.
The survey also revealed that a small group of people spend a large amount of time outdoors.
This is similar to the national average.
"To me that was a surprise, because the kind of weather you can have in Miami compared to Wyoming, for example, is completely different," said Ajelli.
That second group, the findings revealed, were most at risk for Zika infection.
That's because, in the U.S. most Zika infections are contracted by people outdoors.
In other regions of the world, such as the tropics, where Zika's impact has been especially severe, mosquito bites mainly occur indoors.
Therefore, time spent outside is not a big factor in understanding the epidemic's spread.
But in the U.S., there are certain groups--construction workers, for example--who are much more at risk.
According to Ajelli, the vast majority of Zika infections in the U.S. have been contracted by people outdoors.
And the first neighborhoods the virus infiltrated in the U.S. were Miami Beach and Wynwood, both known for outdoor public art and beach-related tourist activities.
Few infections, but rapid spread

Using the survey data, plus the latest available knowledge of Zika infection time and transmissibility, Ajelli developed a computational model.
It showed Zika would infect few people--predominantly those who spend large amounts of time outdoors--but would spread quickly among that specific population.
Ajelli described his findings in a paper published last week in the journal PLOS Neglected Tropical Diseases.
He said the epidemic would spread fast among people who spend lots of time outside because there are fewer of them, they have a high probability of being bitten, and it would take relatively few bites to infect the whole group.
"That means you have less time to put in place a vector control strategy.
Whatever strategy you want to implement, you have to be very quick and ready to take action, otherwise it could be too late," Ajelli said.
Ajelli said his findings suggest that outdoor time should be considered an important factor when developing a plan to halt the potential spread of Zika in the U.S. "Maybe just looking at the areas with the highest density of mosquitos is not enough," he explained.
"Of course, it is crucial, because you need to target interventions in those areas of the city, but you also have to take into account whether people spend time outdoors."
TALLAHASSEE, Fla. -- For years, scientists and physicians have been debating whether personality and behavior changes might appear prior to the onset of Alzheimer's disease and related dementias.
Now, the findings of a new and comprehensive study from FSU College of Medicine Associate Professor Antonio Terracciano and colleagues, published today in the journal JAMA Psychiatry, has found no evidence to support the idea that personality changes begin before the clinical onset of mild cognitive impairment (MCI) or dementia.
"We further found that personality remained stable even within the last few years before the onset of mild cognitive impairment," Terracciano said.
Terracciano, College of Medicine Associate Professor Angelina Sutin and co-authors from the National Institute on Aging examined data from the Baltimore Longitudinal Study of Aging.
The study looked at personality and clinical assessments obtained between 1980 and July 2016 from more than 2,000 individuals who initially showed no cognitive impairment.
About 18 percent of study participants later developed MCI or dementia.
"We compared whether personality change in people who later developed dementia differed from those who remained cognitively normal," Terracciano said.
"Unlike previous research, this study examined multiple waves of self-rated personality data collected up to 36 years before participants developed any sign of dementia."
What the researchers found is that the trajectory of personality traits did not differ between those who would later develop dementia and those who did not.
While personality change was not an early sign of dementia, Terracciano's study provides further support that personality traits (including high levels of neuroticism and low levels of conscientiousness) are risk factors for dementia.
For physicians and loved ones, personality changes remain an important consideration in the care of those who have already experienced the clinical onset of MCI or dementia.
Increasing apathy, irritability, mood changes and other behavioral symptoms impact quality of life for both patients and their caregivers.
Scientists discover several alterations in this cellular process with implications in cancer by analyzing samples from more than 4,000 patients.
Barcelona, 21 September 2017 - Cancer, which is one of the leading causes of death worldwide, arises from the disruption of essential mechanisms of the normal cell life cycle, such as replication control, DNA repair and cell death.
Thanks to the advances in genome sequencing techniques, biomedical researchers have been able to identify many of the genetic alterations that occur in patients that are common among and between tumor types.
But until recently, only mutations in DNA were thought to cause cancer.
In a new study published in the journal Cell Reports, researchers show that alterations in a process known as alternative splicing may also trigger the disease.
Although DNA is the instruction manual for cell growth, maturation, division, and even death, it's proteins that actually carry out the work.
The production of proteins is a highly regulated and complex mechanism: cellular machinery reads the DNA fragment that makes up a gene, transcribes it into RNA and, from the RNA, makes proteins.
However, each gene can lead to several RNA molecules through alternative splicing, an essential mechanism for multiple biological processes that can be altered in disease conditions.
Using data for more than 4,000 cancer patients from The Cancer Genome Atlas (TCGA project), a team led by Eduardo Eyras, ICREA research professor at the Department for Experimental and Health Sciences of the Pompeu Fabra University (DCEXS-UPF), has analyzed the changes in alternative splicing that occur in each tumor patient and studied how these changes could impact the function of genes.
The results of the study show that alternative splicing changes lead to a general loss of functional protein domains, and particularly those domains related to functions that are also affected by genetic mutations in cancer patients.
"Thanks to our previous research, we know that tumor type and stage can be predicted by observing alterations in alternative splicing", says Eyras, head of the research group in Computational RNA Biology from the Research Programme on Biomedical Informatics (GRIB), a joint research unit of the Hospital del Mar Medical Research Institute (IMIM) and the DCEXS-UPF.
"With this new study, we have discovered that changes in alternative splicing that occur in cancer impact protein functions in a way that is similar to that previously described for genetic mutations," he adds.
All of these alterations in protein functions would cause changes in cells morphology and function, giving them the characteristics of tumor cells, such as a high proliferative potential or the ability to avoid programmed cell death.
According to Adam Godzik, professor at Sanford Burnham Prebys Medical Discovery Institute (SBP) and co-author of the study, "These changes potentially have oncogenic power in cells, which means, the ability to turn a healthy cell into a cancer cell."
A novel aspect of the study is that these changes tend to occur in genes other than those often mutated in cancer, and in patients with a low number of mutated genes.
"Changes in alternative splicing provide cancer with new ways in which it can escape fine cellular regulation.
Therefore, the study of alternative splicing opens new doors in the research to cure cancer and may provide new alternatives to the treatment of this disease."
###

Reference work: Climente-Gonzlez, Hctor, Eduard Porta-Pardo, Adam Godzik, and Eduardo Eyras.
"The Functional Impact of Alternative Splicing in Cancer."
Cell Reports20, no.
9 (2017): 2215-2226.
For more information and interviews: Communication at Pompeu Fabra University - Carolina Pozo - carolina.pozo@upf.edu - 93 316 09 16
(Boston) - Stronger alcohol policies, including taxes and sales restrictions, have been shown to reduce the likelihood of alcohol involvement among homicide victims, according to a new study from Boston Medical Center (BMC) and Boston University.
The study, published online in the Journal of Studies on Alcohol and Drugs, supports the importance of alcohol control policies to reduce violence, including homicide.
Alcohol is an established risk factor for homicide perpetration and victimization.
In the U.S., between 40 and 50 percent of homicides involve the use of alcohol by either the victim or perpetrator, and more than half involve people who are significantly impaired by alcohol, which means that their blood alcohol levels are at or above 0.08 percent, the legal limit for driving.
However, little is known about how alcohol policies, which include alcohol taxes and the number of places licensed to sell alcohol, relate to alcohol-related homicides.
The new study looked at the relationship between alcohol policies in place and the likelihood of alcohol involvement (either up to the legal limit of 0.08 or above that limit) among the 27,000 victims of homicide from 17 U.S. states between 2003 and 2012.
The data analyzed was from the Centers for Disease Control and Prevention's National Violent Death Reporting System.
State alcohol policies for each year were characterized using the "Alcohol Policy Scale," a measure of the policy "environment" based on 29 separate alcohol control policies.
Stronger, more restrictive state alcohol policies were protective when alcohol was involved in a homicide.
Specifically, a 1 percent increase in the restrictiveness of policies corresponded to a 1 percent reduction in likelihood of alcohol involvement among homicide victims.
"Given the risks involved with alcohol use, strengthening effective alcohol policies could help prevent homicides," said Timothy Naimi, MD, the study's lead author who is a physician in general internal medicine at BMC and researcher at BMC's Grayken Center for Addiction Medicine.
Furthermore, findings were similarly protective among important groups who account for a large proportion of deaths or who are particularly vulnerable, including young adult homicide victims, those who died in intimate partner violence-related homicides, and those who died from firearms-related homicides, including murders involving guns.
"Both alcohol and guns are significant social determinants of homicide, either considered independently or in combination, and it is important to recognize the potential of policy to help curb these critical problems," said Naimi, who also is associate professor at both BU School of Medicine and BU School of Public Health.
###

About Boston Medical Center
DARIEN, IL - September 21, 2017 - A new study suggests that while healthy preterm children have more medical sleep problems than full-term children, they are more likely to fall asleep independently.
Results show that preterm children displayed more medical sleep problems such as nocturnal movement, restlessness during the night and breathing problems, compared with those born at full term.
However, a lower degree of behavioral sleep problems were present in preterm children.
"Preterm children needed less support to fall asleep and fell asleep more often alone in their own bed compared to those born at full term," said principal investigator Dr. Barbara Caravale, a researcher in the Department of Developmental and Social Psychology at Sapienza University in Rome, Italy.
"However, preterm children showed more frequent sleep difficulties, such as restlessness and breathing problems during the night."
Study results are published in the September 15 issue of the Journal of Clinical Sleep Medicine.
The study involved 51 preterm children with normal cognitive, language, and motor development, and 57 full-term children.
Their average age was 21 months.
Mothers completed a series of questionnaires to assess sleep-related difficulties, sleep habits and child temperament.
The study found no differences between the two groups of children in bedtime, rise time or sleep duration.
However, Caravale noted that the sleep problems reported by the parents of preterms may have resulted in sleep disruption, which could help explain significant differences in attention and emotionality.
"We observed a link between sleep pattern and temperament in preterm children," said Caravale.
"Our study found that sleep problems were related to increased negative emotionality and decreased attention."
According to the authors, these results are consistent with previous studies demonstrating that children born preterm are at risk of attention and learning problems as well as emotional difficulties.
For this reason, it is important that pediatricians screen for sleep problems more rigorously in preterm children, especially with respect to sleep-related breathing disorders such as obstructive sleep apnea and sleep-related movement disorders.
###

For a copy of the study, "Sleep Characteristics and Temperament in Preterm Children at Two Years of Age," or to arrange an interview with the study author or an AASM spokesperson, please contact AASM Communications Coordinator Corinne Lederhouse at 630-737-9700, ext.
9366, or clederhouse@aasm.org.
The startling global resurgence of pertussis, or whooping cough, in recent years can largely be attributed to the immunological failures of acellular vaccines, Boston University School of Public Health (BUSPH) researchers argue in a new journal article.
The article, published in F1000 Research, points to the differences in mucosal immunity between whole-cell pertussis (wP) vaccines and the newer acellular pertussis (aP) vaccines, first introduced in the 1990s, as playing a pivotal role in the resurgence of the disease.
"This disease is back because we didn't really understand how our immune defenses against whooping cough worked, and did not understand how the vaccines needed to work to prevent it," said Christopher J. Gill, associate professor of global health at BUSPH and lead author of the article.
"Instead we layered assumptions upon assumptions, and are now find ourselves in the uncomfortable position of admitting that we may made some crucial errors.
This is definitely not where we thought we'd be in 2017."
Up until the 1950s, there were millions of cases of whooping cough around the globe each year, with numerous fatal cases in infants.
The introduction of whole-cell pertussis (wP) vaccines led to a 99 percent reduction in cases.
Later, as wP vaccines raised concerns of possible rare neurologic adverse events, aP vaccines were licensed and used in a number of countries starting in the early 1990s.
Since then, cases of whooping cough have risen sharply.
In 2014, there were more than 32,000 cases reported in the US.
"The resurgence of pertussis in the US to its highest levels since the 1940s emphasizes the need for answers to these questions," the authors wrote.
The researchers examined mathematical models of pertussis transmission, data derived from the aP and wP vaccines responses in animals, and recent insight into the immunology of pertussis and pertussis vaccines.
They found that, contrary to existing assumptions, although both vaccines blocked symptomatic disease, wP vaccines blocked also infections in animals while aP vaccines did not.
Other differences included wP vaccines' ability to induce a stronger herd immunity and robust TH17 responses, which confer mucosal immunity, while aP vaccines only induced TH2 responses.
Experimental and immunologic data has shown that aP vaccines do not provide herd immunity, while mathematical models imply otherwise.
The researchers proposed a hypothesis to reconcile the contradictory findings: Herd effects from aP vaccines may be the result of modifications in disease presentation that lead to reduced possibility of transmission rather than induced resistance to infection.
The researchers also considered the role of several known factors in the rise of whooping cough cases, including detection bias, waning of immunity, and evolutionary shifts in the bacteria's genome.
They found that, while contributing to the increase in incidence, these factors alone do not fully explain existing epidemiologic data.
Citing the urgency of the growing health crisis, the authors emphasized the need to go beyond the limitations of animal models and provide human data to further examine the arguments put forth in their article.
"The resurgence of pertussis in the aP vaccine era is evolving into a slow-moving global public health crisis," the researchers wrote.
"But, with the public's trust in vaccines waning, this has also become a public relations crisis."
###

Don Thea, professor of global health at BUSPH, was a co-author on the article.
About Boston University School of Public Health:

Boston University School of Public Health, founded in 1976, offers master's- and doctoral-level education in public health.
The faculty in six departments (biostatistics; community health sciences; environmental health; epidemiology; global health; and health law, policy & management) conduct policy-changing public health research around the world, with the mission of improving the health of populations--especially the disadvantaged, underserved, and vulnerable--locally, nationally, and internationally.
Utilizing messages focused on images created by local artists and written information communicated through local dialects proved essential to counter misperceptions during the Ebola epidemic in Sierra Leone, according to a study conducted in part by Muriel J. Harris, Ph.D., associate professor, University of Louisville School of Public Health and Information Sciences, Department of Health Promotion and Behavior Sciences.
Targeted on two Ebola 'hotspots' in Sierra Leone, urban Freetown and the rural Bombali district, the study involved engaging the community in the development of Ebola messaging to address common concerns about the disease.
Harris, who collaborated on the project in 2014 through her work with principal investigator John Kinsman, Ph.D., Umea University, and the Centre for Health and Research Training, Sierra Leone (CHaRT-SL), says health officials realized the top-down messaging strategy wasn't working.
New communication needed to be developed around numerous concerns, including the perception of disrespectful treatment of Ebola victims and bereaved families by burial teams; fear of ambulances with regard to driver competency and air flow within the vehicles; and fear over the use of chlorine procedures within ambulances and of use by burial teams.
To ensure their findings were utilized and implemented appropriately, the researchers recommended using trusted messengers to engage in two-way communication and assigning appropriate officials to listen to community concerns during an outbreak.
A report was then presented to the Ministry of Health.
"The recommendations could be far-reaching as they represent an evidence-based approach to message development and implementation during public health emergencies, including other infectious disease outbreaks," Harris said.
Harris helped design the study methodology and also took part in final data analysis.
The article, "Development of a set of community-informed Ebola messages for Sierra Leone," published recently in PLOS Neglected Tropical Diseases.
Hurricane Maria has caused catastrophic flooding in Puerto Rico and left a wake of heavy rainfall that NASA measured using a fleet of satellites in space.
NASA satellite imagery also saw Maria's eye close up as it tracked across Puerto Rico and re-open after its exit.
Calculating Maria's Rainfall

The Global Precipitation Measurement mission or GPM core satellite, a joint mission between NASA and the Japan Aerospace Exploration Agency can measure rainfall from space.
That rainfall data, combined with data from other satellites provided a tally of Hurricane Maria's rainfall over the course of several days.
At NASA's Goddard Space Flight Center in Greenbelt, Maryland, NASA's Integrated Multi-satellitE Retrievals for GPM (IMERG) data were used to estimate the total amount of rain that Hurricane Maria dropped from Sept. 17 to early Sept. 21, 2017.
During that period Maria dropped heavy rain in the Leeward Islands, Virgin Islands and Puerto Rico.
IMERG estimated that rainfall totals greater than 10 inches (254 mm) were common along Maria's track.
IMERG rainfall estimates indicated that more than 20 inches (512 mm) of rain fell over a large part of Puerto Rico.
Extreme flooding was reported in the streets of San Juan, the capital of Puerto Rico.
The National Weather Service issued flash flood warnings for the entire island.
Hurricane Maria has now moved to the northwest of Puerto Rico but is still expected to contribute to rainfall over the island on Friday.
Feeder bands of thunderstorms are transporting rain over Puerto Rico and the Dominican Republic even as the hurricane moves toward the Turks and Caicos Islands.
Hurricane Maria's Eye Winks

Hurricane Maria made landfall near Yabucoa, Puerto Rico, around 6:15 a.m. EDT/AST on Sept. 20.
Maximum sustained winds in the hurricane were reported to be 149.5 mph (130 knots) as Maria moved toward San Juan, Puerto Rico.
On Sept. 20 at 10:50 a.m. EDT (14:50 UTC) NASA's Terra satellite provided a visible image as Hurricane Maria was moving over Puerto Rico.
Maria's eye had become obscured by clouds.
On Sept. 21 at 1:54 a.m. EDT (0554 UTC) the VIIRS instrument aboard NASA-NOAA's Suomi NPP satellite provided a thermal image of Hurricane Maria after it re-emerged eye moved off the coast of Puerto Rico and as just northeast of Hispaniola.
The image showed that the eye had become visible again and powerful thunderstorms with very cold cloud tops surrounded it's eye.
Another infrared image of Hurricane Maria was taken from the Atmospheric Infrared Sounder or AIRS instrument aboard NASA's Aqua satellite on Sept. 21 at 2:05 a.m. EDT (0605 UTC).
Maria's eye opened up, and there were clear areas where the sea surface shows through.
Powerful thunderstorms circle the large eye where cloud top temperatures of strong thunderstorms in Maria's eyewall as cold as or colder than minus 63 degrees Fahrenheit (minus 53 Celsius).
Warnings and Watches in Effect on Sept. 21

The National Hurricane Center (NHC) said a Hurricane Warning is in effect for the Dominican Republic from Cabo Engano to Puerto Plata, Turks and Caicos Islands and the Southeastern Bahamas.
A Tropical Storm Warning is in effect for the Dominican Republic west of Puerto Plata to the northern border of the Dominican Republic and Haiti, Dominican Republic west of Cabo Engano to Andres/Boca Chica.
A Tropical Storm Watch is in effect for the Central Bahamas.
Location and Status of Maria on Sept. 21

At 11 a.m. EDT/AST (1500 UTC), the large eye of Hurricane Maria was located near 20.2 north latitude and 69.1 degrees west longitude.
That's about 105 miles (175 km) east-northeast of Puerto Plata, Dominican Republic and about 155 miles (255 km) southeast of Grand Turk Island.
Maria is moving toward the northwest near 9 mph (15 kph), and this general motion is expected to continue through tonight.
The minimum central pressure based on aircraft data is 960 millibars.
Data from an Air Force Reserve reconnaissance aircraft indicate that maximum sustained winds remain near 115 mph (185 kph) with higher gusts.
Maria is a category 3 hurricane on the Saffir-Simpson Hurricane Wind Scale.
Some strengthening is possible during the next day or so.
Hurricane-force winds extend outward up to 60 miles (95 km) from the center and tropical-storm-force winds extend outward up to 150 miles (240 km).
The NHC said "A turn toward the north-northwest is forecast early Friday, with that motion continuing through early Saturday.
On the forecast track, Maria's eye will continue to pass offshore of the northern coast of the Dominican Republic today, and then move near or just east of the Turks and Caicos Islands and southeastern Bahamas tonight and on Friday, Sept. 22.
From self-folding robots, to robotic endoscopes, to better methods for computer vision and object detection, researchers at the University of California San Diego have a wide range of papers and workshop presentations at the International Conference on Intelligent Robots and Systems (or IROS) which takes place from Sept. 24 to 28 in Vancouver, Canada.
UC San Diego researchers also are organizing workshops on a range of themes during the event.
"IROS is one of the premier conferences in robotics," said Henrik Christensen, director of the Contextual Robotics Institute and a professor of computer science at UC San Diego.
"It is essential for our institute that we present key papers across manufacturing, materials, healthcare and autonomy.
I am very pleased to see that we have a strong showing at this flagship conference."
The conference this year focuses on "friendly people, friendly robots."
Robots and humans are becoming increasingly integrated in various application domains, conference organizers explain on the IROS 2017 website.
"We work together in factories, hospitals and households, and share the road," organizers said.
"This collaborative partnership of humans and robots gives rise to new technological challenges and significant research opportunities in developing friendly robots that can work effectively with, for, and around people."
Soft robotics is one way to create robots that are not dangerous for humans and the research group of roboticist Michael Tolley is exploring the field with three papers at IROS 2017.
Better interactions between robots and people also require improving computer vision and researchers led by computer scientist Laurel Riek are proposing using depth information to do so in one paper.
Computer scientist Gary Cottrell has a paper on improving object recognition processes.
Meanwhile, electrical engineer Michael Yip is looking to make medical robots like the Da Vinci surgical system even better.
Tolley also is one of the organizers of the Sept. 28 workshop titled "Folding in Robotics."
Yip is one of the organizers of the Sept. 24 workshop titled "Continuum Robots in Medicine, Design, Integration, and Applications."
Mechanical engineer Nicholas Gravish is one of the organizers for the Sept. 28 "Robotics-inspired Biology" workshop.
###

Conference papers:

Custom Soft Robotic Gripper Sensor Skins for Haptic Object Visualization

Benjamin Shih, Dylan Drotman, Caleb Christianson, Zhaoyuan Huo, Ruffin White, Henrik Iskov Christensen and Michael Thomas Tolley, Univ.
of California, San Diego

Video: https:/ / youtu.
be/ Hs14LALfmnQ

Towards Rapid Mechanical Customization of Cm-Scale Self-Folding Agents

William Weston-Dawkes, Aaron Ong, Majit Abdul, Ramzi Mohamad, Francis Joseph, and Michael Thomas Tolley,Univ.
of California, San Diego

Video: https:/ / youtu.
be/ JSAmBnOtCks

Differential Pressure Control of 3D Printed Soft Fluidic Actuators

Tom Kalisky, Yueqi Wang, Benjamin Shih, Dylan Drotman, Saurabh Jadhav, Spencer Aronoff, and Michael Thomas Tolley, Univ.
of California, San Diego

Video: https:/ / youtu.
be/ JSAmBnOtCks

Faster Robot Perception Using Salient Depth Partitioning

Darren Chan, Angelique Taylor, and Laurel D. Riek, Univ.
of California San Diego

Belief Tree Search for Active Object Recognition

Mohsen Malmir and Garrison W. Cottrell, Univ.
of California, San Diego

retraining the supervised LSTM network, the AOR performance on the test set improves significantly.
Visual Feedback Control of Tensegrity Robotic Systems

Haresh Karnan, Raman Goyal and Manoranjan Majji, Texas A&M Univ, Robert E. Skelton, Univ.
of California, San Diego and Puneet Singla, State Univ.
of New York at Buffalo

Workshop papers:

Screw-Propelled Endoscopic Robot

Kevin Cheng, Andrew Saad, Dmitrii Votintcev, Elaine Tanaka, Michael Yip, Univ.
of California, San Diego

Robot Control of Endoscopic Instruments using Flexible Polymer Sheath

Aaron Gunn, Mrinal Verghese, Wesly Wong, Michael Yip, Univ.
of California, San Diego
A new study published in JNCI Cancer Spectrum finds that smoking negatively impacts long-term survival after breast cancer.
Quitting smoking after diagnosis may reduce the risk of dying from breast cancer.
This study aimed to examine whether smoking at the time of diagnosis and changes in smoking within five years after diagnosis were associated with long-term breast cancer mortality.
In a study population of 1508 Long Island women with breast cancer, subjects were interviewed and asked a variety of questions, including about smoking status.
At the five-year follow-up, participants responded to the same questions, which asked about the time period since the original questionnaire.
While breast cancer survival rates in the United States are high, estimated at 90% at five years after diagnosis, approximately 40,000 women will die from breast cancer in 2017.
This makes breast cancer the second leading cause of cancer-related death among women.
Compared to never smokers, the risk of all-cause mortality was elevated among the 19% of at-diagnosis smokers.
Risk of all-cause mortality was further increased among the 8% of women who were at-/post-diagnosis smokers, but was reduced among the 11% women who quit smoking after diagnosis.
Compared to never smokers, smoking at the time of breast cancer diagnosis was associated with a 69% increased risk of all-cause mortality.
Risk of all-cause mortality was increased 50% for current smokers who smoked fewer than 20 cigarettes/day and 85% for current smokers who smoked more than 20 cigarettes/day.
All-cause mortality was also increased among former smokers and current smokers who had smoked for more than 30 years.
The risk of all-cause mortality was elevated 130% among women who continued smoking after diagnosis as compared to never smokers.
Although risk of all-cause mortality remained elevated among women who quit smoking after diagnosis, the increase in risk of mortality was estimated at 83% compared to never smokers.
Similar patterns were observed for risk of breast cancer-specific mortality, which was elevated 60% among women who continued smoking after diagnosis, but was not elevated among those who quit smoking, compared to never smokers.
The results of the study show that smoking negatively impacts long-term survival after breast cancer.
For the 10 to 20% of women who are smokers at the time of breast cancer diagnosis, smoking cessation is one important behavioral change that may improve survival after breast cancer.
"Studies of smoking and breast cancer survival have generally focused on at-diagnosis smoking as a prognostic indicator," said the study's author, Dr. Humberto Parada of the University of North Carolina at Chapel Hill, "We considered the impact of post-diagnosis changes in smoking and show that quitting smoking after diagnosis may be important to improve survival among women with breast cancer.
Future studies should continue to study the mechanisms by which smoking impacts breast cancer specific-survival."
Prospective survival cohorts such as this one "help quantity the mortality burden faced by active smokers with malignancies not traditional thought to be smoking related," wrote Michael N. Passarelli and Polly A. Newcomb in an editorial accompanying the study.
"Evidence that smoking cessation benefits even those who quit soon after diagnosis should serve as continued motivation for breast cancer survivors to pursue positive health behavior changes."
###

The paper "Post-Diagnosis Changes in Cigarette Smoking and Survival Following Breast Cancer," is available at: https:/ / academic.
com/ jncics/ article/ 4191272/ Postdiagnosis-Changes-in-Cigarette-Smoking-and

To request a copy of the study, please contact:

Daniel Luzer

daniel.luzer@oup.com

Direct correspondence to:

Humberto Parada Jr, MPH, PhD

UNC Chapel Hill, Department of Epidemiology

2101 McGavran-Greenberg Hall, CB #7435

Chapel Hill, NC 27599-7435

919-636-9236

hparada@live.unc.edu

Sharing on social media?
Find Oxford Journals online at @OxfordJournals
Investigators at the Children's Center for Cancer and Blood Diseases at Children's Hospital Los Angeles have identified new findings about an immune cell - called a tumor-associated macrophage - that promotes cancer instead of fighting it.
They have identified the molecular pathway, known as STAT3, as the mechanism the immune cell uses to foster neuroblastoma, a pediatric cancer, and have demonstrated use of a clinically available agent, ruxolitinib, to block the pathway.
Results of the study were published in the journal Oncotarget on September 20.
Neuroblastoma is the second most common solid tumor effecting children.
Individuals with high-risk disease have a mortality rate of approximately 50 percent.
Certain conditions are associated with high-risk disease.
High levels of some chemicals involved with inflammation and the presence of an immune cell called a tumor-associated macrophage (TAM) are associated with high-risk disease and lower survival rates.
Macrophages are a type of immune cell that typically function to battle disease, not encourage it.
"The macrophages are essentially co-opted by the tumor cells to help them grow," said Shahab Asgharzadeh, MD, director of the Basic and Translational Neuroblastoma program at CHLA and lead investigator of the study.
"We're trying to find out more about the mechanisms that enable TAMs to help cancer grow so that we can target the pathways they use and block their pro-tumor effect."
The team wanted to find out whether effective therapeutic approaches for children with neuroblastoma could be based on targeting inflammation-associated biologic pathways in the area surrounding the tumor, called the tumor microenvironment.
Using a mouse model to examine the activity of TAMs within the tumor microenvironment, the research team observed the "recruitment and polarization" of TAMs which enhance the ability of neuroblastoma to spread and grow.
They found that TAMs exhibit a dual role - not only nourishing the neuroblastoma but also effectively helping them to evade the "good immune cells" seeking to kill the tumor cells.
To study the effect of TAMs on neuroblastoma cell growth and proliferation, the investigators co-cultured both mouse and human neuroblastoma cells with TAMs and found a significant increase compared to tumor cells without TAMs.
In an effort to find out what the TAMs were secreting that caused stimulation of tumor cells, the investigators targeted IL-6, an immune substance known to cause proliferation of certain types of cancer.
Using a mouse model that lacked IL-6, they still observed increased tumor growth.
In these experiments, they noted activation of the STAT3 cell-signaling pathway - known to promote tumor growth preceding an increase of MYC - a gene that drives many types of cancer.
These findings led them to target the STAT3 pathway.
Using a clinically available drug, ruxolitinib, known to block the STAT3 pathway, the investigators co-cultured both human and mouse TAMs and neuroblastoma cells.
They observed that the immune cells no longer supported tumor growth.
"Targeting STAT3 may be a promising approach to block interactions between tumor cells and the 'traitorous' immune cells, and a way to improve outcomes for children with high-risk neuroblastoma," said Asgharzadeh, who is also a professor of pediatrics with the Keck School of Medicine of the University of Southern California.
According to Asgharzadeh, the next step is to combine agents that block the STAT3 pathway with drugs that have been effective in treating neuroblastoma.
###

Other contributors to the paper include Michael D. Hadjidaniel, Sakunthala Muthugounder, Long T. Hung, Michael A. Sheard, Soheila Shirinbak, Randall Y. Chan, Rie Nakata, Lucia Borriello, Jemily Malvar, Rebekah J. Kennedy, Hiroshi Iwakura, Takashi Akamizu, Richard Sposto, Hiroyuki Shimada, and Yves A. DeClerck, all of Children's Hospital Los Angeles, along with Hiroshi Iwakura and Takashi Akamizu of the First Department of Medicine, Wakayama Medical University in Japan.
Asgharzadeh, Sposto, Simada and DeClerck are also faculty members of the Keck School of Medicine of USC.
The research was supported by grants from the Department of Defense (CDMRP10669916), (W81XWH-12-1-0571), the T.J. Martell Foundation, the Norris Foundation, the Nautica Malibu Triathlon and the National Institutes of Health U54 (5U54CA163117).
About Children's Hospital Los Angeles

Children's Hospital Los Angeles has been ranked the top children's hospital in California and sixth in the nation for clinical excellence with its selection to the prestigious U.S. News & World Report Honor Roll.
CHLA is home to The Saban Research Institute, one of the largest and most productive pediatric research facilities in the United States.
Children's Hospital is also one of America's premier teaching hospitals through its affiliation with the Keck School of Medicine of the University of Southern California since 1932.
For more information, visit CHLA.org.
Follow us on Twitter, Facebook, YouTube, LinkedIn and Instagram, and visit our child health blog (CHLA.org/blog) and our research blog (ResearCHLABlog.org).
Many research groups have recently explored human adaptation and successfully identified candidate genes to high altitude living among three major far-flung global populations: Tibetans, Ethiopians and Peruvians.
But few have simultaneously explored the other extreme---maladaptation----in the form of chronic mountain sickness (CMS), also known as Monge's disease, which is characterized by the production of an excessive number of red blood cells.
Now, in the largest whole genome study of its kind, an international research team led by University of California San Diego's Chairman of Pediatrics, Dr. Gabriel Haddad, has expanded on their recent study of understanding both adaptation extremes in a Peruvian population.
"CMS incidence is highest in Andeans (~18%), lesser in Tibetans (1-11%), and yet, completely absent from the Ethiopian populations, further mystifying this disease pathogenesis," said Haddad.
"Therefore, a clear understanding of its pathophysiology would be beneficial to the large high-altitude populations at risk of developing this syndrome.
It would also provide insights in understanding many disease pathophysiologies where hypoxia plays a major role, at sea level, e.g., stroke, cardiac ischemia, obstructive sleep apnea, sickle cell disease."
A total of 94 individuals equally divided into CMS and non-CMS subjects participated in the study.
They hailed from Cerro de Pasco, one of the largest, high elevation settlements in the world (more than 50,000 people living at greater than 14,000 feet (4300 meters), high up in the Andes.
Next, using available genetic tools and a new custom algorithm, the researchers sifted through the genomes to identify and categorize all of the favored mutations from the Peruvians.
Overall, they identified 11 regions containing 38 genes that were of statistical significance.
Nine of these genes were also tested in hypoxia experiments to validate their functional role using the research lab model organism, the fruit fly Drosophila melanogaster.
"In this study, we present the results of an expanded whole genome sequence analysis of CMS and non-CMS subjects and identify additional candidate regions that are under positive selection," said Haddad.
"Indeed, the larger sample size, the robust selection methods, and the use of a novel statistical test for prioritization all allowed us to uncover novel genes involved in HA adaptation.
Additionally, using Drosophila as a model organism, we found that certain candidate genes, when downregulated in Drosophila, induced more tolerance to hypoxia than controls."
Intriguingly, the majority of the mutations were found in noncoding regions of the genome that may be playing an important regulatory role in finely tuning the levels of gene expression.
"We suspect that this molecular adaptation allows for more genetic flexibility, that plausibly regulates transcript abundance, adjusting with the physiological responses to environmental challenges such as hypoxia," said Haddad.
The results of the study will contribute significantly to the multi-factorial genetic understanding of high-altitude adaptation and the physiology of hypoxia.
In addition, the researchers' new algorithm can be adapted to further the other studies trying to identify the genomic hallmarks of human adaptation.
Multiple sclerosis can be inhibited or reversed using a novel gene therapy technique that stops the disease's immune response in mouse models, University of Florida Health researchers have found.
By combining a brain-protein gene and an existing medication, the researchers were able to prevent the mouse version of multiple sclerosis.
Likewise, the treatments produced near-complete remission in the animal models.
The findings, which researchers said have significant potential for treating multiple sclerosis and other autoimmune disorders, are published today (Sept. 21) in the journal Molecular Therapy.
Multiple sclerosis affects about 2.3 million people worldwide and is the most common neurological disease in young adults.
The incurable disorder starts when the immune system attacks the myelin sheath surrounding nerve fibers, making them misfire and leading to problems with muscle weakness, vision, speech and muscle coordination.
The researchers used a harmless virus, known as an adeno-associated virus, to deliver a gene responsible for a brain protein into the livers of the mouse models.
The virus sparked production of so-called regulatory T cells, which suppress the immune system attack that defines multiple sclerosis.
The gene was targeted to the liver because it has the ability to induce immune tolerance.
"Using a clinically tested gene therapy platform, we are able to induce very specific regulatory cells that target the self-reactive cells that are responsible for causing multiple sclerosis," said Brad E. Hoffman, Ph.D., an assistant professor in the departments of pediatrics and neuroscience at the University of Florida College of Medicine.
The protein, myelin oligodendrocyte glycoprotein, was found to be effective in preventing and reversing muscular dystrophy on its own.
A group of five mouse models that received the gene therapy did not develop experimental autoimmune encephalomyelitis, which is the mouse equivalent of multiple sclerosis in humans.
In another experiment, all but one mouse model showed a significant reversal of the disease eight days after a single gene therapy treatment.
Hoffman said he was also encouraged by the treatment's longevity.
After seven months, the mouse models that were treated with gene therapy showed no signs of disease, compared with a group of untreated mouse models that had neurological problems after 14 days.
When the protein was combined with rapamycin -- a drug used to coat heart stents and prevent organ transplant rejection -- its effectiveness was further improved, the researchers found.
The drug was chosen because it allows helpful regulatory T-cells to proliferate while blocking undesirable effector T-cells, Hoffman said.
Among the mouse models that were given rapamycin and the gene therapy, 71 percent and 80 percent went into near-complete remission after having hind-limb paralysis.
That, Hoffman said, shows the combination can be especially effective at stopping rapidly progressing paralysis.
While researchers have established how gene therapy stimulates regulatory T cells in the liver, Hoffman said little else is known about the detailed mechanics of how that process works.
Before the therapy can be tested in humans during a clinical trial, further research involving other preclinical models will be needed, Hoffman said.
Researchers also need to target the full suite of proteins that are implicated in multiple sclerosis, he added.
Still, Hoffman said he is extremely optimistic that the gene therapy can be effective in humans.
"If we can provide long-term remission for people and a long-term quality of life, that is a very promising outcome," he said.
###

The research was funded by grants from the National Multiple Sclerosis Society, the National Institutes of Health and the Children's Miracle Network.
DETROIT - A novel psychological therapy that encourages addressing emotional experiences related to trauma, conflict and relationship problems has been found helpful for people with the chronic pain condition fibromyalgia.
A research team led by Mark A. Lumley, Ph.D., distinguished professor of psychology in the College of Liberal Arts and Sciences at Wayne State University, in collaboration with a team from the University of Michigan Medical Center led by David A. Williams, Ph.D., professor of anesthesiology, has released the results of its research in the prestigious journal, PAIN.
In the randomized clinical trial, 230 adults with fibromyalgia received one of three treatments, each of which was presented for eight weekly sessions to small groups of patients.
The new therapy, which Lumley and co-developer Howard Schubiner, M.D., director of the Mind Body Medicine Program at Providence Hospital, call Emotional Awareness and Expression Therapy (EAET), helps patients view their pain and other symptoms as stemming from changeable neural pathways in the brain that are strongly influenced by emotions.
EAET helps patients process emotional experiences, such as disclosing important struggles, learning how to adaptively express important feelings -- especially anger and sadness but also gratitude, compassion, and forgiveness -- and empowering people to be more honest and direct in relationships that have been conflicted or problematic.
The EAET intervention was compared to both an educational intervention as well as the gold standard psychological approach in the field, cognitive behavioral therapy.
Six months after treatments ended, patients were evaluated for the severity and extent of their pain and other problems that people with fibromyalgia often experience.
Patients who received EAET had better outcomes -- reduced widespread pain, physical impairment, attention and concentration problems, anxiety, and depression and more positive emotions and life satisfaction -- than patients who received the education intervention.
More than twice as many people in EAET (34.8 percent) reported that they were "much better" or "very much better" than before treatment, compared to 15.4 percent of education patients.
An important additional finding was that the new emotion therapy also had greater benefits than cognitive behavior therapy in reducing widespread pain and in the number of patients who achieved at least 50 percent pain reduction.
"Many people with fibromyalgia have experienced adversity in their lives, including victimization, family problems and internal conflicts, all of which create important emotions that are often suppressed or avoided.
Emerging neuroscience research suggests that this can contribute strongly to pain and other physical symptoms," Lumley said.
"We developed and tested an approach that tries to help people overcome these emotional and relationship problems and reduce their symptoms, rather than just help people manage or accept their fibromyalgia.
Although this treatment does not help all people with fibromyalgia, many patients found it to be very helpful, and some had dramatic improvements in their lives and their health."
###

More information about the research study, "Emotional awareness and expression therapy, cognitive behavioral therapy, and education for fibromyalgia: a cluster-randomized controlled trial," can be found in PAIN, a journal published by the International Association for the Study of Pain (doi: 10.1097/j.pain.0000000000001036).
About Wayne State University

Wayne State University is one of the nation's pre-eminent public research universities in an urban setting.
Through its multidisciplinary approach to research and education, and its ongoing collaboration with government, industry and other institutions, the university seeks to enhance economic growth and improve the quality of life in the city of Detroit, state of Michigan and throughout the world.
For more information about research at Wayne State University, visit research.wayne.edu.
WASHINGTON -- A new imaging technique makes it possible to precisely digitize clear objects and their surroundings, an achievement that has eluded current state-of-the-art 3D rendering methods.
The ability to create detailed, 3D digital versions of real-world objects and scenes can be useful for movie production, creating virtual reality experiences, improving design or quality assurance in the production of clear products and even for preserving rare or culturally significant objects.
"By more accurately digitizing transparent objects, our method helps move us closer to eliminating the barrier between the digital and physical world," said Jonathan Stets, Technical University of Denmark, and co-leader of the research team that developed the pipeline.
"For example, it could allow a designer to place a physical object into a digital reality and test how changes to the object would look."
Transparent objects are challenging to digitize because their appearance comes almost completely from their surroundings.
Although a CT scanner can acquire a clear object's shape, this requires removing the object from its surroundings and lighting, which must also be captured to accurately recreate the object's appearance.
The researchers detail their approach to digitizing transparent objects in The Optical Society journal Applied Optics.
A key innovation in developing the new method was the use of a robotic arm to record the precise locations of two cameras used to image scenes containing a clear object.
Having this detailed spatial information allowed the researchers to take photographs of the scene, remove the object and scan it in a CT scanner and then place it back into the scene -- both digitally and in real life -- to accurately compare the real-life scene and its virtual reconstruction.
Pixel-by-pixel comparison "The robotic arm allows us to obtain a photograph and a 2D computed, or rendered, image that can be compared pixel by pixel to measure how well the images match," said Alessandro Dal Corso, co-leader of the research team.
"This quantitative comparison was not possible with previous techniques and requires extremely precise alignment between the digital rendering and photograph."
Once the digital versions of the objects are finalized, the method provides information about the object's material properties that are distinct from its shape.
"This allows the scanned glass objects to still look realistic when placed in a completely different digital environment," explained Jeppe Frisvad, a member of the research team.
"For example, it could be placed on a table in a digital living room or on the counter in a virtual kitchen."
Using an optical setup containing readily available components, the researchers tested their new workflow by digitizing three scenes, each containing a different glass object on a table with a white and gray checkerboard backdrop.
They began by acquiring structured light scans of the scene, an imaging method that uses the deformation of a projected pattern to calculate the depth and surfaces of objects in the scene.
They also used a chrome sphere to acquire a 360-degree image of the surroundings.
The scene was illuminated with LEDs arranged in an arc to capture how light coming from different angles interacted with the opaque parts of the scene.
The researchers also separately scanned the glass objects in a CT scanner, which provided information to reconstruct the object's surface.
Finally, the digital version of the scene and the rendered glass object were combined to produce a 3D representation of the whole scene.
Quantitative analysis showed that the images of the digital scene and the real-world scene matched well and that each step of the new imaging workflow contributed to the similarity between the rendered images and the photographs.
"Because the photographs are taken under controlled conditions, we can make quantitative comparisons that can be used to improve the reconstruction," said Frisvad.
"For example, it is difficult to judge by eye if the object surface reconstructed from the CT scan is accurate, but if the comparison shows errors, then we can use that information to improve the algorithms that reconstruct the surface from the CT scan."
A new way to measure optical properties The approach also provides a non-contact way to measure a material's optical properties.
This makes the technique potentially useful for a wide range of applications beyond movies and virtual reality.
For example, the approach could allow researchers to create a digital rendering of an object and then tweak a parameter, such as the index of refraction, to better understand the properties of the real-life material.
While previous technologies sometimes require chipping off a piece of the object to measure its optical properties, the new technique could be useful for analyzing rare or valuable transparent objects without harming the object.
The technique could also be applied to help engineers refine the design or manufacture of clear products.
The researchers want to expand their approach to other challenges in 3D rendering, such as rendering objects that exhibit a metallic shine or that are translucent.
They are also working on ways to speed up acquisition of the various images and scans so that the approach could be used for quality assurance in the production of clear products.
###

Paper: J. D. Stets, A. Dal Corso, J.
B. Nielsen, R. A. Lyngby, S. H. N. Jensen, J. Wilm, M. B. Doest, C. Gundlach, E. R. Eiriksson, K. Conradsen, A.
B. Dahl, J.
A. Baerentzen, J. R. Frisvad, H. Aanaes, "Scene reassembly after multimodal digitization and pipeline evaluation using photorealistic rendering," Applied Optics, Volume 56, Issue 27, 7679-7690 (2017).
DOI: 10.1364/AO.56.007679

About Applied Optics

Applied Optics publishes in-depth peer-reviewed content about applications-centered research in optics.
These articles cover research in optical technology, photonics, lasers, information processing, sensing and environmental optics.
It is published by The Optical Society and edited by Ronald Driggers, St. Johns Optical Systems.
About The Optical Society

Founded in 1916, The Optical Society (OSA) is the leading professional organization for scientists, engineers, students and business leaders who fuel discoveries, shape real-life applications and accelerate achievements in the science of light.
Through world-renowned publications, meetings and membership initiatives, OSA provides quality research, inspired interactions and dedicated resources for its extensive global network of optics and photonics experts.
For more information, visit osa.org.
Media Contacts:

Rebecca B. Andersen

202-416-1443

randersen@osa.org



Joshua Miller

202-416-1435

jmiller@osa.org
ANN ARBOR--Inspired by the Labyrinth of Greek mythology, a new chip etched with fluid channels sends blood samples through a hydrodynamic maze to separate out rare circulating cancer cells into a relatively clean stream for analysis.
It is already in use in a breast cancer clinical trial.
Tumor cells isolated from blood samples have the potential to revolutionize cancer treatment by enabling doctors to plan customized treatments, monitor genetic changes, and flag the presence of aggressive cells that are likely to spread the cancer.
The trouble is that circulating cancer cells account for just one in a billion blood cells, and there weren't good options for accurately capturing cancer stem cells, which are thought to be especially aggressive and drug resistant.
"You cannot put a box around these cells," said Sunitha Nagrath, University of Michigan associate professor of chemical engineering, who led the development of the chip along with Max Wicha, the Madeline and Sidney Forbes Professor of Oncology at Michigan Medicine.
Wicha is one of the pioneers of the cancer stem cell hypothesis.
Cancer stem cells are fluid in their gene expression, transitioning from stem-like cells that are good at surviving in the blood to more ordinary cell types that are better at growing and dividing.
Conventional cell targeting, by grabbing proteins known to be on the cell's surface, doesn't work well.
"The markers for them are so complex, there is no one marker we could target for all these stages," Nagrath said.
Size-based sorting gets around this problem, but until the labyrinth, this technique was too imprecise to use on its own.
Conventional chips, with spiral-shaped channels, left each cancer cell contaminated with thousands of other cells--particularly white blood cells.
The labyrinth riffs on the spiral, sorting the blood's contents according to the sizes of the cells, with smaller white and red blood cells accumulating in different parts of the fluid channel.
A number of forces are at play: on the inside of a curve, eddies push particles away from the wall.
The larger cancer cells are pushed a bit harder than the smaller white blood cells.
At the outside of the curve, smaller particles feel more drawn to the wall.
But the innovation of the labyrinth is its daring number of corners.
"Bigger cells, like most cancer cells, focus pretty fast due to the curvature.
But the smaller the cell is, the longer it takes to get focused," Nagrath said.
"The corners produce a mixing action that makes the smaller white blood cells come close to the equilibrium position much faster."
The tortuous route also meant that Eric Lin, U-M doctoral student in chemical engineering and first author on the paper in Cell Systems, was able to fit 60 centimeters of channel on a chip that would only contain 10 centimeters in a spiral layout.
Moreover, without the need to wait for cancer cells to bind with traps or markers, the blood flow through the chip was very fast.
The team could reduce the number of white blood cells contaminating the cancer cell sample by 10 times just by running the captured portion of the blood through a second labyrinth chip--a process that took only five extra minutes.
A thousand white blood cells mixed in with about 9 to 50 tumor cells might seem like a lot, but this level of contamination is manageable in the single cell analysis lab.
The team analyzed individual cells to explore which genes were active--and which mutations were present--in the cancer cells.
Through genetic profiling, the team could pick out cells that were on their way to and from stem-like states, capturing the spectrum of cancer stem cells.
They tested the chip with blood samples from pancreatic and late-stage breast cancer patients.
"We think that this may be a way to monitor patients in clinical trials," Wicha said.
"Rather than just counting the cells, by capturing them, we can perform molecular analysis so know what we can target with treatments."
In Wicha's clinical trial, run by Monika Burness, a lecturer in hematology and oncology, the labyrinth chip is isolating cancer cells from the blood of patients with an aggressive form of breast cancer.
The trial is investigating whether a treatment blocking an immune signaling molecule called interleukin-6, which helps heal wounds by temporarily activating adult stem cells, can make progress against cases of breast cancer that don't respond to standard treatments.
The suspicion is that the interleukin-6 is enabling cancer stem cells, so they expect to see the population of stem-like cells in the blood fall during treatment.
###

The paper in Cell Systems is titled "High throughput microfluidic labyrinth for the label free isolation of CTCs for single cell gene expression profiling."
This work was supported by the National Institutes of Health and the Department of Defense.
Additional support came from the Breast Cancer Research Foundation, MedImmune, and the Fashion Footwear Charitable Foundation of New York/QVC Presents Shoes on Sale.
What the increase may mean for the future of grasslands

Woody vegetation, such as trees and shrubs, has increased dramatically in Ozark grasslands over the past 75 years, according to a study published this week in the journal Landscape Ecology.
The study examines grasslands called dolomite glades in the Mark Twain National Forest near Ava, Missouri.
It analyzed historical aerial photos and found that woody vegetation cover increased from 8 percent in 1939 to 59 percent in 2014.
Fire was largely absent from this landscape between 1939 and 1984 and then was reintroduced within the past 30 years.
The study shows that while prescribed fire has helped "hold the line" against woody encroachment, it has not been able to reverse it.
It added that the chances of reversing it are unlikely once woody plants cover more than 40 percent of the landscape.
Meanwhile, unburned grassland areas have largely become densely wooded.
THE FUTURE OF GRASSLANDS

The study area is characteristic of a range of grassland and savanna ecosystems, and the findings raise questions about the future of grasslands: if, despite intensive management efforts, these ecosystems continue to favor woody vegetation, will it be possible to maintain open grasslands for the foreseeable future?
Grasslands represent a major component of biodiversity in the Ozarks.
Most plants and animals in these habitats need open grasslands and won't tolerate dense areas of trees and shrubs.
PRESCRIBED FIRE 'ESSENTIAL'

"We show that prescribed fire is essential to the continued existence of these grasslands," said lead author Jesse Miller, who completed the research as a Ph.D. student at the University of Wisconsin-Madison.
He is now a postdoctoral researcher at the University of California, Davis.
"Fire was largely removed from the landscape for several decades.
Now we better understand the ecological importance of fire for grasslands, and we're still trying to reverse changes to grasslands that occurred during the period of fire exclusion."
The study said that successful restorations require vigilant monitoring and management.
The authors suggest that grassland restoration should not remove all woody plants, as some species, such as oaks, have been present historically.
When possible, managers should prioritize maintaining existing grassland habitat and intervening before woody vegetation becomes so dense that it requires mechanical removal.
###

The research was supported by the National Science Foundation and the NSF Graduate Research Fellowship.
More information:

Comparisons of 1939 and 2014 woody vegetation can be seen on Miller's blog.
Chronic tissue inflammation resulting from obesity is an underlying cause of insulin resistance and type 2 diabetes.
But the mechanism by which this occurs has remained cloaked, until now.
In a paper, published in the journal Cell on September 21, University of California San Diego School of Medicine researchers identified exosomes -- extremely small vesicles or sacs secreted from most cell types -- as the missing link.
"The actions induced by exosomes as they move between tissues are likely to be an underlying cause of intercellular communication causing metabolic derangements of diabetes," said Jerrold Olefsky, MD, professor of medicine in the Division of Endocrinology and Metabolism at UC San Diego School of Medicine and senior author of the paper.
"By fluorescently labeling cells, we could see exosomes and the microRNA they carry moving from adipose (fat) tissue through the blood and infiltrating muscle and liver tissues."
During chronic inflammation, the primary tissue to become inflamed is adipose.
Forty percent of adipose tissue in obesity is comprised of macrophages -- specialized immune cells that promote tissue inflammation.
Macrophages in turn create and secrete exosomes.
When exosomes get into other tissues, they use the microRNA (miRNA) they carry to induce actions in the recipient cells.
The macrophage-secreted miRNAs are on the hunt for messenger RNAs.
When the miRNA finds a target in RNA, it binds to it, rendering the messenger RNA inactive.
The protein that would have been encoded by the messenger RNA is no longer made.
Thus, the miRNAs are a way to inhibit the production of key proteins.
A team led by Olefsky, associate dean for scientific affairs, took macrophages found in adipose tissue of obese mice and harvested their exosomes.
Lean, healthy mouse models were treated with these "obese" exosomes and once-normal mice began exhibiting obesity-induced insulin resistance despite not being overweight.
When reversing the process, the team found that they could restore insulin sensitivity to obese mice by treating them with exosomes from lean mice.
The obese mice remained overweight, but were metabolically healthy.
Similarly, during an in vitro study, when human liver and fat cells were treated with "obese" exosomes, these cells became insulin resistant.
Conversely, when they were treated with "lean" macrophage exosomes, they became highly sensitive to insulin.
"This is a key mechanism of how diabetes works," said Olefsky.
"This is important because it pins the pathophysiology of the disease in inflamed adipose tissue macrophages which are making these exosomes.
If we can find out which of the microRNAs in those exosomes cause the phenotype of diabetes, we can find drug targets."
Olefsky estimates there are probably several hundred miRNAs in exosomes, but only 20 to 30 are key.
Determining which miRNAs to target will require more research, but the team has already found one likely suspect: microRNA-155, which inhibits a well-known metabolic protein called PPAR.
The researchers note that there are existing clinically effective anti-diabetic drugs that target this protein, but they trigger side effects deemed not acceptable in clinical practice.
"Still, there are a number of microRNAs that we hope will lead to new, highly druggable targets resulting in new insulin-sensitizing therapeutics," said Olefsky.
"We can obtain exosomes from blood -- known as a liquid biopsy -- to sequence all of these microRNAs."
By sequencing exosomes, researchers can obtain genetic signatures that could lead to biomarkers for this disease, similar to how liquid biopsies are used to find drugs that will be effective in cancer treatment.
Olfesky hopes that biomarkers for diabetes will one day be used to determine if a person is at high risk of diabetes in the next year or never.
Biomarkers may also predict which patients will respond to specific therapies.
"If we sequence your exosomes, we get a signature to determine the metabolic state of your liver cells, fat cells, macrophages and beta cells," said Olefsky.
"We would be able to tell you what is going on in your liver without ever doing a tissue biopsy."
While the team was focused on exosomes from adipose tissue, there are also exosomes created in the liver and in other cells.
Olefsky is interested in studying these exosomes to determine if they also move into other tissues and cause metabolic actions.
"This could go beyond insulin resistance," said Olefsky.
"Exosomes could be causing other complications of obesity that may not be related to metabolism."
###

Co-authors include: Wei Ying, Matthew Riopel, Guatam Bandyopadhyay, Yi Dong, Amanda Birmingham, Jong Bae Seo, Jachelle M. Ofrecio, Joshua Wollam, Angelina Hernandez-Carretero, Wenxian Fu, UC San Diego; and Pingping Li, Chinese Academy of Medical Sciences & Peking Union Medical College.
Patients with "metal on metal" (MoM) artificial hips are at risk of complications caused by adverse reactions to metal debris (ARMD).
A study in the September 20, 2017 issue of The Journal of Bone & Joint Surgery confirms that blood metal ion levels specific to the type of hip implant used can help predict patients who are at low risk of ARMD.
The journal is published in partnership with Wolters Kluwer.
Using implant-specific cutoff points resulted in fewer missed cases of ARMD compared to using fixed thresholds currently recommended by US and UK regulatory authorities, according to the report by Gulraj S. Matharu BSc(Hons), MRCS, MRes, DPhil of University of Oxford and colleagues.
Their findings offer a refined approach to predicting the risk of ARMD in patients with two widely used types of metal-on-metal hip replacements: the Birmingham Hip Resurfacing (BHR) implant and the Corail-Pinnacle implant.
The research was funded by Arthritis Research UK (grant reference number 21006).
Blood Metal Ion Levels Identify Patients at Low Risk of ARMD

Patients can develop adverse reactions to the metal debris generated from the implant surfaces sliding over each other in the artificial joint.
Measuring levels of chromium and cobalt ions in the blood--reflecting the presence of small particles from the worn implant surfaces--is recommended as part of patient follow-up for early detection of ARMD.
However, there is no agreement as to the specific blood metal ion levels that should raise concern after MoM hip replacement.
Previous studies by Dr. Matharu and colleagues suggested that using implant-specific thresholds could improve the ability to detect patients at low risk of developing ARMD.
To confirm this approach, the researchers performed an external validation study including 710 patients (803 hips) who underwent MoM hip replacement with one of the two aforementioned MoM hip prostheses at three European hospitals.
Implant-specific versus fixed regulatory authority cutoff points for blood metal ion levels were tested for their ability to correlate with clinically diagnosed ARMD, rates of which were 12 percent after single-hip BHR replacement, 18 percent after double-hip BHR replacement, and 7 percent after single-hip Corail-Pinnacle replacement.
The implant-specific cutoff points performed well in distinguishing between patients with and without ARMD.
Sensitivity--the percentage of patients with ARMD who had ion levels above the implant-specific threshold--ranged from 65 to 79 percent in the three groups.
Just as important, the negative predictive value--the percentage of patients without ARMD who had ion levels below the threshold--was 93 to 97 percent across groups.
Overall, the implant-specific cutoff points identified all but 2.8 percent of ARMD cases.
In contrast, the fixed regulatory authority cutoff points missed up to 6.5 percent of cases.
Early identification of ARMD is important, especially for some patients where early revision (implant removal and replacement) can reduce complications and give a better outcome for the patient.
The new findings confirm the value of implant-specific blood metal levels in helping assess the risk of ARMD after MoM hip replacement.
Using these cutoff points helps to pinpoint patients who should be monitored more closely for possible ARMD, while also minimizing the use of additional testing in patients unlikely to have or develop ARMD.
But Dr. Matharu and colleagues emphasize that no single test can determine whether a patient actually has ARMD or what treatment is needed.
They write, "[B]lood metal ion levels should be only a part of the complete clinical assessment."
###

Read the article: Blood Metal Ion Thresholds to Identify Patients with Metal-on-Metal Hip Implants at Risk of Adverse Reactions to Metal Debris: An External Multicenter Validation Study of Birmingham Hip Resurfacing and Corail-Pinnacle Implants

Article DOI: 10.2106/JBJS.16.01568

About The Journal of Bone & Joint Surgery

The Journal of Bone & Joint Surgery (JBJS) has been the most valued source of information for orthopaedic surgeons and researchers for over 125 years and is the gold standard in peer-reviewed scientific information in the field.
A core journal and essential reading for general as well as specialist orthopaedic surgeons worldwide, The Journal publishes evidence-based research to enhance the quality of care for orthopaedic patients.
Standards of excellence and high quality are maintained in everything we do, from the science of the content published to the customer service we provide.
JBJS is an independent, non-profit journal.
About Wolters Kluwer

Wolters Kluwer N.V. (AEX: WKL) is a global leader in information services and solutions for professionals in the health, tax and accounting, risk and compliance, finance and legal sectors.
We help our customers make critical decisions every day by providing expert solutions that combine deep domain knowledge with specialized technology and services.
Wolters Kluwer reported 2016 annual revenues of 4.3 billion.
The company, headquartered in Alphen aan den Rijn, the Netherlands, serves customers in over 180 countries, maintains operations in over 40 countries and employs 19,000 people worldwide.
Wolters Kluwer shares are listed on Euronext Amsterdam (WKL) and are included in the AEX and Euronext 100 indices.
Wolters Kluwer has a sponsored Level 1 American Depositary Receipt program.
The ADRs are traded on the over-the-counter market in the U.S. (WTKWY).
Wolters Kluwer Health is a leading global provider of information and point of care solutions for the healthcare industry.
For more information about our products and the organization, visit http://www.
wolterskluwer.
com/ , follow @WKHealth or @Wolters_Kluwer on Twitter, like us on Facebook, follow us on LinkedIn, or follow WoltersKluwerComms on YouTube.
INDIANAPOLIS -- Although many juvenile offenders report that they believe they have experienced police injustice, little has been known about how this perception of police injustice may impact future behavior.
A new Indiana University-Purdue University Indianapolis study of juvenile offenders finds that when youth perceive police injustice, it affects not only how they view the justice system, but also their rates of aggression.
The study found that youth who tended to justify behaviors that violate general moral standards, such as believing it is OK to lie or fight, were also more likely to be aggressive.
However, this relationship was found only among juvenile offenders who also reported high levels of perceived police injustice.
"Future aggression appears to be highest among youth who do not believe that ethical standards apply to them, which we refer to as moral disengagement, but only when they also perceive injustice by police," said clinical psychologist Tamika Zapolski, the lead author of the study.
"We need to understand the contexts in which these juvenile offenders live so we can foster things like community policing to counter perceptions such as 'the police are out to get me' or 'the police hate everyone in my neighborhood,'" she said.
Zapolski is an assistant professor of psychology in the School of Science at IUPUI and directs PRISM, the Prevention Research in Substance Use and Minority Health Lab in the School of Science.
PRISM focuses on risk for substance use and other health behaviors among African-Americans.
"Other studies have looked at community views of police officers and how that impacts juvenile offenders' behavior and recidivism," said study co-author Matthew Aalsma.
"What this study adds is the insight that moral disengagement, or believing ethical standards don't apply to you, when combined with perceptions of negative interactions with police officers, is associated with increased aggression."
Aalsma is a juvenile forensic psychologist and a professor of pediatrics and psychology at Indiana University School of Medicine.
The study surveyed 95 juvenile offenders.
The researchers concluded that intervention programs that address perceptions of perceived police injustice as well moral disengagement may be beneficial at reducing aggression among youth involved in the juvenile justice system.
"Perceived Police Injustice, Moral Disengagement, and Aggression Among Juvenile Offenders: Utilizing the General Strain Theory Model?"
is published in Child Psychiatry & Human Development.
Authors in addition to Zapolski and Aalsma are Devin E. Banks of the School of Science at IUPUI and Katherine Lau of State University of New York at Oneonta.
###

Funders of the study included the U.S. Department of Health and Human Services' Health Resources and Services Administration and the Indiana Criminal Justice Institute.
CAMBRIDGE, MA -- If at first you don't succeed, try, try again.
A new study from MIT reveals that babies as young as 15 months can learn to follow this advice.
The researchers found that babies who watched an adult struggle at two different tasks before succeeding tried harder at their own difficult task, compared to babies who saw an adult succeed effortlessly.
The study suggests that infants can learn the value of effort after seeing just a couple of examples of adults trying hard, although the researchers have not studied how long the effect lasts.
Although the study took place in a laboratory setting, the findings may offer some guidance for parents who hope to instill the value of effort in their children, the researchers say.
"There's some pressure on parents to make everything look easy and not get frustrated in front of their children," says Laura Schulz, a professor of cognitive science at MIT.
"There's nothing you can learn from a laboratory study that directly applies to parenting, but this does at least suggest that it may not be a bad thing to show your children that you are working hard to achieve your goals."
Schulz is the senior author of the study, which appears in the Sept. 21 online edition of Science.
Julia Leonard, an MIT graduate student, is the first author of the paper, and MIT undergraduate Yuna Lee is also an author.
Putting in the effort

Many recent studies have explored the value of hard work.
Some have found that children's persistence, or "grit," can predict success above and beyond what IQ predicts.
Other studies have found that children's beliefs regarding effort also matter: Those who think putting in effort leads to better outcomes do better in school than those who believe success depends on a fixed level of intelligence.
Leonard and Schulz were interested in studying how children might learn, at a very early age, how to decide when to try hard and when it's not worth the effort.
Schulz' previous work has shown that babies can learn causal relationships from just a few examples.
"We were wondering if they can do similar fast learning from a little bit of data about when effort is really worth it," Leonard says.
To do that, they designed an experiment in which 15-month-old babies first watched an adult perform two tasks: removing a toy frog from a container and removing a key chain from a carabiner.
Half of the babies saw the adult quickly succeed at the task three times within 30 seconds, while the other half saw her struggle for 30 seconds before succeeding.
The experimenter then showed the baby a musical toy.
This toy had a button that looked like it should turn the toy on but actually did not work; there was also a concealed, functional button on the bottom.
Out of the baby's sight, the researcher turned the toy on, to demonstrate that it played music, then turned it off and gave it to the baby.
Each baby was given two minutes to play with the toy, and the researchers recorded how many times the babies tried to press the button that seemed like it should turn the toy on.
They found that babies who had seen the experimenter struggle before succeeding pressed the button nearly twice as many times overall as those who saw the adult easily succeed.
They also pressed it nearly twice as many times before first asking for help or tossing the toy.
"There wasn't any difference in how long they played with the toy or in how many times they tossed it to their parent," Leonard says.
"The real difference was in the number of times they pressed the button before they asked for help and in total."
The researchers also found that direct interactions with the babies made a difference.
When the experimenter said the infants' names, made eye contact with them, and talked directly to them, the babies tried harder than when the experimenter did not directly engage with the babies.
"What we found, consistent with many other studies, is that using those pedagogical cues is an amplifier.
The effect doesn't vanish, but it becomes much weaker without those cues," Schulz says.
A limited resource

A key takeaway from the study is that people appear to be able to learn, from an early age, how to make decisions regarding effort allocation, the researchers say.
"We're a somewhat puritanical culture, especially here in Boston.
We value effort and hard work," Schulz says.
"But really the point of the study is you don't actually want to put in a lot of effort across the board.
Effort is a limited resource.
Where do you deploy it, and where do you not?"
The researchers hope to investigate how long this effect might last after the initial experiment.
Another possible avenue of research is whether the effect would be as strong with different kinds of tasks -- for example, if it was less clear to the babies what the adult was trying to achieve, or if the babies were given toys that were meant for older children.
###

The research was funded by the National Science Foundation Graduate Research Fellowship Program, the MIT Center for Brains, Minds and Machines, and the Simons Center for the Social Brain.
Diet and exercise may improve treatment outcomes in pediatric cancer patients, according to a study at The University of Texas MD Anderson Children's Cancer Hospital.
The findings, published in the September 13 online issue of Pediatrics Research, also revealed that diet and exercise have strong potential to improve chemotherapy effectiveness and reduces the risk of late effects in pediatric cancer patients.
This discovery propels the need for more work to determine how energy balance -- a combination of diet and exercise -- can be implemented effectively during treatment to manage or treat obesity.
The researchers reviewed 67 studies including 32 novel clinical trials in pediatric patients, and data from a variety of cohorts with pediatric patients diagnosed with different cancers, including patients with acute lymphoblastic leukemia (ALL), rhabdomyosarcoma and brain tumors.
The cellular mechanisms by which energy balance impacts tumor growth was also highlighted.
The relationship between diet and exercise and its positive effects on treatment outcomes in obese cancer patients has sparked interest for quite some time, but for pediatric patients, the research has been limited.
While healthy eating is encouraged during and after treatment, special diet interventions as part of treatment for pediatric patients are uncommon.
Additionally, when it comes to physical activity, clinicians are cautious about administering an exercise regimen in a cancer care setting.
"The purpose of the review was to delineate between obesity reduction as a goal for energy balance interventions versus simply changing diet or adding exercise," said Joya Chandra, Ph.D., associate professor of Pediatric Research and lead author on the study.
"For example, our review confirmed modifying diet or adding moderate exercise can improve chemotherapy efficacy independent of weight loss."
Obesity, an epidemic and risk factor for several cancers, is on the rise in pediatric cancer patients, globally.
According to Chandra, who is also the co-director of MD Anderson's Center for Energy Balance in Cancer Prevention and Survivorship, obese pediatric patients diagnosed with leukemia and bone cancers have a lower prognosis for survival.
Research also indicated that obese patients have a higher rate of relapse and do not respond to treatment as well as other pediatric patients.
The analysis also shows genetic predisposition to obesity will require a more targeted pathway for treatment.
Although research confirms a poor diet and sedentary lifestyle lead to obesity, additional research is needed to understand how diet and exercise affects tumors in different cancers.
For example, physical activity is known to control BMI and obesity, and to improve quality of life, but choosing the right exercise protocol can be challenging.
Currently there are no known clinical trials examining the effects of physical activity on treatment efficacy in pediatric patients.
Keri Schadler, Ph.D., assistant professor of Pediatric Research at MD Anderson, and co-author on the paper says there are many factors to consider when tailoring an exercise regimen including the type of tumor, patient health status, and frequency and duration of the exercise.
"Exercise during treatment is safe and improves physical fitness in patients," said Schadler.
"We have several clinical trials underway including one testing exercise interventions in bone tumor patients."
The research team also is administering nutrition interventions and looking at weight trajectory in ALL patients.
Ongoing studies evaluating diet and exercise interventions and their impact on chemotherapy efficacy, and long-term toxicity risk for leukemia, Ewing's sarcoma, and osteosarcoma are also underway.
"The results from our study gives credibility to the need for energy balance interventions in clinical settings to improve treatment outcomes for pediatric patients," said Eugenie Kleinerman, M.D., professor of Pediatrics, and the study's co-author.
###

The study was funded by the MD Anderson Cancer Foundation Multidisciplinary Research Program (MRP).
Patients can be infected again and again, but research could lead to first successful vaccine for superbug MRSA and other staph bacteria

LOS ANGELES (Sept. 21, 2017) -- For years, medical investigators have tried and failed to develop vaccines for a type of staph bacteria associated with the deadly superbug MRSA.
But a new study by Cedars-Sinai investigators shows how staph cells evade the body's immune system, offering a clearer picture of how a successful vaccine would work.
Staph frequently causes skin infections but occasionally can lead to deadly conditions such as sepsis, pneumonia and bloodstream infections, particularly in hospitalized patients whose immune systems could be weakened by illness.
One strain of the bacterium, the superbug methicillin-resistant Staphylococcus aureus (MRSA), is considered one of the top drug-resistant threats in the U.S., causing more than 11,000 deaths per year, according to the Centers for Disease Control and Prevention.
In fact, the superbug kills more Americans than HIV.
"Widespread MRSA infections have prompted routine use of once last-line antibiotics, and this is making the antibiotic resistance problem worse," said George Liu, MD, PhD, co-lead author of the study and a pediatric infectious diseases physician at Cedars-Sinai's Maxine Dunitz Children's Health Center and the F. Widjaja Foundation Inflammatory Bowel and Immunobiology Research Institute.
"Our study focuses on why MRSA is so common and why we never develop immunity to these bacteria."
The study, published in the peer-reviewed journal Cell Host & Microbe, also sheds light on how investigators could develop an effective vaccine against staph.
When exposed to a pathogen like a staph bacterium, the body usually fights it and then forms a memory of how its immune system responded.
The next time the body encounters the same pathogen, it can use that memory to fight off the microbe much more easily.
But the body can suffer from repeated staph infections throughout life without developing a robust protective memory immune response.
The study shows that staph bacteria are able to dodge this immune response.
When the staph cell wall primarily is kept intact after infecting a host, bacterial molecules don't escape the staph cell and the body isn't prompted to produce robust protective immune memory.
"Essentially, staph tricks the body's T cells, which are white blood cells that fight infection, and prevents them from mounting an effective defense," said co-lead author Gislaine Martins, PhD, an assistant professor at the F. Widjaja Foundation Inflammatory Bowel and Immunobiology Research Institute and departments of Biomedical Science and Medicine.
As a result, the body does not develop long-term immunity and remains vulnerable to that particular staph infection throughout life.
While certain staph bacteria cause mild skin infections, other strains of staph bacteria can wreak havoc in the bloodstream and bones, sometimes leading to amputations.
"The study explains why our immune system is fooled by staph," Martins said.
"Staph evolved to have this enzyme that makes this modification in its cell wall.
This modification protects the wall from degradation and therefore from being properly detected by the immune system, which won't remember the bacteria the next time the body is infected."
When study authors removed the cell wall modification, the staph cells spilled their molecules more easily.
The modified bacteria sparked a robust memory immune response that protected against reinfection.
The study provides clues about what type of element could be added to staph vaccines to make them more effective.
Whereas most staph vaccines have tried to stimulate antibodies -- specialized molecules that recognize foreign bodies and help to mobilize the immune system -- this study suggests that a successful vaccine should harness the body's T cells.
###

Funding for this work was provided by NIH research grants R01AI103542,?R21AI083948 and R01AI127406 and by the F. Widjaja Foundation IBIRI Institute, Cedars-Sinai Medical Center.
About Cedars-Sinai

Cedars-Sinai is a leader in providing high-quality healthcare encompassing primary care, specialized medicine and research.
Since 1902, Cedars-Sinai has evolved to meet the needs of one of the most diverse regions in the nation, setting standards in quality and innovative patient care, research, teaching and community service.
Today, Cedars-Sinai is known for its national leadership in transforming healthcare for the benefit of patients.
Cedars-Sinai impacts the future of healthcare by developing new approaches to treatment and educating tomorrow's health professionals.
Additionally, Cedars-Sinai demonstrates a commitment to the community through programs that improve the health of its most vulnerable residents.
DOI: 10.1016/j.chom.2017.08.008
CAMBRIDGE, Mass.
-- Sometimes things that are technically defects, such as imperfections in a material's crystal lattice, can actually produce changes in properties that open up new kinds of useful applications.
New research from a team at MIT shows that such imperfections in a family of materials known as insulating metal oxides may be key to their performance for a variety of high-tech applications, such as nonvolatile memory chips and energy conversion technologies.
The findings are reported this week in the journal Physical Review Letters, in a paper by MIT Associate Professor Bilge Yildiz, Professor and Associate Provost Krystyn Van Vliet, and former postdoc Mostafa Youssef.
These metal oxide materials have been investigated by many researchers, Yildiz says, and "their properties are highly governed by the number and the kind of defects that are present."
When subjected to strong driving forces, such as strong electric fields, "the behavior of such defects had not been well-understood," she says.
Researchers do have a well-established theoretical understanding of how perfectly structured versions of these insulating metal oxides function under a variety of conditions, such as in strong electric fields, but there was no such theory to describe the materials when they contain common types of defects, according to Yildiz.
Understanding these effects quantitatively is important in order to develop this promising family of materials for potential applications including new types of low-energy computer memory and processing devices, electrically based refrigeration, and electro-catalytic energy-conversion devices such as fuel cells.
The team demonstrated a theoretical framework and showed how the stability and structure of a point defect is altered under strong electric fields.
They took a common defect called a neutral oxygen vacancy -- a place where an oxygen atom should appear in the lattice but instead two electrons are trapped.
Their results have quantified the polarization behavior of the material with this defect, in an electric field.
"The oxygen vacancies in particular are very important in electronic and electrochemical applications," says Yildiz, who holds joint appointments in the departments of Nuclear Science and Engineering and Materials Science and Engineering.
In many of these applications, she says, there can be an internal voltage gradient created within the thin-film material, and this "electric potential" gradient causes strong electric fields.
Understanding the effects of those fields is essential for the design of certain new devices.
"Most of the work in this area is experimental," Yildiz says.
"You take a thin film, you put it in an electric field, and you do measurements."
But in such experiments, the effects of the local electric potential and the electric field are convoluted, making it very hard to understand the results.
"It's impossible to resolve them from each other, so you need to have a theory" to account for the effects, she adds.
The researchers have now devised a new theoretical framework that allows them to isolate the electric field effect from the electric potential effect, and quantify both independently.
This allowed them to make very specific predictions that are different from those produced by classical theory and should make it possible to validate the new model experimentally within a year, Yildiz says.
The findings should help enable the development of some important potential applications, she says.
One is in a new type of computer memory device known as resistive switching memory, which provides fast switching speeds using very little energy.
These memory devices rely on the presence of defects.
"The way they switch their resistance state [to record data] depends on the defect type, content, and distribution," she says.
"In order to model the device behavior, you should be able to model how the applied strong electric fields alter the defect structure, concentration, and distribution."
That's what this new work enables: "If you know quantitatively the effects of both the potential and the field, then you can design your operating conditions to benefit from these effects."
Understanding these effects is also important for other applications such as splitting water molecules to produce hydrogen at solid-liquid interfaces, electronic devices that rely on oxide-oxide interfaces, or other electrochemical processes using these materials as catalysts, where defects serve as the sites that enable the interactions.
The materials the team studied belong to a class known as alkaline-earth-metal binary oxides, whose constituents are "among the most abundant class of materials on Earth," Yildiz says.
"[This class is] cheap, abundant, and has tunable properties," making it promising for many applications.
But she adds that the theoretical approach they took will now be applied much more broadly, to many other kinds of oxide materials and to other kinds of defects within them besides the neutral oxygen vacancies.
###

The research was supported by the MRSEC Program of the National Science Foundation and used resources of the National Energy Research Scientific Computing Center, a Department of Energy Office of Science User Facility supported by the Office of Science of the U.S. Department of Energy.
ITHACA, N.Y. - Human activities could change the pace of evolution, similar to what occurred 66 million years ago when a giant asteroid wiped out the dinosaurs, leaving modern birds as their only descendants.
That's one conclusion drawn by the authors of a new study published in Systematic Biology.
Cornell University Ph.D. candidate Jacob Berv and University of Bath Prize Fellow Daniel Field suggest that the meteor-induced mass extinction (a.k.a.
the K-Pg event) led to an acceleration in the rate of genetic evolution among its avian survivors.
These survivors may have been much smaller than their pre-extinction relatives.
"There is good evidence that size reductions after mass extinctions may have occurred in many groups of organisms," says Berv.
"All of the new evidence we have reviewed is also consistent with a Lilliput Effect affecting birds across the K-Pg mass extinction."
Paleontologists have dubbed this phenomenon the "Lilliput Effect" -- a nod to the classic tale Gulliver's Travels.
"Smaller birds tend to have faster metabolic rates and shorter generation times," Field explains.
"Our hypothesis is that these important biological characters, which affect the rate of DNA evolution, may have been influenced by the K-Pg event."
The researchers jumped into this line of inquiry because of the long-running "rocks and clocks" debate.
Different studies often report substantial discrepancies between age estimates for groups of organisms implied by the fossil record and estimates generated by molecular clocks.
Molecular clocks use the rate at which DNA sequences change to estimate how long ago new species arose, assuming a relatively steady rate of genetic evolution.
But if the K-Pg extinction caused avian molecular clocks to temporarily speed up, Berv and Field say this could explain at least some of the mismatch.
"Size reductions across the K-Pg extinction would be predicted to do exactly that," says Berv.
"The bottom line is that, by speeding up avian genetic evolution, the K-Pg mass extinction may have temporarily altered the rate of the avian molecular clock," says Field.
"Similar processes may have influenced the evolution of many groups across this extinction event, like plants, mammals, and other forms of life."
The authors suggest that human activity may even be driving a similar Lilliput-like pattern in the modern world, as more and more large animals go extinct because of hunting, habitat destruction, and climate change.
"Right now, the planet's large animals are being decimated--the big cats, elephants, rhinos, and whales," notes Berv.
"We need to start thinking about conservation not just in terms of functional biodiversity loss, but about how our actions will affect the future of evolution itself."
###

This research was supported by a National Science Foundation Graduate Research Fellowship and Doctoral Dissertation Improvement Grant to Berv, and a National Sciences and Engineering Council of Canada Graduate Scholarship to Field.
Berv was also supported by a Cornell Lab of Ornithology Athena Grant.
Field is supported by a 50th Anniversary Prize Fellowship at the University of Bath.
Cornell University has television, ISDN and dedicated Skype/Google+ Hangout studios available for media interviews.
WASHINGTON - Halting the opioid epidemic requires aggressive action across multiple dimensions, including informed, active, and determined front-line leadership from health clinicians working in every setting throughout the nation, says a new National Academy of Medicine (NAM) special publication developed at the request of the National Governors Association to assist the nation's governors as they work with clinicians to counter the opioid crisis.
Authored by leading national authorities on substance use disorders, the 30-page paper is an action guide for clinicians - physicians, physician assistants, nurses, nurse practitioners, dentists, social workers, behavioral health practitioners, pharmacists, and first responders - if they are prescribing an opioid or managing a patient who presents with a likely opioid use disorder.
To successfully marshal progress, the paper calls for clinicians to prioritize non-opioid strategies when managing chronic pain, follow five axioms of responsible opioid prescribing, and promote policies that stimulate and support available scientific evidence.
"This paper speaks in particular to the roles of clinicians, both as primary gatekeepers for the appropriate use of these drugs and as first responders to the consequences of their misuse," said J. Michael McGinnis, NAM Leonard D. Schaeffer Executive Officer.
"Moreover, the paper serves as a call to action for the nation's clinicians to assume their broader leadership responsibilities and advance the health of the communities in which they live and work."
"The group of experts who wrote this publication are key leaders from the nation's scientific, professional, and policy organizations.
Only through this sort of collaboration can we make real progress in countering the opioid crisis and its toll on patients, communities, states, and the nation as a whole," said Victor J. Dzau, president of the National Academy of Medicine.
"Clinicians are not expected to make these changes alone.
To truly have maximum impact on the health of their communities, they must work with patients and families, community leaders, elected officials, and the business community.
All clinicians, regardless of their focus or specialty, must work toward the goal of patient health and well-being."
Many factors have intersected to drive the rate and reach of the opioid epidemic, the publication says.
Prescribing practices have played a substantial role, but those practices have been shaped in turn by circumstances ranging from those medical in nature - such as increases in chronic diseases, new surgical interventions, and professional calls for better pain management - to the influence of market distortions, including large quantities of unused opioids easily accessible in the home.
In 2015, about one-third of American adults used a prescribed opioid, with the total number of prescriptions exceeding 225 million, or about 71 prescriptions per 100 persons, according to the Centers for Disease Control and Prevention.
Recognition of the crisis has prompted the development of strong efforts to raise awareness among clinicians of the need for vigilance and counter-action, which is beginning to take some effect.
In particular, the recent National Academies report Pain Management and the Opioid Epidemic: Balancing Societal and Individual Risks of Prescription Opioid Use challenges clinicians and health care systems to re-evaluate how opioids fit into the larger array of pain management strategies.
Except for conditions such as cancer, palliative care, and end-of-life, clinicians should first look to non-opioid approaches that are effective for chronic pain control, the publication says.
If the realistic benefits outweigh the serious risks of opioids for a given patient, clinicians should use them in combination with other modalities, as appropriate, to provide greater benefits to patients in improving pain and function.
In addition, when prescribing opioids, clinicians should follow five axioms that include tailoring the treatment for each patient, employing precautionary protocols, actively managing and monitoring the patient, working as a team with the patient and family, and linking to treatment services.
The publication identifies the range of clinician leverage points important for countering the epidemic and its consequences, including:

Using a team approach to care, which is especially important in substance use disorders.
Emphasizing that substance use disorders are treatable chronic neurologic conditions, requiring a sustained, multifaceted approach typical in managing any chronic disease.
Precautionary prescribing that accounts for individual risk factors and social circumstances.
Counseling on secure storage and proper disposal of unused opioids.
Cross-checking the Prescription Drug Monitoring Program registry to identify unsafe drug use behaviors.
Providing systematic follow-up by the care team for signs of opioid misuse or opioid use disorder.
Co-prescribing naloxone (Narcan) to patients at risk of overdose.
Facilitating use of medication, such as buprenorphine, as indicated, for opioid use disorder, including obtaining training and authority for medication-assisted treatment.
Providing referrals for treatment assistance, as indicated, including follow-up with the referral team.
Engaging with the community to promote the availability of necessary substance use disorder treatment resources.
###

The National Academy of Medicine, established in 1970 as the Institute of Medicine, is an independent organization of eminent professionals from diverse fields including health and medicine; the natural, social, and behavioral sciences; and beyond.
It serves alongside the National Academy of Sciences and the National Academy of Engineering as an adviser to the nation and the international community.
Through its domestic and global initiatives, the NAM works to address critical issues in health, medicine, and related policy and inspire positive action across sectors.
The NAM collaborates closely with its peer academies and other divisions within the National Academies of Sciences, Engineering, and Medicine.
The views presented in this special publication - "First Do No Harm: Marshalling Clinician Leadership to Counter the Opioid Epidemic" - are those of the authors and do not represent formal consensus positions of the NAM; the National Academies of Sciences, Engineering, and Medicine; or the authors' organizations.
Social Media: @theNAMedicine

Resources: http://www.
edu/ FirstDoNoHarm

Contacts:

Jennifer Walsh

Director of Media Relations



Joshua Blatt

Media Relations Assistant



Office of News and Public Information

202-334-2138

news@nas.edu
WASHINGTON, DC and NEW YORK (Sept. 21, 2017) -- If Congress does not renew a critical fund for community health centers before September 30, these safety net providers could lose 70 percent of their federal grant funding by 2018.
As a result 9 million people could lose access to health care, according to a report produced by researchers at the Geiger Gibson/RCHN Community Health Foundation Research Collaborative at the George Washington University's Milken Institute School of Public Health (Milken Institute SPH).
The new report also predicts that cutting funds to community health centers would lead to site closures, a loss of 51,000 health care jobs and an economic downturn in communities located throughout the U.S.

"The patients served by the nation's federally supported community health centers are among the nation's neediest, and the Community Health Center Fund is intended to ensure that these centers have a reliable source of funding to reach these vulnerable populations and communities," said Sara Rosenbaum, one of the report's co-authors and the Harold and Jane Hirsh Professor of Health Law and Policy at Milken Institute SPH.
"Loss of this federal funding could cause 2,800 health center sites located in rural and urban communities alike to close their doors, leaving an estimated 9 million people, including children and the elderly, without the health care they need to stay healthy."
The centers supported by the Community Health Center Fund served nearly 26 million people at more than 10,400 sites in 2016.
The centers at greatest risk are the smallest centers, those located in rural areas and in states that did not opt to expand their Medicaid funding.
Like the Children's Health Insurance Program, also set to expire at the end of the government's fiscal year on September 30, the health center program enjoys broad bipartisan support.
Additional key findings from the new report include:

Between 2000 and 2016, the number of health centers grew by 87 percent.
The scope of services is also broad; in 2016, 87 percent of centers offered behavioral health care while 80 percent offered dental care.
If the Community Health Center Fund is not renewed, essential treatment to combat public health crises such as the opioid epidemic could be scaled back.
Over the past decade, staffing at community health centers grew by 113 percent, bringing jobs and economic development to medically underserved communities.
More than 207,500 full-time-equivalent staff are now employed at community health centers, a figure that could decline by 51,000 if the Community Health Center Fund is not renewed.
Without the Community Health Center Fund, revenue at the nation's community health centers would be reduced by 13 percent.
In states without Medicaid expansion, revenue would drop by 19 percent, community health centers in rural areas would see 17 percent less revenue, and revenue would decline by 27 percent in small health centers serving fewer than 5,000 people.
The report estimates that the national economic impact of losing the Community Health Center Fund translates to $7.5 billion in lost revenue nationwide.
"Without continued support, community health centers will not be able to meet the demand for primary care in underserved parts of the United States," said Feygele Jacobs, DrPH, President and CEO of the RCHN Community Health Foundation.
"Unless policymakers act now to extend the Community Health Center Fund, many Americans will be left without the high-quality services they need, and care that can prevent many expensive health conditions from developing in the first place."
###

The report, "What are the Possible Effects of Failing to Extend the Health Center Fund?"
can be accessed here.
The Geiger Gibson Program in Community Health Policy, established in 2003 and named after human rights and health center pioneers Drs.
H. Jack Geiger and Count Gibson, is part of the Milken Institute School of Public Health at The George Washington University.
The RCHN Community Health Foundation is the only foundation in the U.S. dedicated solely to community health centers.
The Foundation's gift to the Geiger Gibson program supports health center research and scholarship.
The Milken Institute School of Public Health at the George Washington University is the only school of public health in the nation's capital.
Quantum communication over long distances is integral to information security and has been demonstrated in free space and fibre with two-dimensional states, recently over distances exceeding 1200 km between satellites.
But using only two states reduces the information capacity of the photons, so the link is secure but slow.
To make it secure and fast requires a higher-dimensional alphabet, for example, using patterns of light, of which there are an infinite number.
One such pattern set is the orbital angular momentum (OAM) of light.
Increased bit rates can be achieved by using OAM as the carrier of information.
However, such photon states decay when transmitted over long distances, for example, due to mode coupling in fibre or turbulence in free space, thus requiring a way to amplify the signal.
Unfortunately such "amplification" is not allowed in the quantum world, but it is possible to create an analogy, called a quantum repeater, akin to optical fibre repeaters in classical optical networks.
An integral part of a quantum repeater is the ability to entangle two photons that have never interacted - a process referred to as "entanglement swapping".
This is accomplished by interfering two photons from independent entangled pairs, resulting in the remaining two photons becoming entangled.
This allows the establishment of entanglement between two distant points without requiring one photon to travel the entire distance, thus reducing the effects of decay and loss.
It also means that you don't have to have a line of sight between the two places.
An outcome of this is that the information of one photon can be transferred to the other, a process called teleportation.
Like in the science fiction series, Star Trek, where people are "beamed" from one place to another, information is "teleported" from one place to another.
If two photons are entangled and you change a value on one of them, then other one automatically changes too.
This happens even though the two photons are never connected and, in fact, are in two completely different places.
In this latest work, the team performed the first experimental demonstration of entanglement swapping and teleportation for orbital angular momentum (OAM) states of light.
They showed that quantum correlations could be established between previously independent photons, and that this could be used to send information across a virtual link.
Importantly, the scheme is scalable to higher dimensions, paving the way for long-distance quantum communication with high information capacity.
Background

Present communication systems are very fast, but not fundamentally secure.
To make them secure researchers use the laws of Nature for the encoding by exploiting the quirky properties of the quantum world.
One such property is entanglement.
When two particles are entangled they are connected in a spooky sense: a measurement on one immediately changes the state of the other no matter how far apart they are.
Entanglement is one of the core resources needed to realise a quantum network.
Yet a secure quantum communication link over long distance is very challenging: Quantum links using patterns of light languish at short distances precisely because there is no way to protect the link against noise without detecting the photons, yet once they are detected their usefulness is destroyed.
To overcome this one can have a repeating station at intermediate distances - this allows one to share information across a much longer distance without the need for the information to physically flow over that link.
The core ingredient is to get independent photons to become entangled.
While this has been demonstrated previously with two-dimensional states, in this work the team showed the first demonstration with OAM and in high-dimensional spaces.
###

Paper Abstract

High-bit rate long distance quantum communication is an mooted technology for future communication networks and relies on high-dimensional quantum entanglement as a core resource.
While it is known that spatial modes of light provide an avenue for high-dimensional entanglement, the ability to transport such quantum states robustly over long distances remains challenging.
To overcome this, entanglement swapping may be used to generate remote quantum correlations between particles that have not interacted, the core ingredient of a quantum repeater, akin to repeaters in optical fibre networks.
Here we demonstrate entanglement swapping of multiple orbital angular momentum states of light.
Our approach does not distinguish between different anti-symmetric states, and thus entanglement swapping occurs for several thousand pairs of spatial light modes simultaneously.
This work represents the first step towards a quantum network for high-dimensional entangled states and provides a test bed for fundamental tests of quantum science.
Even in our modern world full of highly technological machines and devices it is still impossible to predict when rockslides, such as the recent one in Graubnden, or earthquakes will occur and how exactly they evolve.
This is partly due to the fact that despite many years of research, scientists have only just begun to understand the behaviour of gravel and sand, particularly when mixed with water or gases.
A team of researchers led by Christoph Mller at the Department of Mechanical and Process engineering of the ETH Zurich and Klaas Prssmann at the Institute for Biomedical Engineering of the ETH and University of Zurich, together with colleagues at Osaka University in Japan, have now developed a new technique that could make it much easier to study such phenomena in the future.
Many natural phenomena and natural catastrophes could thus be better understood and predicted more easily.
Powders and grains in the chemical industry

Granular systems - a generic term for anything that resembles grains or powders - play a pivotal role not just in nature.
They are equally important in practical applications, such as the chemical industry, where three quarters of the raw materials are granular substances.
A frequent problem facing the chemical industry is that production flows may be interrupted, for instance, by unforeseen and poorly understood jamming or de-mixing of the granular materials used.
Even a small increase in the efficiency of the production processes through improved knowledge would allow one to save a lot of energy, explains Alexander Penn, a PhD student in the group of Mller and Prssmann.
However, when trying to understand what happens, for instance, when different particles are mixed together or made to interact with gases in so-called fluidized beds, one faces a serious problem: granular systems are opaque, which makes it very difficult to learn anything about the exact spatial distribution and motion of the particles.
Medical technology aids studies of granular systems

To overcome this obstacle, scientists have reintroduced a technology into physics research that, nowadays, is mainly used in medicine: magnetic resonance imaging (MRI), which is well-known for the narrow tube patients need to go into to be examined.
Magnetic resonance imaging uses radio waves and strong magnetic fields to first align the magnetic moments of certain atomic nuclei inside a tissue or material (these can be visualized as tiny compass needles).
Thereafter, the atomic nuclei lose their alignment, and in doing so, they themselves emit radio waves that can be measured.
Finally, the results of those measurements are used to create a three-dimensional image of the positions of the atomic nuclei in the material.
In their new experiments, recently published in the scientific journal Science Advances, the researchers at ETH added a number of radio antennas to a commercial MRI device and analysed the measurements using special software.
This allowed them to measure the internal dynamics of granular systems ten thousand times faster than had been possible before.
For that purpose, the scientists developed special particles consisting of an oil droplet covered in agar measuring one millimetre in diameter that produced a particularly large and sustained magnetic resonance signal.
They used them, amongst other things, to study what happens when a gas flows through granular systems.
The gas flow causes the granular medium, which is usually solid, to behave like a fluid.
In such fluidized granular systems gas bubbles can rise, split up or merge.
Until now, it was impossible to study such bubbles in real time.
The new measurement technique developed by the Zurich-based scientists allows one to take pictures of the inside of granular matter with a temporal resolution of less than a hundredth of a second.
Moreover, a clever analysis of the magnetic resonance signals makes it possible to measure the velocities of the individual particles and, thus, to obtain additional information about the dynamics of those complex systems.
Applications in carbon capture

There are numerous possible applications of the knowledge obtained using the new technique.
The researchers are planning, for instance, to carefully test existing theoretical models for granular systems and, where necessary, to improve them.
Among the models to be tested are the spontaneous de-mixing of granular mixtures of particles having different sizes, which can lead to problems in industrial applications, as well as the spontaneous jamming of flowing systems.
Bubble formation in granular systems exposed to gas flows, on the other hand, is important for procedures in which a gas is supposed to react as strongly as possible with catalyst particles.
Such procedures are used, for example, in carbon dioxide capture, which in the future might be used to counteract climate change.
A better understanding of the physical processes involved could lead to higher efficiency and considerable energy savings.
###

Reference

Penn A, Tsuji T, Brunner DO, Boyce CM, Pruessmann KP, Mller CR.
Real-time probing of granular dynamics with magnetic resonance.
3, e1701879 (2017).
DOI: 10.1126/sciadv.1701879
Wildlife rangers are on the front lines protecting our most iconic species -- tigers, elephants, gorillas and many others.
But their challenges involve more than confrontations with wild animals and poachers.
"Generally, rangers are highly undertrained, undersupported and not respected," said Barney Long, former director of species conservation for the World Wildlife Fund and now with Global Wildlife Conservation.
"We put people in charge of these valuable resources and yet we don't look after the people who are taking care of them."
What motivates a ranger to do a job with low pay, long absences from family and the risk of life-threatening attacks?
UCF researchers are working to answer this question in collaboration with the WWF, a leading international conservation organization headquartered in Washington.
The team's findings are published in Oryx: The International Journal of Conservation.
"This is a completely new area of investigation for the WWF and really a new topic within conservation sciences and policy," said Will Moreto, UCF assistant professor of criminal justice and the lead author of the new study with Long and others on rangers working in Asia.
"You need to understand the day-to-day realities of rangers if you want to develop a ranger force that is motivated and effective in conservation," he said.
Moreto established himself as a researcher with interests spanning crime and conservation as a doctoral student at Rutgers University.
His dissertation research focused on law enforcement rangers and poaching in Uganda.
Long learned of Moreto's work and contacted him about a new WWF project on rangers.
The organization was planning to survey rangers about their jobs, and Long invited Moreto to help develop the survey questions and examine the data.
From January to July 2015, data collectors trained by WWF employees and other partners met with hundreds of rangers in Asia to obtain their responses to 10 questions, most with subparts.
Some rangers submitted their responses by email and postal mail.
In all, the WWF obtained responses from 530 rangers working in 39 conservation areas in 11 Asian countries - Bangladesh, Bhutan, Burma, Cambodia, China, India, Indonesia, Laos, Nepal, Thailand and Viet Nam.
At UCF Moreto partnered with two criminal justice colleagues to analyze and interpret the data.
Associate professor Jactina Gau contributed expertise in statistical analysis and professor Eugene Paoline shared his insight on law enforcement culture.
The survey asked rangers to rank nine job aspects according to what most and least motivated them to continue working as rangers.
Moreto and his team tagged each aspect as being either intrinsically motivated (affected by internal influences) or extrinsically motivated (affected by external influences).
More than 47 percent of rangers selected "I have no other job option" as the aspect that most motivated them.
They ranked having good promotion prospects and liking the power and authority of the job as second and third, respectively.
All are extrinsically motivated aspects suggesting they are under the control of administrators of protected conservation areas, reported the authors.
More than 47 percent of rangers selected "I enjoy being close to nature" as the aspect that least motivated them and 43 percent selected "I enjoy being a ranger" as second.
Both aspects are considered intrinsically motivated.
The survey also asked rangers if they would want or not want their children to become rangers and why.
Rangers who were adequately equipped for the job were much more likely to want their children to become rangers, a finding that underscores the importance of work environment to rangers' job commitment.
The top reasons rangers did not want their children to become rangers were low salary and no reward for hard work.
"If you wouldn't recommend the job to your children, you probably wouldn't be motived to recruit others," Moreto said.
"You wouldn't be a good representative in general."
The WWF expanded its study to include rangers in Africa and Latin America, and Moreto and his team are examining this data as well.
They also are involved in a more in depth study of rangers that includes a 120-question survey.
The ultimate goal is to bring policy changes, said Rohit Singh, a WWF wildlife enforcement and capacity building specialist, president of the Ranger Federation of Asia, and coauthor of the study led by Moreto, in a WWF interview.
"National governments have to take the initiative.
We need to provide them with good, concrete, scientific data, and advocate for the policy changes that can improve ranger conditions," Singh said.
"The future of wildlife and forests depends on rangers."
PITTSBURGH, Sept. 21, 2017 - Expanding the high-dose influenza vaccine recommendation to include middle-aged adults with chronic health conditions may make economic sense and save lives, report scientists at the University of Pittsburgh School of Medicine.
The findings, published online and scheduled for a coming issue of Vaccine, call for clinical trials of the high-dose and new recombinant trivalent influenza vaccines in 50- to 64-year-old adults with chronic illnesses, such as heart or lung disease, diabetes or cancer, to determine if they do provide better protection than the currently recommended standard-dose quadrivalent vaccine.
"The growing proportion of middle-aged adults with chronic health conditions coupled with the modest effectiveness of the standard-dose influenza vaccine prompted us to explore whether existing vaccines already recommended for the elderly also could protect younger people," said lead author Jonathan Raviotta, M.P.H., C.P.H., senior research specialist with The Pittsburgh Vaccination Research Group (PittVax) in Pitt's School of Medicine.
"Sure enough, expanding the recommendation does seem like a good policy -- in silico.
Before making such a recommendation, real world clinical trials are needed."
The high-dose influenza vaccine is recommended for adults over age 65 because their immune response to the standard-dose vaccine diminishes with increasing age.
However, at almost double the price, it is more expensive than the standard-dose quadrivalent vaccine.
To test the value of conducting large clinical trials of the vaccine in 50- to 64-year-olds with chronic conditions, Raviotta and his colleagues used the Influenza Decision Analysis model, which was developed by PittVax, to explore the cost-effectiveness of alternate influenza vaccination scenarios.
Because the circulating influenza strains can shift from season to season, annual vaccine effectiveness can vary widely.
Also, the effectiveness of both the standard-dose and high-dose vaccines among middle-aged patients with different levels of chronic medical conditions is unknown.
Using the best available data, the PittVax team reported that the high-dose vaccine would need to provide at least 18 percent more protection than the standard-dose vaccine to justify the increased cost per dose.
Previous clinical trials found an additional 24 percent effectiveness of high-dose vaccine over the standard-dose vaccine in the elderly, but it is not clear how much more effective the high-dose vaccine would be in younger adults with high-risk medical conditions.
Likewise, a newer but even more expensive recombinant vaccine has shown an additional 41 percent protection among adults, suggesting that additional research of vaccine options for high-risk, middle-aged adults may be justified.
According to the U.S. Centers for Disease Control and Prevention, between 12,000 and 56,000 people die annually in the U.S. from the flu, and up to 35.6 million people are infected.
This adds up to an estimated $10.4 billion a year in direct medical expenses and an additional $16.3 billion in lost earnings annually.
"PittVax will continue to test new vaccination scenarios to help guide flu immunization recommendations," said senior author Richard K. Zimmerman, M.D., M.P.H., professor in Pitt School of Medicine's Department of Family Medicine and Pitt Graduate School of Public Health's Department of Behavioral and Community Health Sciences.
"These analyses are essential to choosing the best immunization policies that save lives from influenza, which kills thousands annually."
###

Additional authors on this study are Kenneth Smith, M.D., Mary Patricia Nowalk, Ph.D., R.D., Angela Wateska, M.P.H., all of Pitt; Jay DePasse, B.S., Shawn Brown, Ph.D., of the Pittsburgh Supercomputing Center at Carnegie Mellon University; and Eunha Shim, Ph.D., of Soongsil University in Seoul, Republic of Korea.
This project was funded by National Institute of General Medical Sciences grant R01GM111121.
About the University of Pittsburgh School of Medicine

As one of the nation's leading academic centers for biomedical research, the University of Pittsburgh School of Medicine integrates advanced technology with basic science across a broad range of disciplines in a continuous quest to harness the power of new knowledge and improve the human condition.
Driven mainly by the School of Medicine and its affiliates, Pitt has ranked among the top 10 recipients of funding from the National Institutes of Health since 1998.
In rankings recently released by the National Science Foundation, Pitt ranked fifth among all American universities in total federal science and engineering research and development support.
Likewise, the School of Medicine is equally committed to advancing the quality and strength of its medical and graduate education programs, for which it is recognized as an innovative leader, and to training highly skilled, compassionate clinicians and creative scientists well-equipped to engage in world-class research.
The School of Medicine is the academic partner of UPMC, which has collaborated with the University to raise the standard of medical excellence in Pittsburgh and to position health care as a driving force behind the region's economy.
For more information about the School of Medicine, see http://www.
medschool.
Checkpoint inhibitor-based immunotherapy has been shown to be very effective in recurrent and metastatic head and neck cancer but only in a minority of patients.
University of California San Diego School of Medicine researchers may have found a way to double down on immunotherapy's effectiveness.
In a paper published in the journal JCI Insights on September 21, researchers report that a combination of toll-like receptors (TLR) agonists -- specialized proteins that initiate immune response to foreign pathogens or, in this case, cancer cells -- and other immunotherapies injected directly into a tumor suppresses tumor growth throughout the whole body.
"The mechanism reverses the phenotype of a tumor by changing its inherit properties to make the tumor more immunogenic," said Ezra E.W.
Cohen, MD, professor of medicine at UC San Diego School of Medicine and associate director for translational science at UC San Diego Moores Cancer Center and senior author on the paper.
"In this study, the combination of immunotherapy drugs resulted in the complete elimination of cancer cells and even when re-challenged the tumors did not recur."
Macrophages are specialized immune cells that destroy targeted cells.
They are supposed to present antigens to the immune system to get it started, but in cancer they stop doing that so the immune system is unable to recognize the cancer.
The combination of drugs restored the ability of macrophages to initiate a tumor response and allow the immune system to eliminate the cancer.
To improve the efficiency of checkpoint inhibitor immunotherapy on human papillomavirus-negative and HPV-positive head and neck cancers, the team of researchers combined synthetic TLR7 and TLR9 that were developed by Dennis Carson, MD, Professor Emeritus at UC San Diego School of Medicine, with an inhibitor of the protein called programmed death-1 receptor (PD-1) which is responsible for turning off T cells.
TLR agonists cause an innate immune response -- that is, the rapid response to a foreign substance in the body.
This immediate protection comes at a cost since the nonspecific immune response may harm healthy cells if activation of the immune systems persists.
PD-1 inhibitors stimulate an adaptive response calling on B cells and T cells to respond to a specific target, but this process takes longer to go into effect.
In mouse models, the combined TLR agonists and PD-1 inhibitors injected directly into a tumor incited a tumor-specific response by T cells which prevented metastasis or the spread of the cancer.
When cancer had already spread, the TLR and anti-PD-1 combo eliminated the primary tumor as well as distant tumors.
The combination therapy was more effective than either agent alone.
The next step should be to study these drugs in a clinical setting for head and neck cancer using FDA-approved immunotherapy.
In addition, Cohen suggests studying these agents with other combinations such as chemotherapy and radiation therapy.
"As we make the tumor more immunogenic we should be making other therapies more effective and eliminate the cancer completely," said Cohen.
###

Co-authors include: Fumi Sato-Kaneko, Shiyin Yao, Alast Ahmadi, Shannon S. Zhang, Tadashi Hosoya, Megan M. Kaneda, Judith A. Varner, Minya Pu, Karen S. Messer, and Tomoko Hayashi, UC San Diego; Cristiana Guiducci, and Robert L. Coffman, Dynavax Technologies Corporation; Kazutaka Kitaura, Takaji Matsutani, and Ryuji Suzuki, Repertoire Genesis Inc.
Athens, Ga. - The key to a thriving business may be the educational level of non-executive employees, according to new University of Georgia research.
Specifically, highly educated employees provide higher quality financial data and are associated with improvements in key areas of business practice, such as mandatory disclosures and management forecasts.
"We find that when companies are located in a place where the workforce is highly educated, they produce better accounting information," said John Campbell, an associate professor of accounting in UGA's Terry College of Business and one of the study's authors.
"The employees don't have to be experts in accounting, but if they see something that doesn't look right, they're more likely to say something about it and tell their superiors about it."
Non-executive employees play a large role in generating and reviewing accounting reports, meaning that they could be best positioned to catch errors or fraud, Campbell said.
"After the scandals with Enron and WorldCom, a lot of people were wondering why nobody spotted the fraud," Campbell said.
"Auditors seem to catch fraud about 10 percent of the time, and regulators like the Securities and Exchange Commission catch fraud about 7 percent of time.
Internal employees, however, catch fraud about 17 percent of the time--as much as the auditors and regulators combined."
Superior internal accounting information improves a firm's external financial reporting in many ways, Campbell said.
"First, if a manager is trying to use internal accounting systems to predict the future, they do a better job when their workforce is more highly educated.
They're more accurate with their forecasts, they're less biased, and they're more precise," he said.
"Secondly, there are fewer errors in their SEC filings.
There's less manipulation in their accounting and fewer restatements, meaning they're less likely to have to go back and correct errors."
The study, published in the Journal of Accounting and Economics, also finds some evidence that when companies move their headquarters to a better-educated area, the quality of their disclosures improves, too.
"A lot of the most-educated areas we examined are college towns, which is not surprising.
But they don't make up a large percentage of where companies are actually headquartered.
The bigger things driving our results are the metropolitan areas that have better-educated people - Washington, D.C.; Silicon Valley; Boston; Raleigh-Durham, N.C.; Seattle; New York.
Companies in these areas produce better disclosures," Campbell said.
"Toward the bottom are the lesser-educated areas, like Las Vegas; El Paso, Texas; Los Angeles; Decatur, Alabama.
That's not to say that there aren't highly intelligent people there.
There are.
But the industry in those areas may not necessitate higher education, so the population as a whole has less schooling."
Campbell and his co-authors were inspired to look into the education levels of non-executive employees after reading about political corruption.
"There's a study in political science showing that states that have more educated voter bases have less corruption in their political systems, and we wanted to see if that analogy held in business," he said.
"One of the reasons for that might be whistleblowers.
In both instances, the better-educated the population is, the more likely there will be a whistleblower if something bad is going on."
Despite not reaping the benefits of a well-educated population, companies headquartered in other areas have a reason to be hopeful, Campbell said.
"Over time, in the big metropolitan areas, education levels are rising," he said.
"That seems to hold true no matter where they rank relative to each other."
###

The research and a full table of cities and their ranking based on average education levels is online at http://www.
sciencedirect.
com/ science/ article/ pii/ S0165410117300356 .
Contact: John Campbell, 706-542-3595, johnc@uga.edu
LAWRENCE -- The search for biology on neighbor planet Mars won't play out like a Hollywood movie starring little green men.
Rather, many scientists agree if there was life on the Red Planet, it probably will present itself as fossilized bacteria.
To find it, astrobiologists likely will need to decode the chemical analysis of rock samples performed by a rover (like the one NASA plans to send to Mars in 2020).
Only then might humankind know conclusively that life exists beyond Earth.
A new paper in the journal Astrobiology suggests NASA and others hunting for proof of Martian biology in the form of "microfossils" could use the element vanadium in combination with Raman spectroscopy on organic material as biosignatures to confirm traces of extraterrestrial life.
"You've got your work cut out if you're looking at ancient sedimentary rock for microfossils here on Earth -- and even more so on Mars," said Craig Marshall, the paper's lead author and an associate professor of geology at the University of Kansas.
"On Earth, the rocks have been here for 3.5 billion years, and tectonic collisions and realignments have put a lot of stress and pressure on rocks.
Also, these rocks can get buried, and temperature increases with depth."
Marshall likens a potential ancient Martian microorganism to a cut of steak from the supermarket in a pressure cooker.
"You can see a steak looks biological -- there's blood dripping from it," he said.
"Then, you put it in a pressure cooker for very long time, and you end up with charcoal.
It could be abiotic charcoal, or it could be made from heat and pressure on organic materials.
A lot of biological compounds get destroyed and ripped apart from heat and pressure, and you're left with carbon residue.
We can see this carbon with Raman spectroscopy."
Indeed, for some time paleontologists and astrobiologists hunting for bits of life on Mars have made use of Raman spectroscopy, a technique that can reveal the cellular composition of a sample.
"People say, 'If it looks like life and has a Raman signal of carbon, then we have life,'" Marshall said.
"But, of course, we know there can be carbonaceous materials made in other processes -- like in hydrothermal vents -- consistent with looking like microfossils that also have some carbon signal.
People also make wonderful carbon structures artificially that look like microfossils -- exactly the same.
So, we're at a juncture now where it's really hard to tell if there's life only based on morphology and Raman spectroscopy."
In the new paper, Marshall and his co-authors offer a path toward ironclad verification that microfossils once were alive.
According to the researchers, the proposed technique could be possible to perform with instrumentation already planned for the NASA 2020 rover mission to explore areas of Mars where the ancient environment could have fostered microbial life.
Researchers included Alison Olcott Marshall at KU, Jade Aitken and Peter Lay of the University of Sydney, Barry Lai of Argonne National Laboratory, Pierre Breuer of the Saudi Arabian Oil Co. and Philippe Steemans of the University de Liege.
"We applied a new technique called X-ray fluorescence microscopy -- it looks at elemental composition," said Marshall.
"Vanadium is an element in the periodic table, a transition metal.
It's been shown it can substitute into biological compounds.
If you can't unambiguously assign if something is biology or not with morphology and Raman spectroscopy in tandem -- maybe we could look for a known biological element, like vanadium.
Then, if the material that looked like a microfossil, and looked carbonaceous with Raman spectroscopy -- and had vanadium -- that's a new way forward for finding out if something really was biology."
According to the researchers, vanadium can be found in crude oil, asphalt and black shale, formed from acknowledged biological sources.
"Vanadium gets complexed in the chlorophyll molecule," Marshall said.
"Chlorophylls typically have magnesium at the center -- under burial, vanadium replaces the magnesium.
The chlorophyll molecule gets entangled within the carbonaceous material, thus preserving the vanadium.
It's like if you have a rope stored in your garage and before you put it away you wrap it so you can unravel it the next time you need it.
But over time on the garage floor it becomes tangled, things get caught in it.
Even when you shake that rope hard, things don't come out.
It's a tangled mess.
Similarly, if you look at carbonaceous material there's a tangled mess of sheets of carbon and you've got the vanadium mixed in."
Marshall and his colleagues proved the concept of testing for vanadium on known microfossils with acknowledged biological origins on Earth -- organic microfossils called acritarchs that might not be far from the kinds of traces of life possibly existing on the Red Planet.
"We tested acritarchs to do a proof-of-concept on a microfossil where there's no shadow of a doubt that we're looking at preserved ancient biology," Marshall said.
"The age of this microfossil we think is Devonian.
These guys are aquatic microorganisms -- they're thought to be microalgae, a eukaryotic cell, more advanced than bacterial.
We found the vanadium content you'd expect in cyanobacterial material."
The work was supported by an ARC International Research Grant (IREX) looking for biosignatures for extracellular life, the Australian Synchrotron, and the Department of Energy at the Advanced Photon Source, Argonne National Laboratory.
When Marshall was an ARC Fellow at the University of Sydney, prior to coming to KU, he worked with co-author Lay's group.
"We plan to undertake further Raman spectroscopic work on the carbonaceous materials using nanospectroscopic imaging," Lay said.
"This research is also of interest to researchers in the European space program on the Mars Explorer, since another investigator on the ARC grant, although not working on this aspect, was Howell Edwards, who was involved in instrumentation for the Mars Explorer."
Marshall said his research team's vanadium-based verification technique deserves attention from NASA scientists planning for the Mars 2020 mission.
Luckily, the KU researcher has good contacts at the space agency.
"Hopefully someone at NASA reads the paper," said Marshall.
"Interestingly enough, the scientist who is lead primary investigator for the X-ray spectrometer for the space probe, they call it the PIXL, was his first graduate student from Macquarie University, before his KU times.
I think I'll email her the paper and say, 'This might be of interest.'"
Tropical Storm Jose continued to spin south of Massachusetts when NASA's Aqua satellite flew overhead from space and captured an image of the large storm that hasn't moved much.
Because of Jose's close proximity to southern New England, the National Hurricane Center said that tropical storm conditions are occurring over portions of southeastern New England, today, Sept. 21.
Also, high surf and rip currents expected to continue on the east coast of the United States.
A Tropical Storm Warning is in effect from Woods Hole to Sagamore Beach, including Cape Cod, Massachusetts.
In addition to Block Island, Martha's Vineyard and Nantucket.
NASA's Aqua satellite flew over Tropical Storm Jose on Sept. 20 at 2 p.m. EDT (1800 UTC) when it was centered south of Cape Cod, Massachusetts.
The Moderate Resolution Imaging Spectroradiometer, known as MODIS captured a visible light picture of the large tropical storm.
The storm appeared to have a defined center of circulation.
Visible and microwave satellite data showed that the storm was still producing well-defined convective bands on the north side of the circulation.
Some of these outer bands were approaching the southern New England coastline.
On Sept. 21 at 3:30 a.m. EDT (0730 UTC) the Visible Infrared Imaging Radiometer Suite (VIIRS) instrument aboard NASA-NOAA's Suomi NPP satellite looked at Tropical Storm Jose in infrared light and found the coldest cloud tops and most powerful storms were located northwest of the center.
Cloud top temperatures were as cold as minus 50 degrees Fahrenheit or minus 45.5 degrees Celsius).
At 8 a.m. EDT/AST (1200 UTC), the center of Tropical Storm Jose was located near 39.6 degrees north latitude and 68.1 degrees west longitude.
That's about 150 miles southeast of Nantucket Island, Massachusetts.
Maximum sustained winds remain near 60 mph (95 kph) with higher gusts.
Gradual weakening is forecast during the next couple of days, and Jose is forecast to become post-tropical on Friday.
The minimum central pressure recently reported by an Air Force reconnaissance aircraft is 982 millibars.
Jose is a large system.
Tropical-storm-force winds extend outward up to 230 miles (370 km) from the center.
A gust to 48 mph (78 kph) was recently reported at the Nantucket Airport.
An unofficial observing site in Vineyard Haven on Martha's Vineyard recently reported a sustained wind of 39 mph (63 km/h) with a gust to 52 mph (83 kph).
The National Hurricane Center noted that "Jose is stationary, and the system is expected to continue to meander off the coast of southeast New England for the next several days."
Swells generated by Jose are affecting Bermuda and much of the U.S. east coast and will likely cause dangerous surf and rip current conditions during the next few days.
Researchers at the University of Bristol have been taking a close-up look at the biting mouthparts of the African tsetse fly as part of ongoing work on the animal diseases it carries.
Using the new high-powered scanning electron microscope in the University's Life Sciences Building, researchers from the Trypanosome Research Group were able to see the rows of sharp teeth and rasps that the fly uses to chew through the skin when it bites.
The teeth tear the delicate blood capillaries in the skin, so the fly can suck up the blood.
To stop the blood clotting, the fly squirts saliva containing anti-coagulant into the wound through a narrow tube inside the proboscis.
To their surprise, the researchers found that the tip of this tube is decorated with intricate finger-like structures with suckers.
Professor Wendy Gibson from the School of Biological Sciences, led the research which has been published this week in the journal Parasites & Vectors.
She said "This was an unexpected finding -- the textbooks just show a plain pointed end to the saliva tube.
"We've no idea yet what this ornate structure is for -- we haven't come across anything like it in other bloodsucking insects such as midges and mosquitoes."
The tsetse fly is a bloodsucking insect that carries human sleeping sickness and the animal disease, nagana.
The needle-like proboscis is armed with a formidable array of sharp teeth and rasps.
Professor Gibson added: "No wonder it hurts when one of these flies bites you."
###

This research was funded by the Biotechnology and Biological Sciences Research Council (BBSRC) and a South West Biosciences Doctoral Training Partnership postgraduate studentship.
Philadelphia, PA, Sept. 21, 2017 - Patients with major depressive disorder (MDD) have increased brain levels of a marker of microglial activation, a sign of inflammation, according to a new study in Biological Psychiatry by researchers at the University of Manchester, United Kingdom.
In the study, Dr. Peter Talbot and colleagues found that the increase in the inflammatory marker was present specifically in patients with MDD who were experiencing suicidal thoughts, pinning the role of inflammation to suicidality rather than a diagnosis of MDD itself.
"Our findings are the first results in living depressed patients to suggest that this microglial activation is most prominent in those with suicidal thinking," said Dr. Talbot.
Previous studies suggesting this link have relied on brain tissue collected from patients after death.
"This paper is an important addition to the view that inflammation is a feature of the neurobiology of a subgroup of depressed patients, in this case the group with suicidal ideation," said Dr. John Krystal, Editor of Biological Psychiatry.
"This observation is particularly important in light of recent evidence supporting a personalized medicine approach to depression, i.e., that anti-inflammatory drugs may have antidepressant effects that are limited to patients with demonstrable inflammation."
In the study, first author Dr. Sophie Holmes and colleagues assessed inflammation in 14 patients with moderate-to-severe depression who were not currently taking any antidepressant medications.
Immune cells called microglia activate as part of the body's inflammatory response, so the researchers used a brain imaging technique to measure a substance that increases in activated microglia.
The evidence for immune activation was most prominent in the anterior cingulate cortex, a brain region involved in mood regulation and implicated in the biological origin of depression, confirming the results of a previous study that first identified altered microglial activation in medication-free MDD patients.
Smaller increases were also found in the insula and prefrontal cortex.
"The field now has two independent reports -- our study and a 2015 report by Setiawan and colleagues in Toronto -- showing essentially the same thing: that there is evidence for inflammation, more specifically microglial activation, in the brains of living patients during a major depressive episode," said Dr. Talbot.
This link suggests that among depressed patients, neuroinflammation may be a factor contributing to the risk for suicidal thoughts or behavior.
According to Dr. Talbot, the findings "emphasise the importance of further research into the question of whether novel treatments that reduce microglial activation may be effective in major depression and suicidality."
###

Notes for editors

The article is "Elevated translocator protein in anterior cingulate in major depression and a role for inflammation in suicidal thinking: a PET study," by Sophie E. Holmes, Rainer Hinz, Silke Conen, Catherine J. Gregory, Julian C. Matthews, Jose M. Anton-Rodriguez, Alexander Gerhard, and Peter S. Talbot .
It appears in Biological Psychiatry, published by Elsevier.
Copies of this paper are available to credentialed journalists upon request; please contact Rhiannon Bugno at Biol.Psych@UTSouthwestern.edu or +1 214 648 0880.
Journalists wishing to interview the authors may contact Peter S. Talbot, MD, MRCPsych, at peter.talbot@manchester.ac.uk.
The authors' affiliations and disclosures of financial and conflicts of interests are available in the article.
John H. Krystal, M.D., is Chairman of the Department of Psychiatry at the Yale University School of Medicine, Chief of Psychiatry at Yale-New Haven Hospital, and a research psychiatrist at the VA Connecticut Healthcare System.
His disclosures of financial and conflicts of interests are available here.
About Biological Psychiatry

Biological Psychiatry is the official journal of the Society of Biological Psychiatry, whose purpose is to promote excellence in scientific research and education in fields that investigate the nature, causes, mechanisms and treatments of disorders of thought, emotion, or behavior.
In accord with this mission, this peer-reviewed, rapid-publication, international journal publishes both basic and clinical contributions from all disciplines and research areas relevant to the pathophysiology and treatment of major psychiatric disorders.
The journal publishes novel results of original research which represent an important new lead or significant impact on the field, particularly those addressing genetic and environmental risk factors, neural circuitry and neurochemistry, and important new therapeutic approaches.
Reviews and commentaries that focus on topics of current research and interest are also encouraged.
Biological Psychiatry is one of the most selective and highly cited journals in the field of psychiatric neuroscience.
It is ranked 6th out of 142 Psychiatry titles and 10th out of 258 Neurosciences titles in the Journal Citations Reports published by Thomson Reuters.
The 2016 Impact Factor score for Biological Psychiatry is 11.412.
About Elsevier

Elsevier is a global information analytics business that helps institutions and professionals progress science, advance healthcare and improve performance for the benefit of humanity.
Elsevier provides digital solutions and tools in the areas of strategic research management, R&D performance, clinical decision support, and professional education; including ScienceDirect, Scopus, SciVal, ClinicalKey and Sherpath.
Elsevier publishes over 2,500 digitized journals, including The Lancet and Cell, more than 35,000 e-book titles and many iconic reference works, including Gray's Anatomy.
Elsevier is part of RELX Group, a global provider of information and analytics for professionals and business customers across industries.
http://www.
elsevier.
com

Media contact

Rhiannon Bugno

Editorial Office, Biological Psychiatry

1-214-648-0880

Biol.Psych@UTSouthwestern.edu
In light of ongoing concerns by the media and the public surrounding the use of mesh in women with pelvic organ prolapse and urinary incontinence, the Pelvic Floor Society has issued a consensus statement addressing the use of mesh for the treatment of constipation and rectal prolapse (via a surgical procedure called ventral mesh rectopexy, or VMR).
The Statement is published in Colorectal Disease.
Mesh is a synthetic or biological material used to offer extra internal support.
In a small number of patients, such meshes may cause problems, but according to the Pelvic Floor Society, evidence suggests that mesh-related complications for VMR are far lower than those seen in transvaginal procedures.
The Society's statement addresses proper training and accreditation regarding VMR, as well as recommendations on tracking and recording complications and providing detailed consent forms and information booklets to patients.
"This important paper presents the evidence to support the use of Ventral Mesh Rectopexy in the treatment of constipation and rectal prolapse.
It should reassure the profession and public that we take potential mesh complications very seriously," said Andrew Williams, Chair of the Pelvic Floor Society.
"We are doing everything possible to improve education, provide detailed patient information, and record any complications to better understand the outcomes following this surgery."
New Rochelle, NY, September 21, 2017--Researchers in China who assessed self-monitoring of blood glucose (SMBG) behavior among nearly 19,000 patients with type 2 diabetes treated with oral medications reported very low SMBG rates both before and after the patients began treatment with basal insulin, although the data showed an increase in mean SMBG frequency after 6 months and the percentage of patients who never monitored their blood glucose decreased.
The study, which also confirmed that patients who performed SMBG more frequently tended to have lower HBA1c levels, is published in Diabetes Technology & Therapeutics (DTT), a peer-reviewed journal from Mary Ann Liebert, Inc., publishers.
The article is available free on the DTT website until October 21, 2017.
Yingying Luo, Yuqian Linong Ji, Peking University People's Hospital, Beijing; Yuqian Bao, Shanghai Jiao Tong University Affiliated Sixth People's Hospital, Shanghai; and Puhong Zhang, Dongshan Zhu, Xian Li, Jiachao, and Heng Zhang, Peking University Health Science Center, Beijing, representing the ORBIT Study Group, coauthored the article entitled "Self-Monitoring of Blood Glucose in Patients with Type 2 Diabetes Before and After Initiating Basal Insulin Treatment in China."
The researchers conducted a prospective analysis using ORBIT study data, comparing SMBG frequency, HbA1c control, and hypoglycemia rates among patients with HbA1c > 7% on oral diabetic agents at the initiation of the study.
They collected follow-up measurements at 3 months and 6 months after the patients began using basal insulin.
"Introduction of insulin is usually delayed in real-life in subjects with uncontrolled type 2 diabetes.
This study by Luo et al highlights the improvements achieved in glucose control by introduction of any basal insulin," says DTT Editor-in-Chief Satish Garg, MD, Professor of Medicine and Pediatrics at the University of Colorado Denver (Aurora).
###

About the Journal

Diabetes Technology & Therapeutics (DTT) is a monthly peer-reviewed journal that covers new technology and new products for the treatment, monitoring, diagnosis, and prevention of diabetes and its complications.
Led by Editor-in-Chief Satish Garg, MD, the Journal covers topics that include noninvasive glucose monitoring, implantable continuous glucose sensors, novel routes of insulin administration, genetic engineering, the artificial pancreas, measures of long-term control, computer applications for case management, telemedicine, the Internet, and new medications.
Tables of contents and a free sample issue may be viewed on the Diabetes Technology & Therapeutics (DTT) website.
DTT is the official journal of the International Conference on Advanced Technologies & Treatments for Diabetes (ATTD).
About ATTD

The International Conference on Advanced Technologies & Treatments for Diabetes (ATTD) presents top caliber scientific programs that have provided participants with cutting-edge research and analysis into the latest developments in diabetes-related technology.
A unique and innovative conference, ATTD brings the world's leading researchers and clinicians together for a lively exchange of ideas and information related to the technology, treatment, and prevention of diabetes and related illnesses.
About the Publisher

Mary Ann Liebert, Inc., publishers is a privately held, fully integrated media company known for establishing authoritative peer-reviewed journals in many promising areas of science and biomedical research, including Thyroid, Metabolic Syndrome and Related Disorders, Journal of Aerosol Medicine and Pulmonary Drug Delivery, Childhood Obesity, and Population Health Management.
Its biotechnology trade magazine, GEN (Genetic Engineering & Biotechnology News), was the first in its field and is today the industry's most widely read publication worldwide.
A complete list of the firm's 80 journals, books, and newsmagazines is available on the Mary Ann Liebert, Inc., publishers website.
An Australian researcher has come up with a unique way to manage predatory African lovegrass

A partnership between QUT, the NSW Government and farmers could lead to the eventual eradication of the highly invasive African lovegrass threatening pastures and native grasslands Australia-wide.
What they discovered is that local knowledge is the key to a successful management approach.
The results of a research project by Associate Professor Jennifer Firn from QUT's School of Earth, Environmental and Biological Sciences, Emma Ladouceur from Italy's University of Pavia and Dr Josh Dorrough from the NSW Office of Environment and Heritage, have been published in the esteemed international Journal of Applied Ecology.
"The impact of invasive non-native plant species like African lovegrass is increasing dramatically," said Professor Firn, who has previously tested control methods for the grass in southern Queensland.
"A native of southern Africa, it is very hardy and considered valuable for animal production and soil conservation but in Australia, where it is believed to have first arrived in the 1800s, it is considered by many Landholders to be a pest species because it is not selectively grazed by livestock and tends to dominate native pastures reducing biodiversity and essential ecosystem functions.
"Landholders are in a unique position to witness species turnover in grasslands as well as learn from their own successes and failures in trying to manage invasive grasses.
"For this study, we worked closely with 15 landholders in the Bega region of NSW to examine the changing ecological characteristics of grassy woodlands and the impact on them following the arrival of the non-native African Love Grass which has become an enormous problem for them.
"We then conducted a field study testing seven landholder-generated hypotheses at 57 sites on the 15 Landholders properties, which validated many of their management perceptions."
Professor Firn said seeds for African lovegrass can germinate even up to 17 years of age and are dispersed by grazing animals, slashing, vehicles, water, fodder and wind.
It thrives in drought conditions and paddocks with low ground cover are more susceptible to invasion.
"As well as overwhelming endangered native grasses, African lovegrass tussocks can grow so large they restrict the movements of livestock and become a hazard to famers trying to navigate their properties," she said.
"Our project has yielded some extremely helpful information and really highlighted the value of a team effort amongst scientists, governments, land care groups and farmers.
"One theory we tested was whether mechanically slashing African lovegrass and then putting a large number of cattle into the paddock was effective as some farmers think.
We found the opposite was true and it only made the lovegrass more abundant.
It was also an expensive exercise for farmers.
"Conversely, we discovered that an alternative control technique, "roller-wiping" or spot spraying with herbicide, was effective even with heavy infestations and cost efficient despite its poor reputation.
"Overall, we found local knowledge coupled with scientific methods can act in tandem as a smart approach to developing management solutions to African lovegrass, but this approach would likely be useful for understanding and managing other invasive plants and animals."
###

The full study - Integrating local knowledge and research to refine the management of an invasive non-native grass in critically endangered grassy woodlands - can be viewed on the website of the Journal of Applied Ecology.
Contact:

Amanda Weaver

07-3138-3151

amanda.weaver@qut.edu.au



After hours:

Rose Trapnell

0407-585-901

media@qut.edu.au
A research group consisting of scientists from Tomsk Polytechnic University, Germany and Venezuela proved vulnerability of a two-dimensional semiconductor gallium selenide in air.
This discovery will allow manufacturing superconducting nanoelectronics based on gallium selenide, which has never been previously achieved by any research team in the world.
The study was published in Semiconductor Science and Technology.
One of the promising areas of modern materials science is the study of two-dimensional (2D) materials, i.e.
thin films consisting of one or several atomic layers.
2D materials due to their electrical superconductivity and strength could be a basis for modern nanoelectronics.
Optic applications in nanoelectronics require advanced materials capable of 'generating' great electron fluxes upon light irradiation.
Gallium selenide (GaSe) is one of the 2D semiconductors that can cope with this problem most efficiently.
'Some research teams abroad tried to create electronic devices based on GaSe.
However, despite extensive theoretical studies of this material, which were published in major scientific journals, the stability of the material in real devices remained unclear,' says Prof. Raul Rodriguez, the Department of Lasers and Lighting Engineering.
The research team revealed the reasons behind this.
They studied GaSe by means of Raman spectroscopy and x-ray photoelectron spectroscopy that allowed proving the existence of chemical bonds between gallium and oxygen.
Photoluminescence in oxidized substance is absent that also proves the formation of oxides.
It means that the scientists revealed that GaSe oxidizes quickly in air and loses its electrical conductivity necessary for creating nanoeletronic devices.
'GaSe monolayers become oxidized almost immediately after being exposed to air.
Further research of GASe stability in air will allow making proposals how to protect it and maintain its optoelectronic properties,' emphasize the authors.
According to Prof. Rodriguez, for GaSe not to lose its unique properties it should be placed in a vacuum or inert environment.
For example, it can be applied in encapsulated devices that are vacuum-manufactured and then covered with a protective layer eliminating air penetration.
This method can be used to produce next generation optoelectronics, detectors, light sources and solar batteries.
Such devices of ultra-small sizes will have very high quantum efficiency, i.e.
they will be able to generate large electron fluxes under small external exposure.
Novel lithium electrodes coated with indium could be the basis for more powerful, longer-lasting, rechargeable batteries.
The coating hinders undesirable side-reactions between the electrode and electrolyte, provide a more uniform deposition of lithium when charging, and augments storage in the lithium anode via alloying reactions between lithium and indium, as reported by American scientists in the journal Angewandte Chemie.
Their success stems from the good diffusion of lithium ions along the interfacial layer.
Modern lithium ion batteries usually have graphite anodes that store lithium when the batteries are charged.
An interesting alternative is presented by batteries with metallic anodes, such as lithium metal, which promise significantly higher storage capacity.
However, a significant hurdle barring their successful implementation has been the uneven deposition of the metal during the charging process, which leads to formation of dendrites.
After longer uses of the battery, these dendrites can grow so extensive that they short-circuit the battery.
In addition, there are undesirable side-reactions between the reactive metal electrodes and the electrolyte, which significantly reduces the lifetime of the batteries.
The formation of a stable, passivating layer that prevents further contact would be an ideal solution; however, it isn't possible because of the constant expansion and contraction of the electrode upon charging and discharging.
This destroys the layer and exposes the metal to the electrolyte for more reactions.
Other approaches include artificial films or physical barriers.
Researchers working with Ravishankar Sundararaman at Rensselaer Polytechnic Institute (Troy, USA) and Lynden A. Archer at Cornell University (Ithaca, USA) have now introduced a novel alternative.
By using straightforward electroless ion-exchange chemistry, they produced indium coatings on lithium.
Simple immersion in a special indium salt solution is all it takes.
Some of the indium is deposited on the surface of the lithium electrode as metal and the lithium ion concentration in the electrolyte simultaneously increases.
The indium layer is uniform and self-healing when the electrode is in use, if small amounts of the indium salt are added to the electrolyte.
It remains intact during charge/discharge cycles, its chemical composition remains unchanged, and side-reactions are prevented.
Dendrites are also eliminated, leaving the surface smooth and compact.
By using computer modeling, the researchers were able to show why their method is so successful: lithium ions are very loosely bound to the indium coating.
They form an alloy with the indium, which allows them to move very rapidly over the surface before they cross it and are deposited on the underlying lithium electrode.
In complete cells with commercial cathodes, these new indium-lithium hybrid electrodes were stable over more than 250 cycles, retaining about 90 % of their capacity.
###

About the Author

Lynden Archer is the James A.
Friend Family Distinguished Professor of Chemical and Biomolecular Engineering at Cornell University.
His research focuses on transport properties of polymer/particle hybrids, and their applications for electrochemical energy storage.
He serves as the Co-Director for the Cornell Center for Nanomaterials Engineering & Technology and is a Fellow of the American Physical Society.
Marijuana is the most commonly abused drug in the world, and the advent of synthetic cannabinoids creates additional challenges to the society because of their higher potency and ability to escape drug detection screenings.
Scientists from Japanese sleep institute have a warning for the society about a danger coming from cannabinoid abuse.
Research led by Olga Malyshevskaya and Yoshihiro Urade of International Institute for Integrative Sleep Medicine (WPI-IIIS), University of Tsukuba, discovered that seizures, a life-threatening condition, can be induced by natural 9-tetrahydrocannabinol (9-THC, main constituent of marijuana) or the synthetic cannabinoid JWH-018 (main component of synthetic blend "Spice") in mice.
This was demonstrated by continuous recording of animals' electric brain activity (electroencephalogram, EEG), video and movement activity tracking.
Based on their data they propose potential treatment in case of cannabinoid overdose with the cannabinoid-1-receptor (CB1R) specific antagonist (AM-251), because in their study pretreatment prevented cannabinoid-induced seizures.
"Our study is quite important because unaware of the particularly severe effect by those cannabinoids, people see marijuana as a soft drug, without dangerous health effects," Malyshevskaya says.
Use of synthetic cannabinoids and the associated complications in humans are on the rise and spreading all-over the world.
People are synthesizing different variants of cannabinoids to evade regulatory agents, producing structures with minimal information on their pharmacology and potential harm.
Considering the recent irreversible spread of synthetic cannabinoids and their impact on human health, their data should serve as a public alert.
It is critically important for health-care professionals and policy makers to be aware of the serious adverse effects, as shown in this report.
Clinicians in the emergency departments should always suspect seizure activity in patients who have a history of cannabinoid intoxication.
The number of clinical cases involving marijuana intoxication has been steadily increasing due to increase in cannabis potency over the last two decades.
Reflecting the scientific debate on the action of cannabinoids, there are numerous disputes regarding the legal status of marijuana.
As several governments proceed with legalization for both medical and recreational use, there will always be public health concerns, as marijuana overdose often results in direct adverse reactions.
BOSTON-- Routine and rapid hepatitis C virus (HCV) testing among young adults who use injection drugs improves life expectancy and may provide a good use of limited resources, according to new research out of Boston Medical Center, in partnership with the Boston Public Health Commission.
The findings are published online ahead of print in the journal Clinical Infectious Diseases.
HCV is a viral infection that affects the liver.
An estimated 3.2 million people in the United States are infected with HCV, and most do not feel ill or know that they are infected, according to the Centers for Disease Control and Prevention (CDC).
Since 2010, acute cases of HCV have more than doubled, with new cases predominantly among young, white individuals with a history of injection drug use.
Currently, the CDC recommends doctors screen patients at high-risk for contracting HCV, which include but are not limited to people born between 1945 and 1965, those diagnosed with HIV, children born to HCV-positive women and individuals who engage in injection drug use, among other select populations at high risk.
This strategy is called "targeted" screening.
"Routine" screening, as defined in the study, tests all individuals in a community with a high prevalence of HCV.
There are two ways to perform these screenings.
Rapid testing is when results are given on the same day that the sample is drawn.
Standard testing requires patients to return for a second appointment to get the results.
Using simulation modeling, researchers evaluated the clinical benefits and cost-effectiveness of testing strategies among 15 to 30-year-olds at urban community health centers.
They found that routine, rapid testing was cost effective and increased the quality of life among this patient population.
Additionally, when dedicated counselors initiated the tests, they identified more cases of hepatitis C and reduced the proportion of deaths compared to targeted, standard testing by a physician.
"When standard testing was applied, patients were less likely to come back for that second appointment to get their results, which in turn meant more people weren't getting the treatment they so desperately needed," said Sabrina Assoumou, MD, MPH, infectious disease physician at Boston Medical Center and assistant professor of medicine at Boston University School of Medicine who led the study.
"Our results indicate that we must initiate rapid [testing] strategies so that more people will know their status and get treatment more quickly."
###

The study was supported by grants from the National Institute on Drug Abuse and the National Institute of Allergy and Infectious Diseases.
The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health.
Exceptionally preserved trilobite fossils from China, dating back to more than 500 million years ago, have revealed new insights into the extinct marine animal's digestive system.
Published today in the journal PLOS ONE, the new study shows that at least two trilobite species evolved a stomach structure 20 million years earlier than previously thought.
"Trilobites are one of the first types of animals to show up in large numbers in the fossil record," said lead author Melanie Hopkins, an assistant curator in the Division of Paleontology at the American Museum of Natural History.
"Their exoskeletons were heavy in minerals, and so they preserved really well.
But like all fossils, it's very rare to see the preservation of soft tissues like organs or appendages in trilobites, and because of this, our knowledge of the trilobite digestive system comes from a small number of specimens.
The new material in this study really expands our understanding."
Trilobites are a group of extinct marine arthropods--distantly related to the horseshoe crab--that lived for almost 300 million years.
They were extremely diverse, with about 20,000 species, and their fossil exoskeletons can be found all around the world.
Most of the 270 specimens analyzed in the new study were collected from a quarry in southern Kunming, China, during an excavation led by Hopkins' co-author, Zhifei Zhang, from Northwest University in Xi'an.
Previous research suggests that two body plans existed for trilobite digestive systems: a tube that runs down the length of the trilobite's body with lateral digestive glands that would have helped process the food; or an expanded stomach, called a "crop", leading into a simple tube with no lateral glands.
Until now, only the first type had been reported from the oldest trilobites.
Based on this, researchers had proposed that the evolution of the crop came later in trilobite evolutionary history and represented a distinct type of digestive system.
The Chinese trilobite fossils, about 20 percent of which have soft tissue preservation, are dated to the early Cambrian, about 514 million years ago.
Contradictory to the previously proposed body plans, the researchers identified crops in two different species within this material.
In addition, they found a single specimen that has both a crop and digestive glands--suggesting that the evolution of trilobite digestive systems is more complex than originally proposed.
The study backs up an earlier announcement made by a separate research team, which found evidence for the unusual crop and gland pairing in a single juvenile trilobite specimen from Sweden from the late Cambrian.
But the Chinese material presents the oldest example of this complex digestive system in a mature trilobite, wiping away doubts that the dual structures might just be part of the animal's early development.
"This is a very rigorous study based on multiple specimens, and it shows that we should start thinking about this aspect of trilobite biology and evolution in a different way," Hopkins said.
###

Other authors of the study include Feiyang Chen, from Northwest University in Xi'an, and Shixue Hu, from the Chengdu Institute of Geology and Mineral Resources.
This study was financially supported by the National Natural Science Foundation of China.
Fossil collection was partly financed by the National 973 Program and 111 Project of China.
PLOS ONE paper: http://journals.
org/ plosone/ article?id= 10.
1371/ journal.
0184982

American Museum of Natural History (amnh.org)

The American Museum of Natural History, founded in 1869, is one of the world's preeminent scientific, educational, and cultural institutions.
The Museum encompasses 45 permanent exhibition halls, including the Rose Center for Earth and Space and the Hayden Planetarium, as well as galleries for temporary exhibitions.
It is home to the Theodore Roosevelt Memorial, New York State's official memorial to its 33rd governor and the nation's 26th president, and a tribute to Roosevelt's enduring legacy of conservation.
The Museum's five active research divisions and three cross-disciplinary centers support approximately 200 scientists, whose work draws on a world-class permanent collection of more than 34 million specimens and artifacts, as well as specialized collections for frozen tissue and genomic and astrophysical data, and one of the largest natural history libraries in the world.
Through its Richard Gilder Graduate School, it is the only American museum authorized to grant the Ph.D. degree and the Master of Arts in Teaching degree.
Annual attendance has grown to approximately 5 million, and the Museum's exhibitions and Space Shows can be seen in venues on five continents.
The Museum's website and collection of apps for mobile devices extend its collections, exhibitions, and educational programs to millions more beyond its walls.
Visit amnh.org for more information.
Follow

Become a fan of the Museum on Facebook at facebook.com/naturalhistory, and follow us on Instagram at @AMNH, Tumblr at amnhnyc, or Twitter at twitter.com/AMNH.
Mr. Vaughans sentiment is echoed by a cadre of researchers who place mantises in a class of their own among the swarming Class Insecta, and who are discovering a range of skills and predilections that make mantises act like aspiring vertebrates.
Praying mantises are the only insects able to swivel their heads and stare at you.
Those piercing eyes are much like yours, equipped with 3-D vision and a fovea  a centralized concentration of light receptors  the better to focus and track.
A mantis can jump as unerringly as a cat, controlling its trajectory through an intricate series of twists and turns distributed across its legs and body, all to ensure a flawless landing on a ridiculously iffy target nearly every time.
Advertisement Continue reading the main story

The mantis appetite likewise turns out to leap and bound, and with scant regard for food-chain decorum.
By the standard alimentary sequence, insects feed on plants or one another, and then birds hunt down insects.
But just as there are carnivorous plants like the Venus flytrap, mantises prey on hummingbirds and other small-to-middling birds more often than most people realize.
James V. Remsen of the Museum of Natural Science at Louisiana State University and his colleagues documented 147 cases of mantis-on-bird predation in 13 countries representing all continents but Antarctica  not surprising, Dr. Remsen said in an interview, since there are no mantises on Antarctica.
Hummingbirds were the most common target, but mantises also went after warblers, sunbirds, honeyeaters, flycatchers, vireos and European robins.
Large species like the Chinese mantis, which grows to four inches in length, were the most avid avivores, and females were responsible for virtually all the bird-killing observed worldwide.
In two reported cases, females feasted on birds while copulating with males.
Sometimes the mantises would tuck in through the birds breastbone, but more often they went for the head, Dr. Remsen said.
They bite in and eat the brains, he said, which might imply this is something theyre professionals at.
Some mantises in North America now seem to view hummingbird feeders as happy hunting grounds.
Kris Okamoto, a retired nurse in San Juan Capistrano, Calif., recently came running when the young son of her house painter cried out that a praying mantis had snatched a hummingbird from her feeder.
Seeing that the bird was already dead, its skull pierced, Ms. Okamoto and the boy settled down and watched the mantis eat its fill of bird brain.
When the postprandial mantis crept back up the feeder, Ms. Okamoto gently pushed it off with a stick.
Not good enough.
Advertisement Continue reading the main story

It started crawling back toward the feeder, she said.
So we took it away completely and put it over the fence.
Researchers emphasize that bird predation by mantises remains rare and is insignificant compared to the carnage linked to, say, free-roaming cats.
Nevertheless, that the insects have learned to seek out bird feeders for a meal signifies another step in cognition, Dr. Remsen said.
Were lucky praying mantises arent our size.
A Certain Personality

Hunting is a professional trademark of the mantid order: the 2,500 known species are all predators, usually of insects and other small invertebrates.
Some mantises chase down their prey, but many are consummate ambush artists, waiting with Zen stillness in the grass or among flowers for the right moment to strike.
Their closest relatives are the cockroaches, from which they diverged about 250 million years ago, said Gavin J. Svenson, curator of invertebrate zoology at the Cleveland Museum of Natural History and a leading authority on praying mantises.
The family resemblance can still be seen in the long, slender antennae and the triangular, movie-alien shape of the head, among other features.
But praying mantises rise above the flattened scuttling posture that makes cockroaches look soverminy.
Praying mantises are unusually charismatic, said William D. Brown, who studies them at the State University of New York at Fredonia.
Those large eyes, the way they turn to look at you, gives them a certain personality that most insects lack, he added.
Newsletter Sign Up Continue reading the main story Please verify you're not a robot by clicking the box.
Invalid email address.
Please re-enter.
You must select a newsletter to subscribe to.
Sign Up You agree to receive occasional updates and special offers for The New York Times's products and services.
Thank you for subscribing.
An error has occurred.
Please try again later.
View all New York Times newsletters.
Molecular and evolutionary studies suggest that mantises diversified in parallel with angiosperms  not because they had anything to do with flowering plants directly, but in part to more effectively prey on the insects that ate or pollinated the plants.
Some mantises evolved to look like showy blossoms, a cancan of deadly come-ons.
Those show-offs dont like playing wallflower.
The orchid mantises of Asia, for example, generally avoid lingering around the flowers they imitate, and instead seek out patches of green vegetation.
They themselves become the flower, Dr. Svenson said.
Theyre a conspicuous beacon for pollinating insects.
The bigger the floral pollinators, the bulkier grew their predatory mantises, the better to catch, control and consume even well-armed bumblebees and wasps.
Other mantises resemble gnarled twigs, scraps of tree bark or decomposing leaves, blending in beautifully with forest underbrush, tree trunk or canopy, a cryptic approach to fool would-be prey and their own predators alike.
The smallest mantises flit around in the leaf litter of Australia and are no bigger than your pinkie nail, Dr. Svenson said.
Yet the stick-mimicking mantises of Africa can be nearly as long as your forearm.
Alexandra Horowitz, a psychologist at Barnard College who studies the behavior of dogs and has written several books about them, decided to give dogs a chance at showing self-recognition on their own, smelly terms.
In a recent study, she concludes that they do recognize the smell of their own urine.
While some researchers find the study intriguing, the scientist who first developed that mirror mark test doesnt think the evidence supports her conclusion.
Still, even the idea of a smell mirror is mind (nose?)
boggling.
I had always flirted with the idea in my head that there should be an olfactory mirror, Dr. Horowitz said, acknowledging that it could be horrifying for humans.
Marc Bekoff, a biologist and animal behavior specialist at the University of Colorado, Boulder, broke the ice, or actually the snow, in this kind of research around 20 years ago with what has become know as the yellow snow study.
He found that his dog, Jethro, recognized his own scent.
The evidence was that Jethro was more interested in snow marked by another dogs urine than in snow marked by his own, even if it had been surreptitiously moved  by Dr. Bekoff.
The research had its down side.
People who saw me move the pee around thought I was weird, and someone wrote a letter to the editor of the local paper that questioned what he was doing, he said in an email.
Dr. Horowitz took the testing a bit further, adding something like the mark on a chimps face: she set up dishes with different smells.
More Reporting on Dogs

A dogs own urine.
An unfamiliar dogs urine.
A dogs own urine along with another scent.
And, in some control tests, no urine and just the unfamiliar added scent.
Advertisement Continue reading the main story

She tested 36 pet dogs to see how long they spent with the different scents.
In many behavior tests, the time spent on a scent or a sight is taken as evidence of interest.
As she reported in Behavioral Processes, the dogs were least interested in their own urine, somewhat interested in another dogs urine, and most interested in their own altered urine.
Newsletter Sign Up Continue reading the main story Please verify you're not a robot by clicking the box.
Invalid email address.
Please re-enter.
You must select a newsletter to subscribe to.
Sign Up You agree to receive occasional updates and special offers for The New York Times's products and services.
Thank you for subscribing.
An error has occurred.
Please try again later.
View all New York Times newsletters.
What that means, of course, is a matter for discussion.
She says it shows that the dogs recognize their own scent, finding it less interesting unless it has been messed with.
I dont think its precisely parallel to the mirror mark test, Dr. Horowitz said.
In an odor test, you cant use the mirror to restore what you think you should look like.
But, she said, her test and the mirror tests all show that theres this selective sensory investigation of something that comes from yourself, but is changed.
The scientist who developed the mirror mark test, Gordon Gallup, disagrees.
I dont think the results support the conclusions, he said.
He defines the self-awareness assessed in the mirror mark test as the ability to become the object of your own attention.
If you present a familiar odor and a modified version of that familiar odor, he said, that will increase a dogs attention.
The same would happen when a dog is presented with the odor of the owner who lives in the same house.
A definitive test would need to have a component in which the animal identifies the source and refers to it, the way chimpanzees point to the mark on their own faces.
Advertisement Continue reading the main story

Dr. Gallup also questions the tests of dolphins.
They twist their body around to look at a mark, but cant point to it as chimpanzees and other apes and human children do.
Laurie Santos, director of the Canine Cognition Center at Yale, said the study was a really important innovation.
She said that by using a mirror test based on smell, Dr. Horowitz was able to observe cognitive capacities that we didnt realize dogs had.
Because the mirror mark test depends on visual ability, many researchers, including Dr. Gallup, have been interested in extending testing to other senses.
Frans de Waal, a primatologist at Emory University, said by email, We need to move away from the mark test as sole source of information.
My view is that all animals have some level of self-awareness, they need to, and that the mirror mark test taps into a special kind, perhaps a rare kind, but we need more ways of testing.
Dr. Horowitz plans further tests, including using the scent of familiar dogs and modifications to that scent.
The testing methods may vary, but one thing is likely: There will be urine.
This could be your chance to make Sputnik beep again.
It was on Oct. 4, 1957, just 60 years ago, that the Soviet Union launched the first Earth satellite, Sputnik.
It was little more than an aluminum beach ball with a radio transmitter that sent out a regular series of radio beeps, but it expanded the Cold War to outer space, shook up American technological smugness and probably helped John Kennedy get elected president in 1960.
On Wednesday, just ahead of the 60th anniversary of its launch, a replica of the famous satellite is going on sale at Bonhams in New York City as part of their Air and Space Sale.
Another item on the block is the harness, complete with camera, and an oxygen tank for the rhesus monkeys that preceded Americas Mercury astronauts into space.
The original Sputnik fell out of orbit and burned up three months after its launch.
But test models and engineering replicas, allegedly from the laboratory where the legendary Sergei Korolev built them, have surfaced in museums and collections in recent years  some more authentic than others, said Robert Pearlman, a journalist and space historian who runs the website Collectspace.
Africa proved a bigger challenge.
There were fewer skeletons in museums, and most searches for genetic material failed.
The environment was partly to blame: DNA is more likely to survive in colder places.
Its been mad, watching all the advances in what we understand about European prehistory, said Jessica C. Thompson, an archaeologist at Emory University who does field work in Malawi.
Dr. Thompson was heartened by the discovery of ancient DNA in Ethiopia in 2015.
Those scientists succeeded for two reasons: The skeleton they discovered had been lying for thousands of years in a cool cave in the Ethiopian highlands, and the researchers developed new technological methods increasing the odds of finding even tiny bits of DNA.
More recently, Dr. Thompson teamed up with experts in ancient DNA and began searching for skeletons in Malawi.
Much of the country comprises tropical lowlands, but it also includes high-elevation plateaus where nighttime temperatures can plunge below freezing.
Eventually she and her colleagues discovered DNA-bearing skeletons as old as 6,000 years in caves in the highlands.
Other bones were discovered by archaeologists working in African countries, as well as in museum collections.
David Reich, a geneticist at Harvard Medical School and a co-author of the new study, and his colleagues analyzed DNA from 16 of these fossils, along with the one previously found in Ethiopia, comparing the genetic material to that of living people throughout Africa as well as on other continents.
This analysis allowed them to determine how living Africans descended from ancient populations, which are older in Africa than anywhere else on Earth.
Advertisement Continue reading the main story

Africa is now going to be fully included in the ancient genomics revolution, Dr. Reich said.
Were going to be able to do a lot of things in Africa that weve been able to do in Europe and elsewhere.
Africa is where our species evolved at least 300,000 years ago.
Previous genetic analysis of living Africans had suggested that their ancestors began splitting into distinct groups over 200,000 years ago.
Roughly 70,000 years ago some Africans moved out of Africa, becoming the ancestors of non-Africans.
In earlier studies, researchers had concluded that the hunter-gatherers who live today in the Kalahari Desert and other parts of southern Africa descend from the branch believed to be the first to have divided from other Africans.
But the new study suggests that there may be even older branches in the tree.
Something more complicated is going on, Dr. Reich said.
Dr. Reich and his colleagues found that some people in West Africa share a unique collection of genetic variants that suggest an even deeper ancestry, raising the possibility that an earlier population of humans in West Africa diverged from rest.
Thats quite a big new idea, Dr. Busby said.
The new study also sheds light on exactly which Africans spread to other continents.
The 4,500-year-old Ethiopian man discovered in 2015 had DNA linking him to non-Africans.
Today, only a single, small population of living Africans shares the same genetic link: Tanzanian hunter-gatherers called the Hadza.
Newsletter Sign Up Continue reading the main story Please verify you're not a robot by clicking the box.
Invalid email address.
Please re-enter.
You must select a newsletter to subscribe to.
Sign Up You agree to receive occasional updates and special offers for The New York Times's products and services.
Thank you for subscribing.
An error has occurred.
Please try again later.
View all New York Times newsletters.
Theyre the group of living Africans most closely related to non-Africans, Dr. Reich said.
Once humans expanded out of Africa, there was little or no flow of genes between Africans and non-Africans for tens of thousands of years, the new study indicates.
But Dr. Reich and his colleagues discovered that a 3,100-year-old girl in Tanzania was profoundly different from the older East Africans.
A third of her ancestry could be traced to early farmers in the Near East.
Advertisement Continue reading the main story

Previous studies of living East Africans had hinted at some Near Eastern ancestry.
But the new analysis shows that people from the Near East spread into East Africa at least 3,100 years ago.
This puts a time stamp on this connection, said Pontus Skoglund, a postdoctoral researcher in Dr. Reichs lab and co-author of the new study.
Near Eastern genes were also found in a skeleton from South Africa about 1,200 years old; according to the researchers, some living South Africans carry this DNA today.
In all, these genetic patterns suggest that early farmers or herders from the Near East swept down through Egypt into East Africa several thousand years ago.
They then kept expanding over the centuries until their descendants reached the southern edge of the continent.
Around the same time, another expansion driven by agriculture was taking place in West Africa.
A people known as the Bantu spread from the region around present-day Cameroon and Nigeria.
They left a trail of distinctive iron tools that archaeologists have used to trace their migration into southern and eastern Africa about 2,000 years ago.
Archaeologists have studied this expansion for decades to learn what happened as the Bantu arrived in other parts of the continent.
The new genetic findings suggest that in some places, they may have pushed out the hunter-gatherers.
Up until 2,000 years ago, Dr. Thompson and her colleagues found, people in Malawi belonged to the same ancestral group as hunter-gatherers in southern Africa.
This was a hugely widespread population, she said.
But something happened: Living Malawians have no genetic connection to those who lived there before.
These ancient people must have disappeared virtually without descendants in Malawi.
Advertisement Continue reading the main story

Its possible, Dr. Thompson said, that Bantu farmers drove hunter-gatherers out of places like Malawi.
The surviving hunter-gatherers ended up in deserts and other places that werent good for crops and livestock.
In East Africa, the transition may not have been so stark.
There, modern people can trace much of their ancestry to the Bantu, suggesting a blending of populations.
But some people also inherited a mix of other ancestries, including genes from the Near East and some from the ancient East African hunter-gatherers.
Dr. Thompson is now digging into archaeological sites for evidence of the Bantu arrival in Malawi, looking for tools, bones and perhaps even more DNA.
We want to see if we can catch the timing of that transition and see if there was trade between the groups, or if the whole area was taken over, she said.
Ancient DNA in skeletons from western Africa would be just as valuable; it may hold profound secrets about the early history of our species.
But it wont be easy to find: The early archaeological record there is sparse, and there are few cold caves to search.
It is the major gap in our ancient DNA coverage, Dr. Skoglund said.
On their way over, they ran into Ms. Bedbrook and excitedly relayed their plan.
Theres no way these jellyfish sleep, she said, before joining them.
Photo

In the darkened lab, they observed a tankful of jellyfish pulsing infrequently and staying still for long periods of time  jellyfish that looked, in other words, like they were sleeping.
Ms. Bedbrook started to believe they were onto something.
To prove that jellyfish sleep, the students had to demonstrate that they fulfill three behavioral criteria.
First, the animals must undergo a period of diminished activity, but they must also be able to be aroused from this state, to distinguish sleep from other states, like comas.
Over six days and nights, the researchers monitored 23 jellyfish, which pulsed about 30 percent less at night than during the day.
If fed or poked in the middle of the night, the jellyfish would temporarily stir.
Next, the animals must exhibit decreased responsiveness to stimuli while sleeping.
Upside-down jellyfish get their name from the fact that they sit upside-down on the seafloor  they dont like to be suspended in water.
To test their responsiveness, the scientists placed the jellyfish in little cubbies with removable bottoms that were elevated within the tank.
When the researchers pulled the cubby bottoms out during the day, the creatures would immediately swim to the bottom of the tank.
At night, however, they would sluggishly float around at first.
Newsletter Sign Up Continue reading the main story Please verify you're not a robot by clicking the box.
Invalid email address.
Please re-enter.
You must select a newsletter to subscribe to.
Sign Up You agree to receive occasional updates and special offers for The New York Times's products and services.
Thank you for subscribing.
An error has occurred.
Please try again later.
View all New York Times newsletters.
Last, the animals must show an increased need for sleep if they are kept from it, so the biologists pulsed water through the jellyfishs tank every 20 minutes at night to prevent the creatures from sleeping continuously.
The following day and night, the jellyfish exhibited much lower levels of activity than normal, suggesting sleep deprivation.
As a bonus, the researchers also showed that jellyfish get sleepy when exposed to melatonin, just as humans do  a hint that their underlying sleep mechanism may be similar to ours.
Together, these experiments do a good job of demonstrating that jellyfish fulfill the most fundamental criteria for sleep, William Joiner, a sleep researcher at the University of California, San Diego, said in an email.
The study also provides new fodder for thinking about the origins and functions of sleep, both of which are still unknown, said Dr. Joiner, who was not involved in the study.
Sleep is often associated with having a brain because the behavior seems to be required for memory and learning, and because shared genes and mechanisms for sleep have been identified in all sorts of animals with brains, from worms and flies to mice and humans.
But what weve found, at least in this jellyfish, is you dont need a brain to sleep, Mr. Abrams said.
Dr. Rosas and his team studied ancient Neanderthal remains recovered from a cave system in Spain known as El Sidrn, where archaeologists have found the remains of more than a dozen individuals, including the childs mother and younger brother.
The first thing the researchers needed to do with their child specimen was determine how old he was.
So they peeked inside his mouth, which had a mix of 30 baby and adult teeth.
By cutting into his teeth they were able to use a microscope to count bands in the enamel, which grow similarly to tree rings.
From their investigation they determined the child was just under eight years old when he died.
They did not find any signs on his bones that would have clued them into the cause of his death.
By investigating the boys cranium, the researchers found that it was only 87.5 percent the size of a full grown Neanderthals cranium.
That differs from anatomically modern human children, who at age seven have craniums that are about 95 percent the size of an adults.
Photo

Because cranium size is a good indicator of brain size, the findings suggest that Neanderthals large brains took longer to grow to adult size than our brains do.
Though the team did not have the childs complete skull, they were able to compare the available fragments with a skull from a different Neanderthal and reconstruct the missing parts.
Advertisement Continue reading the main story

The team also found the Neanderthal child still had several unfused vertebrae.
In modern human children, those vertebrae are fused around the ages of four to six.
Despite the differences in brain and spine development, the team found that in many ways the Neanderthal child was no different from a modern human child, especially in the elbows, wrists, hands and knees.
Both seem to have experienced similar growth patterns, like having arms and legs that grew slowly between infancy and puberty, according to Dr. Rosas.
Photo

As he went through the whole skeleton, comparing it to skeletons of Homo sapiens, these particular differences stood out, contributing to the mystery of what accounts for the early differences between the two species.
We were surprised because we were expecting some differences, said Dr. Rosas.
But it was, Similar, similar, similar  oh, different  similar, similar  oh, different.
Luis Ros, a paleoanthropologist also at The National Museum of Natural Sciences in Madrid and co-author on the paper, said at a news conference that the new finding about growth rates fits with the generally held idea that Neanderthal brains were bigger.
But to confirm that hypothesis, they will need to further investigate the craniums in the cave, looking for remains between childhood and adulthood, to complete their life cycle of Neanderthals.
Dr. Delmer pioneered research on how cotton synthesizes cellulose, the primary compound in its fibers.
She wanted to see evidence that the researchers novel molecules formed stable chemical bonds with cellulose.
If they didnt, she said, then the prospects that they can survive harsh treatments when incorporated into fabrics would seem less certain.
Photo

Filipe Natalio, lead author of the study and a scientist at the Weizmann Institute of Science in Israel, said his team had similar concerns.
He and his colleagues used chemical and physical analytical techniques to show that the cellulose in the fibers had undergone changes.
But thats not the same as showing that the new molecules were chemically woven, via enzymatic reactions, into strands of cellulose, Dr. Delmer said.
Instead, Dr. Natalios team could just be picking up signatures of their molecules hanging out in the cells, but not forming long-term linkages.
Dr. Natalio responded that English is not his native language, and to him, words like incorporated or integrated covered the possibility that the molecules got into the cotton fibers without binding to its components.
We didnt claim also that there were linkages, he said.
Given limited room to explain every last detail in the paper, he continued, we had to make a lot of sentences that were very vague and encapsulate information without proving it, which is awkward.
Beyond being unconvinced of the papers central claim, cotton researchers were skeptical about whether Dr. Natalios system would ever evolve past proof of concept.
He spoke in an interview about a not-so-distant future with cotton and other plants growing in hydroponic greenhouses, bathed in fluids with all sorts of customized molecules.
But Dr. Natalio and his colleagues were experimenting with small amounts of cotton embryos in the lab, not whole plants.
Dr. Natalio acknowledged that for the technology to work with actual plants, he would have to synthesize whole new sugars, one of the most delicate chemistries you can do.
Moreover, Dr. Natalios group found that the modified fibers they produced were actually weaker than raw cotton fibers.
Thats a big no-no in the cotton industry, since it wreaks havoc in yarn production and goes against the durability consumers want from cotton, said Don Jones, a director of agricultural research for Cotton Incorporated, a trade organization based in North Carolina.
Advertisement Continue reading the main story

Cotton experts also noted that the authors cultured their cotton for an unusually short amount of time, many experiments presented in the paper had no information on replication and there were statistics missing in places one might expect to find them.
Mislabeled chemicals in two supplemental figures led Science to publish its editorial expression of concern.
Several experts wondered if the people involved in the peer review of the study were materials scientists, chemists or physicists, not biologists.
When asked what fields the editors and reviewers for this study belonged to, the journal said in an email that Science papers are assigned to a staff editor who identifies the types of expertise needed to evaluate all aspects of the manuscript under consideration, but offered no specifics.
Two of the three biologists who are experts in cotton only agreed to speak on the condition of not being named, out of concern that publicly raising questions about other scientists work could boomerang on their careers.
One of them spotted the misnamed chemicals and contacted Science, leading to the journals expression of concern about the paper.
Newsletter Sign Up Continue reading the main story Please verify you're not a robot by clicking the box.
Invalid email address.
Please re-enter.
You must select a newsletter to subscribe to.
Sign Up You agree to receive occasional updates and special offers for The New York Times's products and services.
Thank you for subscribing.
An error has occurred.
Please try again later.
View all New York Times newsletters.
Ivan Oransky, co-founder of Retraction Watch, a site that reports on problems with scientific research, said the researchers concerns were understandable, but in the long term its bad for science if researchers are not willing to have public, respectful debates.
He added that there are ways to make the peer review process more transparent, like having journals publish reviewers reports and editorial decisions along with articles.
Dr. Natalio said his team is preparing a list of corrections to be attached to the article.
He added that they have preliminary data that suggests the stable chemical linkages that Dr. Delmer had wanted to see.
But he refrained from putting that data in this paper because it was incomplete and he believed it would prolong the review process.
One of the rules of publication?
Dont claim what you cant prove, he said.
But they also learned that some sea turtles are still declining  like leatherbacks in the Eastern and Western Pacific.
Their findings support assessments made by the International Union for Conservation of Nature, which lists six of seven species as vulnerable, endangered or critically endangered.
Advertisement Continue reading the main story

In contrast with some other at-risk species, perhaps sea turtles have been easier to manage because their threats are more tangible: They are accidentally trapped by fishermen or harvested by others as delicacies, aphrodisiacs or decoration.
In the most extreme cases, like in Tortuguero, Costa Rica, nearly all female green turtles at one point had been exported for turtle soup.
But conservation efforts there dating back to the 1950s made an impact, and protecting beaches, regulating fishing and establishing marine protected areas have helped save turtles in many locations.
This isnt often the case in conservation stories of animals, like endangered caribou, which face threats that are more difficult to manage.
Photo

But to truly know how well conservation is working, the researchers found, its best to look at long-term trends (although short-term data has its uses).
Thats because most sea turtle species only nest when foraging is good, and from year to year, the number of nests found on a beach can vary dramatically.
Detecting whether a juvenile sea turtle survives long enough to make babies can take 10 to 30 years while it matures.
They were surprised to find that with adequate protection, even small populations of turtles have a chance of survival.
In an area called French Frigate Shoals in Hawaii, for example, green sea turtles increased nest numbers from around 200 in 1973, when the Endangered Species Act was signed, to around 2,000 in 2012.
This species is now considered of least concern, by the International Union for Conservation of Nature.
Yet research is still lacking.
For all sea turtles, most male to female ratios are unknown, which is an important aspect of reproduction and appears to be altered with increasing sand temperatures, skewing births toward more females.
And a huge initiative to collect more data on flatback turtles in and around Australia may be complicated by a recent announcement that the country will shrink its marine protected areas.
Dr. Mazaris said his paper is a tale of cautionary optimism.
He commends conservationists working to save turtles over the past 70 years, but long term efforts need to be supported.
Times journalists around the world bring you a new 360 video every day.
The science itself  like most attempts to link brain biology to behavior  is murkier.
In recent decades, researchers have made extraordinary strides in understanding the workings of brain cells, neural circuits and anatomy.
Photo

Yet drawing a direct line from those basic findings to what people do out in the world is dicey, given the ineffable interplay between circumstance, relationships and personality.
What scientists  from such diverse fields as psychiatry, neurology and substance use  can say is that the arrows seem to be pointing in the same direction.
A number of brain states raise the risk of acting out violently, and the evidence so far, while incomplete, suggests that C.T.E.
may be one of them.
Dr. Samuel Gandy, director of the N.F.L.
neurology program at Mount Sinai Medical Center, said that rage and irritability are far and away the most prominent symptoms among former players with likely C.T.E., in his research.
His group has identified 10 of 24 former players who probably have C.T.E.
Scientists at Boston University, who reported the findings on Mr. Hernandez, have described similar behavior in many of the more than 100 players they have evaluated.
The caveat for both research efforts is that these samples are selective: Almost all of the players had signs of possible C.T.E.
before being studied, which led the players and their families to participate and to donate their brains for research.
It may still be that most of the athletes in violent sports who develop the signature brain pathology, especially at modest levels, are no more irritable than anyone else.
But an important hint to the contrary comes from a more mature corner of brain science: dementia research.
People with advanced dementia often begin to act in uncharacteristically aggressive ways, as many caregivers can attest.
In a recent study of dementia patients, Swedish researchers found that 97 of 281 dementia patients had a history of aggression.
Advertisement Continue reading the main story

Those who acted out earliest in the progression of their disease had so-called frontotemporal degeneration  that is, damage concentrated in the frontal and temporal lobes of the brain.
This is where C.T.E.
shows up, too.
In frontotemporal degeneration, a purported association has been made with criminal behavior, said Kevin Bieniek, a research fellow in the Dickson Neuropathology Lab at the Mayo Clinic College of Medicine in Jacksonville, Fla.
Different disease, but some clinical and pathological parallels to C.T.E.
All of this is far from definitive, given the wide variety of factors that affect motivation and impulsive behavior.
Substance abuse is a prominent example.
Mr. Hernandez was no stranger to illicit drugs, according to testimony at his murder trial.
Studies strongly suggest that people who are mentally unstable, particularly those with severe paranoia, are more likely to become violent when under the influence of alcohol or other drugs.
Photo

The link between steroids  such as testosterone  and rage is another confounding factor.
It is rarely clear in mature athletes whether they have used performance-enhancing drugs, or how much.
Testosterone aggravates aggression in the absence of pathology, said Dr. Gandy.
If theres pathology, its likely to make things worse.
As cases like Mr. Hernandezs and others continue to move into the courts, judges will be making decisions based on limited, piecemeal scientific evidence.
These wont be easy decisions to make.
Newsletter Sign Up Continue reading the main story Please verify you're not a robot by clicking the box.
Invalid email address.
Please re-enter.
You must select a newsletter to subscribe to.
Sign Up You agree to receive occasional updates and special offers for The New York Times's products and services.
Thank you for subscribing.
An error has occurred.
Please try again later.
View all New York Times newsletters.
The only way to diagnose C.T.E.
is at autopsy.
A number of scientists, including Dr. Gandys group, are working to refine brain imaging tests intended to detect the signature pathology in living patients.
Those tests are not yet definitive.
Over the past decade, many courts have been reluctant to admit brain scans as exculpatory evidence.
Theres no serious argument about whether violence comes from the brain, said Owen Jones, director of the MacArthur Foundation Research Network on Law and Neuroscience at Vanderbilt University.
Advertisement Continue reading the main story

Its just hard to make a credible claim that a particular brain injury has caused a particular act of violence.
Photo

More than half of all American teenagers are getting vaccinated against human papillomavirus, and the rate is rising over time, according to a new report from the Centers for Disease Control and Prevention.
Sixty percent of adolescents received one or more doses of the HPV vaccine in 2016, an increase of 4 percentage points from 2015, researchers found.
About a decade ago, the figure was less than 30 percent.
Were really encouraged to see this finding, said Shannon Stokley, a co-author of the report and associate director for science at the Immunization Services Division of the C.D.C.
The vaccine protects against strains of HPV that can cause cancers of the cervix, penis, anus and back of the throat.
Close to half of all Americans are infected at any given time, and nearly 32,000 get cancer from the virus each year.
Advertisement Continue reading the main story

About 90 percent of those cases could be prevented with the vaccine, according to the C.D.C.
The agency used to recommend three doses, but new guidelines introduced last year amended that to two doses for adolescents younger than age 15.
See how monkeys teach manners, elephants show empathy and ants imitate water in ScienceTake, combining cutting-edge research from the world of science with stunning footage of the natural world in action.
Osiris-Rex  a shortening of Origins, Spectral Interpretation, Resource Identification, and Security, Regolith Explorer  was launched last year and circled the sun, returning for Fridays flyby.
It is to arrive at Bennu in about a year.
The asteroid periodically crosses Earths orbit, and theres even a 1-in-2,700 chance that it could hit Earth between 2175 and 2196.
Advertisement Continue reading the main story

Scientists believe that Bennu, a dark asteroid about 500 yards in diameter, is full of carbon-rich molecules dating back to the birth of the solar system 4.5 billion years ago.
Those molecules might have been the ingredients that led to life on Earth.
Osiris-Rex will attempt to collect a few pounds of rock and dirt from Bennu by gently bouncing off the surface like a pogo stick and collecting material that it disturbs with a burst of nitrogen gas.
It will bring the samples back to Earth in 2023 for closer study.
For the flyby, there is no chance that Osiris-Rex, about the size of an S.U.V., will veer off course and slam into Earth.
Spacecraft navigators have become adept at using precise flybys as slingshots to steer spacecraft through the solar system.
NASAs New Horizons spacecraft, for example, added nearly 9,000 miles per hour to its speed with a Jupiter flyby in 2007, shortening its travel time to Pluto (It still took another eight years to get there).
Dr. Moreau said Osiris-Rex will pass within a kilometer of the targeted spot above Earth.
The timing is precise too, within a few tenths of a second.
It will make its closest approach to Earth at 12:52 p.m. Eastern time on Friday.
Dr. Moreau said his team will face larger navigational challenges once Osiris-Rex gets to Bennu in 2018.
Its the smallest object that has ever been orbited by a spacecraft, he said.
And thats exciting.
The European Space Agencys Rosetta spacecraft spent a couple of years exploring Comet 67P/ChuryumovGerasimenko, a comet about 2.5 miles wide.
Bennu is about one-eighth that diameter, and Osiris-Rex will come within a kilometer of the center of Bennu, Dr. Moreau said.
We are much closer to the object than Rosetta was, he said.
It means a lot of the errors in your estimation of the trajectory and navigation are less forgiving.
With gravity near the asteroid so slight, the navigators need to keep track of even very minute forces, including heat from the spacecraft radiators and the momentum imparted by particles of light hitting the solar panels.
Photo

For Friday, the Osiris-Rex team is encouraging amateurs to photograph the passing spacecraft and share the images on the mission website.
The Desert Fireball Network, a project based at Curtin University in Perth, Australia, will use high-end digital single lens reflex cameras to photograph Osiris-Rex from different angles.
Usually, the project tracks meteors burning up in the Earths atmosphere.
Advertisement Continue reading the main story

This time, the different angles will allow scientists to reconstruct the three-dimensional path that Osiris-Rex took as it swung by.
To fulfill his flow-finding mission, Mr. Wheal wants to bring what he calls his Dojo Domes to locations around the world.
Next year, he and his partners hope to build a one-million-square-foot complex in Vancouver, British Columbia, with a medical emphasis, combining brain-imaging technology with simpler equipment.
Advertisement Continue reading the main story

Mr. Wheal began to envision gatherings of this sort in 2007, while he was teaching at Esalen, the spiritual retreat in California.
With Steven Kotler, a journalist, he founded the Flow Genome Project, based in Austin, Tex., and dedicated to gathering the latest science behind flow states.
Its board of advisers includes neuroscientists, filmmakers and a kiteboarder.
It was his book, Stealing Fire, written with Mr. Kotler and published earlier this year, that attracted many of the flow campers to Utah.
In it, Mr. Wheal and Mr. Kotler consider the question of peak human performance, describing how so many powerful companies and individuals are now trying to optimize their own brains, in ways both legal and illegal.
They offer case studies from the Navy SEALs and Google, arguing that what the world today faces wicked problems, unprecedented and complex, that require creative solutions, the kinds that are most likely to come not from staid meetings in conference rooms but rather from non-ordinary states.
Flow, they write, is associated with six neurotransmitters: dopamine, serotonin, oxytocin, norepinephrine, anandamide and endorphins.
Knowing the neurochemical profile of flow means, in theory, people can devise ways of achieving it more often, more reliably and more quickly.
The new generation of flowsters are excited, perhaps, that using the advances of neuroscience, they might not have to meditate every day for 10 years to gain access to these layers of their brains.
Photo

This was a significant investment of time and money for me  this tells you how compelled I was to come here, said Alexandre Lang-Willar.
At 28, Mr. Lang-Willar is in some ways the embodiment of Mr. Wheals target demographic: the high achiever who grasps the brass ring, only to discover he craves something more.
Mr. Lang-Willar quit his job as a Goldman Sachs analyst and has created a dating app with his father called Invite and Meet, centered on live activities, that will be introduced later this year.
Reading Stealing Fire, Mr. Lang-Willar said, he became convinced that nothing less than a cultural awakening was underway.
Advertisement Continue reading the main story

By 8 a.m. each morning, the flow campers lay prone and shoeless in the Dojo Dome, moving back and forth on brightly colored foam rollers.
Other daily activities included balancing and bouncing on big yellow balls; acro-yoga, in which partners learn to lift each other in the air; and strapping into special contraptions, like Mr. Wheals 360 Swing, which allows those courageous enough to propel themselves, standing up, all the way around the swings axle in a complete loop.
Newsletter Sign Up Continue reading the main story Of the Moment The lifestyle newsletter from the Styles, Travel and Food sections, offering the latest trends to news you can use.
Please verify you're not a robot by clicking the box.
Invalid email address.
Please re-enter.
You must select a newsletter to subscribe to.
Sign Up You agree to receive occasional updates and special offers for The New York Times's products and services.
Thank you for subscribing.
An error has occurred.
Please try again later.
View all New York Times newsletters.
All of these undertakings were in the service of honing a crucial element in flow, what Mr. Wheal refers to as embodied cognition: integrating our whole minds and bodies through specific exercise, based on the science showing that physical movement directly affects how we think and feel.
They are tapping into spiritual intelligence that before now was only really talked about in a religious context, Kristen Ulmer said, sitting outside the Dojo Dome one morning.
Ms. Ulmer, formerly the top ranked extreme skier in the world, has also written a book, The Art of Fear.
She went on: A lot more people are saying theyre spiritual but not religious  but what does that really mean?
I would say sports and movement are the most oft way we access a spiritual experience and transcend our ego, but theyre the least discussed and least understood.
Other patients would require a slightly higher or lower concentration to achieve the same effect, but the variations were not large.
That led to their introduction in 1965 of a concept, called the minimum alveolar concentration, or MAC, that quickly became the standard measure of potency for anesthetic gases.
Because powerful anesthetics work at lower concentrations and weaker ones require higher doses, a lower MAC value would indicate a stronger drug.
Anesthesiologists use MAC values when planning doses needed for surgery.
The values are highly consistent from one patient to another and even among animals.
For any given drug, about the same concentration can anesthetize a 200-pound man, a smaller woman, a dog or a rat.
The amount needed to reach that concentration differs depending on the patients size, but the effective concentration itself does not change.
Dr. Shafer said the technique devised by Dr. Eger and his colleagues made the administering of anesthesia far safer and has saved millions of lives.
Photo

In later work, Dr. Eger identified new drugs that could be used as anesthesia, such as isoflurane, sevoflurane and desflurane, which are still the most widely used general anesthetics.
Ted Eger revolutionized modern anesthetic practice, and led the way to the development of the anesthetic gases used tens of millions of times a year, Dr. Michael A. Gropper, the chairman of the department of anesthesia and perioperative care at the University of California, San Francisco, wrote in an email.
Advertisement Continue reading the main story

Edmond I. Eger II was born on Sept. 3, 1930, in Chicago.
(His parents gave him a middle initial but not a middle name.)
His father was an advertising executive, and his mother, the former Miriam Newmann, was a homemaker.
As a boy, Dr. Eger skipped at least one grade, became a whiz at checkers and led the Hyde Park High School checker team to two city championships.
He graduated at 15, but, as a bored and indifferent student, wound up in the bottom 20 percent of the class.
He was soon hired to sell womens shoes, but after only one day on the job he decided he had had enough and resolved to apply for college.
He was accepted at Roosevelt College in Chicago, where he went from not working at all to working his butt off, Dr. Shafer said.
After a year, he transferred to the University of Illinois, where he majored in chemistry with a minor in math.
He went to medical school at Northwestern University.
In 1955, the same year he graduated from Northwestern, he married Dollie Ross, a speech therapist.
The marriage ended in divorce in 1983.
In 1996, he married Dr. Lynn Spitler, an immunologist, who survives him.
Dr. Eger is also survived by three daughters, Cris Cadence Waste, Doreen J. Eger and Renee R. Eger, and a son, Edmond Eger III, all from his first marriage; a half brother, Larry Eger; two stepchildren; seven grandchildren; and six step-grandchildren.
After completing his internship and residency, Dr. Eger served for two years as a captain in the medical corps, based at the Army hospital at Fort Leavenworth, Kan. From 1960 to 2006 he was a faculty member at the University of California, San Francisco.
He was an author of more than 500 scientific articles and an author or editor of seven books.
He received every award known to man in his specialty, Dr. Shafer said.
Dr. Eger spent the last 20 years of his career trying to understand how inhaled anesthetics work.
The drugs and their effects remain a mystery.
The same concentration that knocks out a person will anesthetize a sea slug or an amoeba, and will even paralyze a fern that normally curls up when touched, Dr. Shafer said.
The universality of those reactions suggests that the drugs are tapping into some biological mechanism that evolved eons ago.
Dr. Eger regretted that he had not been able to discover that mechanism, writing in his autobiography, The ah ha!
moment, the thrill of solving the hardest puzzle in all of pharmacology, awaits another investigator.
The alliance includes California, Colorado, Connecticut, Delaware, Hawaii, Massachusetts, Minnesota, New York, North Carolina, Oregon, Rhode Island, Vermont, Virginia and Washington; plus Puerto Rico.
All but two states are led by Democratic governors.
Advertisement Continue reading the main story

Yet theres a caveat to this announcement: Because the states in the alliance only represent 36 percent of the nations population, the United States as a whole is still expected to fall short of Mr. Obamas pledge.
A previous Rhodium Group analysis estimated that total United States emissions would likely drop just 15 to 19 percent by 2025 as Mr. Trump dismantled federal climate policies.
For the country to meet its commitments under the Paris agreement, further action by states would be needed.
The alliance could try to persuade other governors to ratchet up their ambitions, though those prospects are uncertain, since barriers to climate policy in Republican-leaning states are often as much political as technical.
Or the alliance states could pursue even deeper cuts themselves.
But here, experts say, they may face practical limits on how far they can go to tackle global warming on their own.
What States Can, and Cant, Do

In theory, state governments have plenty of ways to cut emissions without federal help.
They can require electric utilities to use more renewable power, modify building codes and impose tougher efficiency standards on appliances.
They can shape transportation infrastructure.
California is allowed to require automakers to sell more electric vehicles, and any state can join its program, as several in the Northeast have done.
Within the climate alliance, most of the efforts to date have focused on cleaning up electric grids.
Collectively, emissions from electricity in the alliance states are expected to drop by half between 2005 and 2025, the Rhodium Group analysis found.
But many experts consider these changes in the power sector the low-hanging fruit of climate policy, aided by a boom in natural gas production that has forced many coal plants into early retirement.
The real test, analysts say, will come as states try to juggle ever-greater shares of intermittent renewable power and tackle other, harder-to-decarbonize sectors like transportation and industry.
Here, the outlook is murkier.
According to the Rhodium Group, emissions from cars and trucks in the alliance states are expected to fall just 18 percent by 2025.
By contrast, emissions from sectors like buildings, heavy industry and agriculture are hardly expected to decline at all.
These sectors are expected to make up more than 60 percent of alliance states emissions by 2025.
Photo

That hints at one limit states may face in pursuing further climate action.
New technologies  like better batteries to help integrate wind and solar, or carbon capture for cement plants  could make the task of deeper decarbonization easier.
But historically, the federal government has led the way in researching and developing these technologies.
And with the Trump administration proposing deep cuts in federal energy research, it is unlikely that process will speed up anytime soon.
I see state action as important, but ultimately, if were serious about deep decarbonization, the federal government needs to get back involved, said David M. Hart, who studies energy policy at the Information Technology and Innovation Foundation.
Advertisement Continue reading the main story

There are other risks to a states-only approach.
According to Christopher Clack, chief executive of the grid-modeling firm Vibrant Clean Energy, the best way to fully decarbonize the United States electricity system with renewable energy would be through a national grid that allows optimally placed wind and solar resources from far-flung regions to balance each other out in the face of weather fluctuations.
But such a system would most likely require federal planning.
Right now, solar and wind are still a relatively small slice of electricity, so this isnt a big problem yet, Mr. Clack said.
But as these sources grow, he said, individual state efforts to build out their own renewable bases without broader coordination could lead to a system that is less well-suited to handling large quantities of wind and solar.
A Virtue of Necessity

For their part, the alliance states are trying to overcome these hurdles.
New York, for instance, is trying to nurture energy innovation on a small scale through a state "green bank" that helps companies bring riskier new technologies to market.
While this is no substitute for basic energy research at the national labs, state officials say it can help advance incremental innovation around technologies that are closer to market.
Were trying to make a virtue of necessity, said Richard Kauffman, Governor Cuomos chairman of energy and finance.
In an ideal world, it would be fantastic if we had the federal government providing leadership and investing in R&D and energy infrastructure.
But thats not only not the world were in  with this administration, its not even close to the world that were in.
States also face the risk that the Trump administration could try to thwart their efforts.
Officials in California, for instance, are preparing to challenge any effort by the federal government to pre-empt their electric vehicle mandate on automakers.
And it remains to be seen if the climate alliance can keep adding members.
There was already heavy political pressure in these states to move forward on clean energy, said David G. Victor, a climate policy expert at the University of California, San Diego.
But just because these states demonstrate that it can be done doesnt mean the politics suddenly shift in places like Kentucky or Kansas.
The ultimate significance of these state efforts, Dr. Victor said, may be to help prevent international climate efforts from collapsing, by reassuring other countries that the United States has not totally abandoned the issue.
Now that the rest of the world is over the initial reaction to Trump, theyre trying to figure out whats still real and whats not in U.S. policy, he said.
And these states can offer a starting point for other countries to gauge U.S. climate action, even when whats happening in Washington is chaotic.
But, he added: It all happened really quickly.
Mr. Friedemann, the administrative director of Lebus, could not be reached by email or telephone on Wednesday.
But he was quoted by the German news organization RBB24 as saying that he had made the decision to shoot when he was informed that the animal could be dangerous.
European bison, also known as wisent, are listed as vulnerable, or at risk of extinction, by the International Union for Conservation of Nature, whose Red List is the worlds most comprehensive inventory of threatened plant and animal species.
They are native to Belarus, Lithuania, Poland, Romania, Russia, Slovakia and Ukraine, according to the I.U.C.N.
There are about 4,000 free-roaming bison in herds, and a few thousand more in parks or other designated but open areas, according to the European Bison Conservation Center.
Threats include a lack of knowledge about the animal, habitat loss, a narrow genetic base making it weak against disease and the absence of a shared strategy among European nations to support the bison population, said Rewilding Europe, a conservation group that put the bison's population at about 3,000.
Wild bison had not been seen in Germany for over 200 years, said Christoph Heinrich, the director of conservation at the WWF in Germany, in announcing the lawsuit.
Efforts to reintroduce the animals, which can weigh over one ton, have taken place in recent years in western Germany.
The sighting in the east was an anomaly, despite being in line with the impulses of male bison, Mr. Klose said, which tend to roam more than female ones.
Newsletter Sign Up Continue reading the main story Please verify you're not a robot by clicking the box.
Invalid email address.
Please re-enter.
You must select a newsletter to subscribe to.
Sign Up You agree to receive occasional updates and special offers for The New York Times's products and services.
Thank you for subscribing.
An error has occurred.
Please try again later.
View all New York Times newsletters.
It was obviously a sign that there are suitable habitats in Germany, and if there is a possibility that these big herbivores can come to it, it is a good example that we have to be prepared for that, he said.
A legal framework exists, but if people are overwhelmed and dont know what to do, there is a wildlife management issue.
He said the WWF was suing based on conservation laws, which designated the bison as a protected animal.
We want to make a sign that endangered, rare, protected animals do have a right to live here in Germany and form an integral part of our ecosystem, and we think there needs to be harmonization between the countries, he said.
Animals dont know country borders.
Advertisement Continue reading the main story

He said the body of the bison was being examined and would be prepared for display, likely in a museum in Potsdam.
Conservationists are working on designating new places for large bison populations to live and breed, said Wanda Olech-Piasecka, a coordinator for the European Bison Conservation Center.
She said the bison had roamed for days near the border and his presence was reported to nature protection authorities in Poland.
She understood from news reports in Germany that local officials in Lebus, who could not be reached on Wednesday, had tried to find a veterinarian to handle the animal but they apparently panicked, she said.
For me, this is the reason we must tell people all around Europe and the world what wildlife means, Ms. Olech said.
Those animals must live with us, and we must learn how to treat them and to let them live.
She added: The problem was they did not start to look for somebody who could solve the problem and answer questions about the species.
The decision was made without research and this is a pity.
Photo

Two strong earthquakes, 12 days apart, have shaken Mexico this month, crumpling buildings, sending panicked people into the streets, and together killing hundreds of people who were unable to escape the destruction.
Just before midnight on Sept. 7, a magnitude-8.1 earthquake  the most powerful to hit Mexico in a century  rattled the country, doing the brunt of its damage to the southern part, which was closest to the quakes epicenter off the Pacific Coast.
Then, on Tuesday, as officials continued their cleanup and recovery efforts, an earthquake with a preliminary magnitude of 7.1 struck about 100 miles southeast of Mexico City, causing severe and sustained shaking in the capital.
It occurred on the anniversary of a quake in 1985 that killed as many as 10,000 people in Mexico.
Although it might seem unusual for two strong earthquakes to hit relatively near each other in such a short time, scientists say strong earthquakes can sometimes alter stresses nearby, leading to subsequent quakes.
But they are not sure yet if that is what happened with these two.
Heres a look at some of what they know about earthquakes, how often they strike, and where the most powerful ones can occur.
Why does Mexico keep getting hit with powerful earthquakes?
Photo

Mexicos location makes the country prone to strong earthquakes because it is in a so-called subduction zone.
Subduction zones are the parts of the earth where one slab of the crust is slowly sliding under another.
In Mexicos case, an oceanic plate  the Cocos  is gradually sinking beneath a continental plate  the North American.
Over time, stress builds because of friction between the slabs, and at some point, the strain becomes so great that all the pent-up energy is released in the form of an earthquake.
The subduction zone responsible for the two recent quakes runs along the western coast of Central America, from Central Mexico to Panama, said Gavin Hayes, a research geophysicist with the United States Geological Survey.
Other subduction zones are found across the globe  and experts say they are responsible for the worlds most powerful earthquakes.
In fact, earthquakes with a magnitude of 9.0 or higher can occur only in subduction zones, Dr. Hayes said.
Relatively recent examples of such megathrust quakes include a magnitude-9.1 quake off Japan in 2011, a magnitude-9.1 quake in Indonesia in 2004, a magnitude-9.2 quake that struck Alaska on Good Friday in 1964 and a magnitude-9.5 quake that struck Chile in 1960  the strongest quake ever recorded.
Why werent the Mexico quakes even stronger?
Both earthquakes that struck Mexico this month occurred within the sinking Cocos Plate, rather than between the Cocos Plate and the North American.
Had the recent quakes occurred between the plates, it would have produced a megathrust.
Quakes at plate boundaries usually involve larger faults and thus release more energy, generating shaking over larger areas.
But they also usually occur farther from the surface, Dr. Hayes said.
Newsletter Sign Up Continue reading the main story Get the Morning Briefing by Email What you need to know to start your day, delivered to your inbox Monday through Friday.
Please verify you're not a robot by clicking the box.
Invalid email address.
Please re-enter.
You must select a newsletter to subscribe to.
Sign Up You agree to receive occasional updates and special offers for The New York Times's products and services.
Thank you for subscribing.
An error has occurred.
Please try again later.
View all New York Times newsletters.
Earthquakes that happen inside a plate tend to be weaker, but closer to the surface.
Consequently they can cause major damage to whatever is sitting above them.
The Sept. 7 earthquake was stronger than the one that struck less than two weeks later, but experts said it could have less of an impact because the epicenter was farther from densely populated areas.
The more recent quake was much closer to Mexico City, which Dr. Hayes said is built on a sedimentary basin.
That kind of geology amplifies an earthquakes shaking more so than, say, an area with more bedrock.
How often do strong quakes happen?
Typically, about one quake of magnitude 8 or higher occurs somewhere in the world every year; there are about a dozen quakes of magnitude 7 or higher annually, Dr. Hayes said.
So far, 2017 has actually been a quiet year for earthquakes, Dr. Hayes said.
According to U.S.G.S.
data, about 4,200 earthquakes of magnitude 4.5 or higher have occurred around the world so far this year.
Over the same period in 2016 and 2015, about 5,100 quakes of the same strength occurred.
In 2014 there were closer to 6,000.
Where might a powerful quake strike in the United States?
There are two subduction zones in the United States.
One, which includes Alaska, generated the 9.2 quake in 1964, and therefore, Dr. Hayes said, another quake of that strength probably wont happen for hundreds of years.
The other, the Cascadia subduction zone, runs along the Pacific Coast on the western borders of Oregon and Washington.
There, the Juan de Fuca Plate is edging east and slipping slowly beneath the North American Plate.
This Cascadia subduction zone last generated a magnitude-9.0 earthquake in the Pacific Northwest in 1700, and based on what we know about the frequency of such quakes, Dr. Hayes said that another one of similar strength could occur any day now.
A quake that big, and the tsunami it would generate, would be devastating to both Oregon and Washington, especially their coasts, Dr. Hayes said.
Our operating assumption is that everything west of Interstate 5 will be toast, an official with the Federal Emergency Management Agency told The New Yorker.
Oklahoma has had issues in recent years with what Dr. Hayes called human-induced earthquakes, which are the result of wastewater being pumped into the ground.
They have been recorded with magnitudes as high as about 5.8, but its not clear how much stronger they can get.
The San Andreas fault, which creates something of a spine that runs north to south along most of western California, is capable of producing an earthquake with a magnitude as high as 8.2, Dr. Hayes said.
Such a quake would be relatively shallow, he added, and experts say it could be catastrophic for the densely populated state.
The memory of that day seems to have been woven into the DNA of Mexicans, even those who did not live through that tragedy.
At one site, Santiago Borden, 10, was straining to help, carrying a heavy jug of water over his shoulder.
Eventually he gave up and passed the burden to his father.
Youre a kid so you cant expect to do everything, his father, Abraham Borden, a lawyer and local politician, said to comfort him.
I want to show solidarity, Santiago said.
His father replied: Of course you do.
Youre Mexican, after all.
The work has been nonstop.
Overnight, whirring generators powered floodlights to illuminate the disaster scenes.
And almost always, accompanying the rescue workers were volunteers clearing debris and distributing water, surgical masks and mustard-colored work gloves.
The scene at a collapsed building on Laredo Street took a grim turn shortly after dawn, as two bodies were unearthed from the wreckage.
Still, work continued.
We will continue to work to try and rescue everybody who lives in the building, said Karen Pia, a doctor in charge of distributing medicine for the area.
Five people had been rescued, but there was still no word of Gabriela Jan Pimienta, 43.
Her uncle, Miguel ngel Pimienta, had fainted with exhaustion as he waited for news on Wednesday morning.
His face covered by a surgical mask against the dust raised by the debris, he wept as he acknowledged the grim truth behind the wait.
With every hour that passes, there is less possibility, he said.
The work was taking its toll on rescue workers, pushing many to the brink.
As dawn broke over two collapsed residential buildings in the middle-class neighborhood of Del Valle, workers paused to rest as they waited for replacements.
They believed 40 people were still trapped inside.
Theres a breaking point, and were of no help like this, said one government rescue worker with tears in his eyes.
He asked not to be named because he was not authorized to speak publicly.
Ive been doing this 20 years, but its difficult to find people who almost made it out but didnt, he added.
There was a mother and daughter in a door frame and they were so close.
Newsletter Sign Up Continue reading the main story Breaking News Emails Sign up to receive an email from The New York Times as soon as important news breaks around the world.
Please verify you're not a robot by clicking the box.
Invalid email address.
Please re-enter.
You must select a newsletter to subscribe to.
Sign Up You agree to receive occasional updates and special offers for The New York Times's products and services.
Thank you for subscribing.
An error has occurred.
Please try again later.
View all New York Times newsletters.
But even where the daily routine returned, as dog walkers emerged in the early light and cafes opened to people scanning the news and messages on their phones, the unfolding tragedy, sometimes just blocks away, was evident.
Ambulance sirens interrupted the silence, and police trucks rumbled by.
Volunteers carrying shovels headed to the rescue sites ready to take over from those who had been working all night.
Social media ricocheted with messages: photos of missing people, appeals for aid.
Poor neighborhoods in Xochimilco and Iztapalapa without much help, wrote Ricardo Becerra, an economist, on Twitter, referring to areas in the citys south and east.
Come with picks and shovels.
Over and over, variations on the list of supplies were repeated.
Hammer drills, work gloves, helmets, electrolytes, IV fluid, adrenaline, insulin.
And through it all, there were notes of hope: Found, read one message on Twitter.
Leonardo Faras from the Enrique Rebsmen school, the school where the 30 children died.
But the anguish was never far away.
Leonardo, pictured in a happier time wearing his knapsack and waving, was in the hospital.
He is in delicate condition, the message said.
The research here is part of a worldwide push that is growing increasingly urgent.
After decades of accumulating damage, followed by a huge die-off in 2015 and 2016, some scientists say they believe half the coral reefs that existed in the early 20th century are gone.
Advertisement Continue reading the main story

Instead of standing around watching the rest of them die, a vanguard of reef experts is determined to act.
In Florida, they are pioneering techniques that may allow the rapid re-establishment of reefs killed by heat stress.
In Hawaii, they are studying the biology of corals that somehow managed to cling to life as an earlier generation of people dumped raw sewage into a magnificent bay.
In the Caribbean, countries are banding together to create a genetic storage bank for corals, a backup plan if todays reefs all die.
We created these problems, said Michael P. Crosby, president of the Mote Marine Laboratory & Aquarium in Sarasota, Fla., one of the institutions leading this work.
We have to get actively involved in helping the corals come back.
Photo

Yet this new push to aid the worlds reefs comes with its own risks, and with many questions.
A large-scale restoration effort could be expensive, and so far, governments have put up only modest sums, despite the hit that their multibillion-dollar tourism industries could take from continued deterioration of the reefs.
Private philanthropists  including Paul G. Allen, the co-founder of Microsoft  are paying for much of the early work, spending millions.
But will they ultimately commit billions?
And while scientists are trying modest approaches first, the most effective strategy for saving reefs in the long run might be through genetic methods, including selective breeding or transferring heat-resistance genes into corals.
That type of thing has been done for crops, but would it be ethical to do it in the wild?
How do you decide what interventions are right and when to intervene?
said Madeleine van Oppen, a professor of marine biology at the University of Melbourne who is leading the experiments in Australia, aiming at what she calls the assisted evolution of coral reefs.
Theres a long road ahead; thats why were starting now.
Questions like these appear to be an inescapable part of the human future, and they go beyond coral reefs.
Already, some species of fish and birds are being kept alive only because they are bred in pens or hatcheries and then returned to the wild.
Forests are under stress on a rapidly warming planet, and scientists are wondering whether to manipulate their fate by planting more heat-resistant trees.
Creatures are fleeing toward the poles to escape rising heat; should humanity give them a lift?
Advertisement Continue reading the main story

Even the scientists who have plunged into this kind of work are asking themselves if it is the right thing and it if would ever be enough given the scale of climate changes predicted impact.
To think weve had to turn our science this way is kind of terrifying, but that is what weve had to do, said Ruth Gates, a coral researcher who is heading up the work in Hawaii.
Photo

UNITED NATIONS  As Hurricane Maria thunders through the Caribbean, island leaders still reeling from Hurricane Irma are calling on international organizations to provide money to help vulnerable countries recover from devastating storms linked to climate change.
In the Bahamas, emergency evacuations crippled the tourism on which the islands depend, said Darren A. Henfield, the countrys minister of foreign affairs.
The Dominican Republic, spared the worst of Hurricane Irma, fears a future of devastated beaches undermining decades of investment, President Danilo Medina said.
And on Barbuda, where Hurricane Irma destroyed everything in its path this month, there is not a single person left, officials said.
In one day, the population of neighboring Antigua swelled when it took in about 1,400 men, women and children who fled Barbuda.
Rodney Williams, the governor general of Antigua and Barbuda, said that in addition to the estimated $300 million cost of rebuilding Barbuda, Antigua was grappling with how to provide shelter, schools and medical care to hundreds of displaced people.
Photo

Today I ask how your governments will respond to this international crisis.
We ask the international community to help us, not because we want to outstretch a begging bowl, but because forces far beyond our control have pushed us to this dire situation, Mr. Williams told the United Nations on Monday.
Rebuilding Barbuda is not a task we can undertake alone.
Roosevelt Skerrit, the prime minister of Dominica, where Hurricane Maria made landfall late Monday as a Category 5 hurricane, pressed friendly nations and organizations to provide a helicopter so that he could survey the widespread devastation, which he described as mind-boggling.
In a special session convened by Secretary General Antnio Guterres before the official opening of the 72nd United Nations General Assembly, those Caribbean leaders and others appealed to the body to rethink humanitarian aid.
They asserted that because climate change is fueling more intense storms, vulnerable countries must have a better way to recover than to beg for money with each new devastation.
Newsletter Sign Up Continue reading the main story Interested in Climate Change?
Sign up to receive our in-depth journalism about climate change around the world.
Please verify you're not a robot by clicking the box.
Invalid email address.
Please re-enter.
You must select a newsletter to subscribe to.
Sign Up You agree to receive occasional updates and special offers for The New York Times's products and services.
Thank you for subscribing.
An error has occurred.
Please try again later.
View all New York Times newsletters.
Climate change, they said, is no longer a distant threat.
Islands are already suffering millions of dollars in losses that they can barely afford because of planet-warming greenhouse gas emissions baked into the atmosphere, the leaders said.
Climate change and its consequences should not be a subject of speculation or debate, Mr. Medina said.
Its a truth which hits us and which causes great uncertainty.
Leaders did not make explicit demands at the formal United Nations session.
Behind the scenes, though, several said it was past time for the creation of a special funding mechanism to help countries deal with the unavoidable consequences of climate change.
No amount of planning in Barbuda, for example, could have protected the island from the utter collapse of its infrastructure, Walton Alfonso Webson, Antigua and Barbudas ambassador to the United Nations, said in an interview.
The small islands have been saying for so many years in the climate change discussions that this is possible, Mr. Webson said.
Its no longer possible.
Its happened.
The issue of whether countries should be assured of some aid to rebuild from storms or droughts, or to relocate citizens if need be, is known in United Nations parlance as loss and damage.
The question of wealthy nations responsibility for providing this compensation has never been fully resolved.
Industrialized nations have consistently rejected being held legally liable for their decades of carbon pollution.
After a protracted debate, the Obama administration allowed the Paris agreement in 2015 to acknowledge the special needs of vulnerable countries, but American negotiators supported a provision saying that doing so does not involve or provide a basis for any liability or compensation.
Island leaders said this week that it was time to forget the issue of compensation and focus on ways rich and poor countries could work together.
Some have called for large-scale insurance programs that pay out after a disaster, while others have proposed a special international fund.
There really has to be some sort of mechanism for insurance so we can have quick restoration after events such as this, Diann Black-Layne, Antiguas ambassador for climate change, said in an interview.
If that doesnt happen, we will have no choice but then to look for a compensation system.
Thats not what we want, to spend years in court.
She and other diplomats said they would press for a funding mechanism at a United Nations session in Germany in November.
The State Department did not respond to questions about the Trump administrations position on loss and damage.
Michele J. Sison, the deputy United States ambassador to the United Nations, told leaders on Monday that the United States Agency for International Development had committed $1.2 million to help Caribbean islands hit by Hurricane Irma.
American assistance has gone toward purchasing hygiene kits, helping to deliver relief supplies, restoring water access and assessing damage.
"It is a core American value to help those in need, Ms. Sison said.
The following year he created a nonprofit consulting firm that became a line of first defense for companies facing health and safety challenges from the E.P.A.
Mr. Dourson has a popular sideline as a writer of books that combine Bible stories with his views on science.
His series, Evidence of Faith, is an examination of the intersection of evolution and bible history.
At a time when the E.P.A.
is in the early stages of putting in place Congresss 2016 overhaul of the law governing toxic chemicals, Mr. Doursons nomination to become the agencys assistant administrator for chemical safety has alarmed Democrats and some former E.P.A.
officials.
Dr. Doursons consistent endorsement of chemical safety standards that not only match industrys views, but are also significantly less protective than E.P.A.
and other regulators have recommended, raises serious doubts about his ability to lead those efforts, said Senator Tom Carper, Democrat of Delaware, the ranking minority member on the panel that will assess Dr. Doursons qualifications.
This is the first time anyone with such clear and extensive ties to the chemical industry has been picked to regulate that industry.
Neither Mr. Dourson nor the E.P.A.
would comment on the criticisms of his industry ties.
A notice on the E.P.A.s website praises Mr. Doursons achievements in toxicology and the quality of his research.
Trade groups for the $800 billion chemical industry are supportive of the nominee.
CropLife America, which lobbies for purveyors of pesticides, fungicides and rodenticides, called Mr. Dourson a perfect fit.
We welcome Dr. Doursons nomination, CropLife America notes on its website.
His extensive experience in risk assessment and science, both in government and private sector make him a valuable addition to the office.
The confirmation hearing for Mr. Dourson and others had been scheduled for Wednesday, but it has been postponed and a new date has not been set.
Advertisement Continue reading the main story

Senator John Barrasso, Republican of Wyoming and chairman of the Senate committee that will hold the hearing, defended Mr. Doursons nomination.
Dr. Dourson is an experienced toxicologist who deserves full and fair committee consideration, followed by a Senate vote, Mr. Barrasso said.
That should be the case for all of the nominees for leadership roles at the E.P.A.
The nonprofit consulting firm that Mr. Dourson founded and ran, TERA, became part of the University of Cincinnati in July 2015.
The department changed its name from the TERA Center to the Risk Science Center in January 2017.
The center disclosed that it collected about 30 percent of its funding from for-profit sources in the 2015-16 fiscal year.
Mr. Doursons ethics agreement says that he will not, once confirmed, participate for one year in any particular matter involving specific parties related to University of Cincinnati work he has done.
But Mr. Doursons financial disclosure report  filed after he was nominated  shows no direct payments to him from any chemical company, meaning any company-funded research Mr. Dourson did in the last year would likely have been paid for through the University of Cincinnati or another organization.
As a result, it is unlikely ethics rules would bar him from overseeing issues related to chemicals manufactured by companies he has conducted research for.
Grants given by companies to universities, but not to the scholars themselves, generally do not create conflicts that require individuals to recuse themselves from matters involving the companies, said Walter Shaub, the former head of the federal Office of Government Ethics.
Mr. Doursons firms clients have included the American Chemistry Council, the industrys top lobbying group.
The firm also advised individual companies, makers of flame retardants, compounds that are called chemicals of concern, and pesticides.
In some cases, his firm provided results that suggested the health risk of a certain chemical or product was less than the assessment by the E.P.A.
and other researchers.
Newsletter Sign Up Continue reading the main story Please verify you're not a robot by clicking the box.
Invalid email address.
Please re-enter.
You must select a newsletter to subscribe to.
Sign Up You agree to receive occasional updates and special offers for The New York Times's products and services.
Thank you for subscribing.
An error has occurred.
Please try again later.
View all New York Times newsletters.
PPG Industries, for example, a paint and coatings manufacturer, uses a chemical called 1,4-dioxane, which the E.P.A.
designated a likely carcinogen, in its products.
The substance is also created incidentally in some shampoos, cosmetics and personal care products through chemical reactions.
Advertisement Continue reading the main story

PPG hired Mr. Doursons group, which proposed establishing a safe level for 1,4-dioxane that would allow 1,000 times more risk than the E.P.As recommended level.
Other clients have included Albemarle, which makes flame retardants; Dow AgroSciences, which makes the pesticide chlorpyrifos; Waste Management; and Monsanto.
He has also helped DuPont defend a chemical called PFOA, used to make nonstick substances, from states, including West Virginia, that sued the company to clean up contaminated water.
Each of the four chemicals has been associated with severe health issues, like cancer, birth defects and developmental problems in children.
Mr. Doursons studies frequently concluded that the risk associated with these substances is much lower or more dubious than what E.P.A.
scientists and independent researchers have found.
The most striking discrepancy between findings by the agency and his firm is likely Mr. Doursons research funded by Dow AgroSciences on the pesticide chlorpyrifos, in which the authors recommended a safe level that was actually 33 times higher than the agencys standard, according to an analysis by Richard Denison, lead senior scientist at the Environmental Defense Fund.
The agency subsequently lowered its standard even more, to a level nearly 6,000 times less than Mr. Doursons, according to Mr. Denisons analysis.
E.P.A.
scientists then recommended that the product be banned for commercial use as a pesticide.
But E.P.A.
Administrator Scott Pruitt overruled a staff recommendation for a ban, after objections were raised by Dow and other industry players.
More recently, Mr. Dourson published a report titled A case study of potential human health impacts from petroleum coke transfer facilities, that was funded by Koch Industries, which has a subsidiary that handles petroleum coke and coal.
The report concluded that human exposures, if any, are well below levels that could be anticipated to produce adverse health effects in the general population.
Adam Finkel, executive director of the Penn Program on Regulation at the University of Pennsylvania Law School, who worked as a partner on a project with Mr. Dourson, said he observed a disturbing pattern.
Advertisement Continue reading the main story

Most of what he has done over time is to rush headlong to exonerate chemicals, Mr. Finkel said, adding that he stopped working with Mr. Dourson based on these concerns.
Pretty much every piece of work hes ever done, it just so happens that when they are finished with it, the risk is smaller than when they started, the doubt is larger, the concern is less.
But Oliver Kroner, now a Cincinnati city environmental official, praised Mr. Dourson, with whom he worked at TERA for nearly 10 years.
I think Mike is widely misunderstood, Mr. Kroner said.
Here in chemical regulation, were faced with a decision of whether we accept all the health science available to us, or if we exclude some science depending on the source.
Mike has worked hard to help strengthen the regulatory environment by improving the science coming out of industry and bringing a collaborative peer review approach to help assess the quality of industry-derived science, Mr. Kroner said.
Three other E.P.A.
nominees will be vetted at the confirmation hearing, one of whom also has spent much of his career defending businesses against the E.P.A.
: William L. Wehrum, named to head the agencys Office of Air and Radiation.
Mr. Wehrum, who was acting assistant administrator for air and radiation from 2005 to 2007, is now a partner in Hunton & Williams, which has a large energy and environmental law practice.
In the past few years, Mr. Wehrum has represented the Rubber Manufacturers Association, the American Petroleum Institute, the American Forest & Paper Association, and electric utilities, among others, against the E.P.A., legal records show.
Mr. Wehrum did not return messages seeking comment.
Liz Bowman, an E.P.A.
spokeswoman, pointed to Mr. Wehrums decades of working for the government and private sector as evidence of his qualifications for the new job.
Advertisement Continue reading the main story

Mr. Wehrums career includes over 31 years working in the environmental field through engineering, legal practice, and administrative duties, said Ms.
Bowman, who used to work for the American Chemistry Council, in a statement.
This addresses that criticism directly.
Of the 13 named storms so far in 2017, seven have been hurricanes, a number matched or exceeded at this point in the season only four times since 1995.
Four of the seven  Harvey, Irma, Jose and Maria  have reached Category 3 or higher, the threshold for a major hurricane on the Saffir-Simpson scale.
Only five other seasons since 1995 have had that many by Sept. 18.
More named storms have developed in the first three and a half months of the six-month hurricane season than developed in the entirety of the 1997, 1999, 2002, 2006, 2009, 2014 or 2015 seasons, according to National Hurricane Center and Weather Underground data.
Were running at about twice the pace of a typical season, Mr. Henson said.
Newsletter Sign Up Continue reading the main story Get the Morning Briefing by Email What you need to know to start your day, delivered to your inbox Monday through Friday.
Please verify you're not a robot by clicking the box.
Invalid email address.
Please re-enter.
You must select a newsletter to subscribe to.
Sign Up You agree to receive occasional updates and special offers for The New York Times's products and services.
Thank you for subscribing.
An error has occurred.
Please try again later.
View all New York Times newsletters.
A few caveats are in order.
August, September and October are almost always the peak of the season, and it isnt uncommon for several storms to develop on each others heels, as Harvey, Irma, Jose, Katia, Lee and Maria did from Aug. 17 to Sept. 16.
And the phrase above average loses some of its significance when 10 of the 15 most active hurricane seasons since antebellum America have occurred in the past two decades.
What stands out is the combination of frequency and intensity.
It may not be unheard-of for six storms to develop in a month, but it is very unusual for two Category 4 and two Category 5 hurricanes to do so.
It is also extremely unusual for three major hurricanes to pass through the same region in three weeks, as Irma, Jose and Maria have in the northeastern Caribbean.
The last time the northern Leeward Islands experienced two major hurricanes in the same season was 1899, and now it is looking at three in the same month.
Residents of some islands barely had time to assess the wreckage of a Category 5 hurricane before another bore down on them.
Others fled their homes to escape Irma, only to find themselves in the cross hairs of Maria.
A full reckoning of 2017s place in hurricane history will not be possible until the season ends on Nov. 30, but there are a few things we can say with reasonable confidence:

It will almost certainly be the most expensive season on record in the United States.
That distinction, like most others, currently belongs to 2005, when Katrina and three other major hurricanes caused more than $143.5 billion of damage in the country.
But this year, AccuWeather estimated that Hurricanes Harvey and Irma might cost a combined $290 billion: two storms producing double the economic damage of four in 2005.
Advertisement Continue reading the main story

It probably wont be the most active season on record.
That dubious distinction belongs, by a large margin, to 2005 and its 28 named storms, which exhausted the World Meteorological Organizations yearly list of 21 names and forced officials to dip into the Greek alphabet for the first time.
Fifteen of the storms (another record) were hurricanes, including seven (second place, behind 1950) Category 3 or higher.
Five names (yet another record) were retired: Dennis, Rita, Stan, Wilma and, of course, Katrina.
The 2017 season is unlikely to match that.
But it will most likely be near the top.
Currently, the 1933 season, with 20 named storms, sits in second place after 2005.
Behind that are five seasons that produced 19 named storms apiece, one that produced 18, three that had 16 and four that had 15, according to Weather Underground, which maintains a list of the top 10 busiest Atlantic hurricane seasons.
By the end of November, that list will almost certainly include 2017.
Mr. Henson said he would not be surprised if 2017 were the second year to run through the alphabet of names, which would mean at least 21 named storms.
(Hurricane names do not begin with Q, U, X, Y or Z.)
And even if it doesnt get quite that far, he said, the intensity of the activity this year will put it in the pantheon of our most active years regardless of what happens from here outward.
On Monday, she was bracing for Hurricane Maria, which was heading straight for the island that she and hundreds of others had escaped to for sanctuary, Guadeloupe.
This year we are cursed, Ms. Guyard, 28, said after a morning of last-minute grocery shopping as the hurricane approached.
When will we be able to breathe again?
When will all of the hurricanes stop?
Some islands still reeling from the impact of Hurricane Irma were bracing late Monday for Round 2, closing schools, stores and just about everything else before the storm made landfall.
More than two dozen people were killed by Irma, and on Monday emergency shelters were beginning to fill up on Guadeloupe, Dominica and Montserrat, as well as on the islands of St. Kitts and Nevis.
Those who chose to stay home were busy boarding up their houses, trimming trees or gathering stockpiles of food and water.
Karine Fleury, 47, a psychologist in Martinique, which was also expected to be hit by Maria, said she found out about the storm only on Sunday while shopping for groceries.
After that, it was a race to prepare herself  both physically and mentally  for the storms landing.
I know its going to be impressive during the storm, she said.
And when we go out for the first time afterward, seeing the fallen trees and the damage, its always scary.
Though Maria is expected to trace a similar path to Hurricane Irma, some of the islands hit hardest by that storm may be spared.
Instead, having escaped the wrath of Irma, Guadeloupe and Dominica were expected to bear the initial brunt of Maria.
Advertisement Continue reading the main story

But the already storm-battered islands could be affected in other ways.
In addition to being the main sanctuary for those evacuating St. Martin, Guadeloupe has also become the staging ground for the relief effort.
If the storm hits hard, it could delay or upend the desperately needed aid going to its neighbor.
Though the number of hurricanes passing through the Caribbean feels exceptional this year, experts say it is not unheard-of.
Ten years ago, Hurricanes Karl, Igor and Julia were all active at the same time.
In 1998, four hurricanes  Georges, Ivan, Jeanne and Karl  passed through the Atlantic at once, according to the hurricane research division of the National Oceanic and Atmospheric Administration.
Still, the number of serious storms this year is higher than average.
None of this is unusual in terms of the number; we are in the peak week of the peak month in what was forecast to be an active season, said Dennis Feltgen, an agency spokesman.
What is horrific is the succession of Category 4 Harvey, Category 4 and 5 Irma and now Maria.
Newsletter Sign Up Continue reading the main story Sign Up for the Race/Related Newsletter Join a deep and provocative exploration of race with a diverse group of New York Times journalists.
Please verify you're not a robot by clicking the box.
Invalid email address.
Please re-enter.
You must select a newsletter to subscribe to.
Sign Up You agree to receive occasional updates and special offers for The New York Times's products and services.
Thank you for subscribing.
An error has occurred.
Please try again later.
View all New York Times newsletters.
A typical season has 12 named storms, six of which become hurricanes, with three of those becoming major hurricanes.
So far this season, which is more than halfway through, there have been 13 named storms, including seven hurricanes, four which have been major.
The constant threat of storms has created a state of agitation among some residents  and some resistance to making the necessary preparations.
Were tired of this, lamented Stan Musquer, 44, an artist in Guadeloupe who says he has been evacuated three times in his life, forced to move all of his belongings ahead of storms that did not strike as badly as anticipated.
Were tired of this.
Its stressful.
Local authorities across the region have implored residents to take the warnings seriously.
Having suffered season after season of hurricanes, they are fearful residents will shrug off yet another storm.
Mr. Skerrit, Dominicas prime minister, addressed the tiny nation Monday morning, asking residents to remain calm but be prepared.
I want to say to Dominicans that this is not a time for heroism, he said.
This much water in Dominica is dangerous given our terrain, and therefore persons should not wait for something to happen in order to take action.
Advertisement Continue reading the main story

Preparation for many Caribbean islanders has, by now, become second nature.
I stocked up as much as possible with fresh water and dried foods, said Michele Henderson, a musician on Dominica.
I secured my dogs, rabbits and chickens.
We boarded up the windows and we are hunkered down in our basement apartment.
Others said that while they were not worried, they were still taking the proper precautions.
Ive seen lots of hurricanes and know what to expect, said Melissa Roberts, 36, on Dominica.
You stay home, buckle down and wait for it to clear.
Impending storms are often likened to past storms, especially in the minds of survivors.
For those on St. Martin, Hurricane Luis in 1995 was the big one until Irma blasted apart their island.
On the island of Montserrat, meanwhile, Hurricane Hugo looms large.
Photo

After Hugo, my house was full of glass and coconuts, said Susan Edgecombe, who runs Tradewinds Real Estate on the island and recalled the attitude that existed before that hurricane in 1989.
Everyone said: Theres not been a hurricane in over 60 years.
Dont stress.
Yeah right, she snapped.
We didnt get power for over three months, so now I am the prep queen.
On the island of Antigua, which Hurricane Irma skirted while destroying nearby Barbuda, Dr. Jillia Bird, an optometrist, said she had once again gone through her familiar pre-hurricane motions, closing storm shutters, moving items off the floor in case of flooding, covering beds with shower curtains and towels to prevent soaking, packing up valuables and moving from her wooden house to her mothers storm-tested 60-year-old concrete house.
Dr. Bird also chilled her merlot  in case of power loss, she said  and found time for an act of generosity toward friends of hers in the British Virgin Islands, which was slammed by Hurricane Irma: She bought credit for their cellphones, as a kindness gesture as they face another difficult night, she said.
In St. Kitts and Nevis, the storm has particularly cruel timing, landing on the eve of the 34th anniversary of the islands independence.
The good news for residents there, however, was that most of them had already prepared for Irma, and so had less to do to prepare for Maria.
Advertisement Continue reading the main story

Well, following the recent passage of Hurricane Irma, I still have most things in place, like candles, flashlight with batteries and important items in plastic bags, said Precious Mills, a resident.
I would say that I have basic measures in place to weather the storm.
While the island escaped largely unscathed from Irma, some homes sustained damage.
For John Webster, who lives in the affected area of Newton Ground, that means the patchwork fixes he made to his roof after Irma will have to do for now.
I had planned to properly fix it, but I am going to wait until this storm has passed, he said.
He rejected the idea that the governors represent a shadow diplomatic corps.
I dont think its a shadow, he said.
Were in the sunlight.
Were shining the bright light of success.
Advertisement Continue reading the main story

The General Assembly brings together leaders and senior officials from nearly 200 countries for a week of speeches and high-level talks.
Climate change  though not the central issue of the meeting  will have a high profile, in part because of confusion over whether the United States can be persuaded to remain in the Paris agreement.
The White House has asserted that it will stay in the pact if suitable terms are met.
It has not laid out what those terms might be.
Mr. Cohns breakfast meeting on Monday with a handful of ministers to discuss climate change was the only event the White House has scheduled on the topic.
Thats why we have governors here.
Because we dont have someone from Washington D.C., Governor Brown said.
The states are picking up the baton.
Governor Brown, along with Governor Inslee and Gov.
David Y. Ige of Hawaii, is also participating in Climate Week, a series of high-level panels on climate change.
The Trump administration did not send a representative to the meetings, which are not affiliated with the United Nations.
Governor Inslee will also meet with Frank Bainimarama, the prime minister of Fiji, which holds the presidency of United Nations climate change negotiations this year.
Another governor, Roy Cooper of North Carolina, was expected to announce this week that his state would join California, 13 other states and Puerto Rico in the United States Climate Alliance, a group of states and territories that has pledged to uphold the Paris agreement.
Photo

The addition of North Carolina to the group would be notable because it is among the highest-emitting states.
Without big producers of greenhouse gasses, experts say, states will struggle to make significant gains in reaching global climate goals.
As part of the Paris accord, the Obama administration vowed that United States greenhouse gas emissions would fall at least 26 percent below 2005 levels by 2025.
Each governor in the alliance is promoting individual policies aimed at meeting that goal.
Advertisement Continue reading the main story

Oregon and New York, for instance, plan to shutter their last coal plants by 2020.
In Virginia, Gov.
Terry McAuliffe has ordered new carbon regulations for local power plants.
Californias legislature has authorized one of the most sweeping climate programs in the world, aimed at decarbonizing every corner of the states economy, from transportation to agriculture.
We certainly believe if the federal government wont lead in this area, we want the world to understand there are states across the country that are committed, said Governor Ige, whose state enacted the first 100-percent-renewable energy standard.
Despite the push by the climate alliance, though, those states make up just one-third of the nations population, and the United States as a whole is still expected to fall short of Mr. Obamas pledge.
The big question, then, is whether the alliance can persuade other states to join its climate efforts.
Unless their leadership is met with followership, the impact will be pretty limited, said David G. Victor, a professor of international relations at the University of California, San Diego.
The idea has always been that if these states can demonstrate the technologies needed to cut emissions, that will help shift the politics in other states.
But we have yet to see that play out.
Perhaps the governors biggest challenge will be the deep partisan divide over climate change in the country.
Nicolas Loris, a research fellow in energy and environmental policy at the Heritage Foundation, a conservative research groups, said he believed the governors were speaking for a minority of Americans.
He said that more than half of American states opposed Mr. Obamas signature effort to cut emissions, known as the Clean Power Plan.
Its one thing if these governors are communicating their respective state climate plans, as ill-advised as they may be, Mr. Loris said.
No matter how expensive or ineffective these climate policies may be, its their right.
They can deliver that message to anyone they please.
But they shouldnt pretend their actions are the will of the federal government or the entire country.
For now the climate alliance is focused on the economic argument that it is possible to cut emissions without harming the economy.
According to a recent report from the Brookings Institution, every state in the alliance has managed to cut emissions since 2000 even while expanding their overall economic output.
The coalition states say they have created 1.3 million clean energy jobs while cutting emissions.
We have blown up the argument that acting on climate change is bad for your economy, Governor Inslee said.
Thoroughly Americanized by that time, it was a huge culture shock, he recalled.
Leaning on the family loom while his father worked, he listened to stories about what life had been like in the village and how it had changed.
Eventually he rediscovered a passion for weaving.
And he realized that, just as he had forgotten the richness of his culture, the village, too, was slowly losing its age-old traditions.
Advertisement Continue reading the main story

There was not much soul anymore, he said.
These natural dyes were absolutely on the brink of extinction.
Mr. Gutirrez and his family decided to create their own weaving studio to create pieces using only natural dyes and to teach others how to do it.
His sister, Juana Gutirrez Contreras, serves as dye master, combining seven or eight natural elements to produce more than 40 colors.
Ms. Contrerass husband, Antonio Lazo Hernandez, is also a master weaver and helps develop the textile designs.
Photo

Potassium alum, or potash, a mineral found in the mountains around Oaxaca, is used as a mordant, holding the dye to the yarn.
In addition to plants gathered in the mountains, flora common in local gardens  zapote negro, marush and pomegranate, for example  are also used as sources for dye.
The indigo and cochineal pigments, however, are purchased from elsewhere.
The ail plant grows primarily in the southern part of the state of Oaxaca.
As for cochineal  a dye that colored the red coats of British soldiers  tens of thousands of dried insects are needed to produce just one pound of dye.
So the studio buys the pigment from families who farm the prickly pear cactuses that host the parasitic insects.
Only females produce the carminic acid that is responsible for the intense red coloring.
The dye is so harmless that the family uses it to water the garden, while the remaining plant material serves as mulch.
Advertisement Continue reading the main story

In Teotitln, Mr. Gutirrez is not the only artisan concerned with preserving Zapotec weaving traditions.
Perhaps a dozen others in the village use natural dyes exclusively, and some train tourists in the techniques.
But Mr. Gutirrezs fluency in English and familiarity with the United States  he still lives much of the time in Ventura  have given him an opportunity to reach a wider audience.
Im able to see my culture from an outsiders perspective and also from an insiders, as part of the community, he said.
Photo

The family is compiling a book of dye recipes, formulas passed down for centuries by word of mouth.
And Mr. Gutirrez has worked to expand traditional designs used by Zapotec weavers into new territory, for example, by combining wool with agave fiber, palm leaves  used for thousands of years to make mats for sleeping  or other natural materials.
He has contributed samples of natural dyeing materials to the Harvard Art Museums Forbes Pigment Collection.
Last year, with a grant from the Smithsonian Museum of the American Indians Artists Leadership Program, he held a four-day workshop in Teotitln for 15 young weavers, teaching them the science and practice of natural dyes.
Their reaction was almost a, Wow, let me try it, let me do it, said Keevin Lewis, who ran the program and recently retired as the museums outreach coordinator.
They got their hands on the wool, they got their hands in the dye, they were crushing up the cochineal bug.
They were in it.
In July, Mr. Gutirrezs work was featured in the innovation section of the annual International Folk Art Market in Santa Fe.
What my family and I are doing is continuing an art form and honoring the work that our ancestors started, he said.
I think once people learn more about these processes, then theyll support this market, and thats how it will continue.
The surprise discovery came at the conclusion of a project that was spread over three years and a hectic two weeks  necessitated by limited financing and availability.
Atlantic Ocean 100 Miles SCOTLAND North Sea N. IRELAND ENGLAND Irish Sea IRELAND BRITAIN WALES London Celtic Sea Boxford English Channel FRANCE

Among the first to spot it was Joy Appleton, who leads the Boxford History Project and who was a driving force behind the excavation.
I was stunned into silence, Ms. Appleton recalled of her first sight of the small red tiles, each the size of her fingernail.
Which is unusual.
The expert on site, Matt Nichol, was equally surprised.
I will never forget that moment, said Mr. Nichol, a professional archaeologist who was supervising the dig.
It was down to the volunteers, it really was.
I get quite emotional about it; it was something to see their drive, added Mr. Nichol, project officer for Cotswold Archaeology, a company whose normal work includes helping real estate developers preserve archaeological finds.
Experts say the mosaic at what is now called Boxford villa depicts Bellerophon, a hero of Greek mythology who was sent to kill the chimera, a fire-breathing monster with the head of a lion, the torso of a goat and the tail of a serpent.
Hercules is also thought to be featured, fighting a centaur, and so is Cupid.
According to Anthony Beeson, a specialist in classical art and member of the board of the Association for Roman Archaeology, the discovery is important for several reasons.
Advertisement Continue reading the main story

It is so unusual because it has all sorts of quirks which you dont expect, and it has subjects on it that are completely alien to mosaics in this country, he said.
Photo

Some figures breach geometric borders and there seems to be a trompe loeil effect.
Mr. Beeson added that he could not think of another Roman mosaic in this country that is as creative as this one.
There are inscriptions, too, though only about one-third of the mosaic was excavated and the full text was not uncovered.
The execution is uneven, Mr. Beeson said, suggesting that the mosaicist has had ideas above his technical ability, producing what he called a very sophisticated design done in a slightly nave manner.
Boxford villa had been marked  inaccurately, as it turned out  on an old map.
(It later turned out that the site was disturbed in the 19th century, when the installation of a land drainage pipe damaged part of the mosaic.)
With much to be revealed, there is still a lot to learn about life at Boxford villa, though its owner must have been affluent and cultured, and clearly wanted to show off a broad knowledge of mythology to guests.
Mr. Beeson says he believes that it is really vital that we at least see what the other part of the mosaic is like; its too important not to investigate.
For Ms. Appleton, the discovery has filled in part of a missing link in the history of Boxford, a village of around 300 inhabitants.
Evidence of Stone, Bronze and Iron Age life had been discovered, and there is a Saxon window in the local church that dates to the period before the Norman invasion of 1066.
Given the geographical location, and the quality of the agricultural land, Ms. Appleton was confident that this was also the site of a Roman settlement, a conviction reinforced by the discovery of several artifacts from that period.
Photo

So Ms. Appleton and her group pressed ahead.
Survey work began in 2012, and there were discoveries at two nearby sites during digs in 2015 and 2016.
Advertisement Continue reading the main story

Without expert archaeological knowledge, the Boxford History Project secured help from the Heritage Lottery Fund, a national charity funded by lottery receipts, to pay for professional supervision during a project made up of short excavations conducted on three sites in three consecutive years.
By chance, Mr. Nichol, who supervised the dig, does not live far away, an irony that is not lost on an archaeologist who has traveled to the Western Sahara, Macedonia and Serbia in search of antiquities, only to discover something so spectacular so close to home.
Newsletter Sign Up Continue reading the main story Please verify you're not a robot by clicking the box.
Invalid email address.
Please re-enter.
You must select a newsletter to subscribe to.
Sign Up You agree to receive occasional updates and special offers for The New York Times's products and services.
Thank you for subscribing.
An error has occurred.
Please try again later.
View all New York Times newsletters.
I never believed it could have been in Boxford, 30 minutes drive from home, he said.
What happens to the site into the future remains unclear because, once exposed to the atmosphere, a mosaic deteriorates quickly unless it is preserved.
Ms. Appleton and Mr. Nichol hope to uncover the rest of it next year, though that will depend on whether funding can be raised.
But even if they do, making it available for public view would be costly.
Just lifting it and removing it from the site would cost hundreds of thousands of pounds.
In fact, there was little choice about an immediate solution  which was to bury it in the earth that had protected it for so long because the farmer needed his land back to plant his wheat crop.
More Reporting on Archaeology

Even that step proved nerve-racking because there was no money to pay for security to prevent treasure hunters from damaging or destroying the mosaic.
The risks increased when, the day before the mosaic was covered over, the site was opened to friends and families of the volunteers who had worked there, increasing the number of people who knew the location.
Advertisement Continue reading the main story

So for the organizers, it was a relief, rather than a disappointment, when the earth was pushed back to conceal their discovery.
The night before that was done, Mr. Nichol decided to keep watch over the site from his S.U.V.
with a supply of food, a sleeping bag and a bottle of red wine, all donated by volunteers.
The Roman owner of the villa would have invited guests to eat and drink on this spot, using the mosaic as a talking point, so a mildly bacchanalian vigil did not seem out of place.
I was on my own in the field; it was incredible, Mr. Nichol said.
He described how, in the solitude, he felt drawn back across the centuries to experience a unique connection to the more-than-1,600-year-old archaeological site, and to the mythological images of its extraordinary, colorful mosaic.
The wine did help, he added.
Photo

UNITED NATIONS  Gary D. Cohn, the top White House economic adviser, told ministers from several major allies on Monday that the Trump administration was unambiguous about its plans to withdraw from the Paris agreement on climate change unless new terms were met.
Ministers emerging from the 90-minute breakfast in a back room of The Smith, a brasserie near the United Nations, described the meeting as genial and productive.
But, they said, they learned no specifics from Mr. Cohn about the likelihood of the United States remaining in the global accord or what changes would be needed to make it acceptable to the White House.
I made the presidents position unambiguous, to where the president stands and where the administration stands on Paris, Mr. Cohn told reporters after the meeting.
We reaffirmed the presidents statement that he made in the Rose Garden, and we continue to reinforce what the president is saying.
President Trump announced in a Rose Garden speech in June that the Paris agreement  under which nearly 200 nations pledged voluntary targets to cut planet-warming greenhouse gas emissions and to support poor countries grappling with rising global temperatures  was bad for Americas economy.
He said the United States would withdraw from the agreement, but left open the possibility that he might try to renegotiate the accord.
When the State Department filed a formal notice to the United Nations that it intended to withdraw from the Paris agreement, officials made clear that Washington might rejoin if suitable terms were found.
Newsletter Sign Up Continue reading the main story Interested in Climate Change?
Sign up to receive our in-depth journalism about climate change around the world.
Please verify you're not a robot by clicking the box.
Invalid email address.
Please re-enter.
You must select a newsletter to subscribe to.
Sign Up You agree to receive occasional updates and special offers for The New York Times's products and services.
Thank you for subscribing.
An error has occurred.
Please try again later.
View all New York Times newsletters.
Yet several diplomats said that while the United States position may have been clear, its plans were not.
Ministers said Mr. Cohn did not clarify what it might take for the United States to remain a party to the accord, other than saying such conditions are not there yet, according to two aides who received summaries of the meeting.
Both said Mr. Cohn emphasized that the United States wanted to work with other countries on climate change and energy.
It was quite clear that their position is, right now they are pulling out of the Paris agreement, said Catherine McKenna, Canadas environment minister.
Ms. McKenna said she had asserted that the accord was nonnegotiable and irreversible, but she said there was broad agreement that countries wanted to lower emissions without harming the economy.
The fact that were meeting is quite good, said Edna Molewa, the South African environment minister.
You know, in climate change discussions we believe in engagement, and engagement is very tough.
She said she did not learn anything new from the meeting with Mr. Cohn but added, Its important to understand where we come from.
Also at the meeting were ministers from Argentina, Brazil, the European Union, Japan and Australia.
The White House has not released a full list of attendees.
He offers a variety of love hacks because he doesnt believe in one-size-fits-all solutions for relationships.
He suggests picking whichever hack appeals and starting right away.
Touch Your Partner

Holding hands can win you points even when you dont mean it, as demonstrated in an experiment with couples who watched a video together.
Some people were instructed not to touch their partners during the video, while others were told to touch in a warm, comfortable and positive way.
Afterward, the people who had been touched reported being more confident of being loved by their partner  and this effect occurred even when the people knew that their partners actions were being directed by the researchers.
Their rational selves knew that the hand-holding wasnt a spontaneous gesture of affection, but it made them feel better anyway.
Dont Jump to Bad Conclusions

If your partner does something wrong, like not returning a phone call, dont over-interpret it.
Researchers have found that one of the biggest differences between happy and unhappy couples is their attributional style in explaining a partners offense.
The unhappy couples tend to automatically attribute something like an unreturned phone call to a permanent inner flaw in the partner (Hes too selfish to care about me) rather than a temporary external situation, like an unusually busy day at work.
When something goes wrong, before drawing any conclusions about your partner, take a few seconds to consider an alternative explanation that puts the blame elsewhere.
Newsletter Sign Up Continue reading the main story Please verify you're not a robot by clicking the box.
Invalid email address.
Please re-enter.
You must select a newsletter to subscribe to.
Sign Up You agree to receive occasional updates and special offers for The New York Times's products and services.
Thank you for subscribing.
An error has occurred.
Please try again later.
View all New York Times newsletters.
Picture a Fight From the Outside

In an experiment with 120 married couples in Chicago, Dr. Finkel periodically asked questions about their marriages over the course of two years.
During the first year, their satisfaction with their marriages declined, which unfortunately is typical.
At the start of the second year, some of the couples were instructed to try something new when they found themselves in an argument: Think about this disagreement with your partner from the perspective of a neutral third party who wants the best for all involved; a person who see things from a neutral point of view.
How might this person think about the disagreement?
How might he or she find the good that could come from it?
Again, that little exercise made a big difference.
Over the next year, marital satisfaction remained stable in those couples, whereas it continued to decline in the control group that hadnt been instructed to take the third-party perspective.
Advertisement Continue reading the main story

Make a Gratitude List

Once a week, write down a few things your partner has done to invest in the relationship, as the participants in one experiment were instructed to do.
Other participants were instructed to list things they had done themselves to invest in the relationship.
The ones who patted themselves on the back subsequently felt a little more committed to the relationship, but the ones who wrote about their partners contributions felt significantly more committed  and also, not surprisingly, a lot more grateful toward their partners.
Accept a Compliment

One of the most common factors in failed marriages is the rejection sensitivity of one partner.
People with low self-esteem have a hard time believing their partner really loves them, so they often preemptively discount their partners affection in order to avoid being hurt by the expected rejection.
Eventually, even when they start off with a loving partner, their worst fear comes true because their defensive behavior ends up driving the other person away.
In testing ways to counteract this anxiety, researchers asked insecure people to recall a specific compliment from their partner.
Giving a detailed account of the situation and the compliment didnt have any effect, apparently because these insecure people could dismiss it as a lucky aberration: For once I did something right.
But there was a notable effect when people were asked to think about the compliment abstractly: Explain why your partner admired you.
Describe what it meant to you and its significance for your relationship.
That quick exercise helped them see why their partner could really care for them.
Celebrate Small Victories

When your partner tells you about something that went right in his or her day, get excited about it.
Ask questions so your partner can tell you more about the event and relive it.
Put some enthusiasm into your voice and your reactions.
Researchers call this a capitalization attempt.
When researchers studied couples who were trained to use these techniques in their evening discussions, it turned out that each partner took more pleasure from their own victories, and both partners ended up feeling closer to each other.
By sharing the joy, everyone came out ahead  and in true love-hack fashion, it didnt take much time at all.
In their estimation, the most savage heat waves that we experience today will likely become routine in a matter of decades.
The coastal inundation that has already begun will grow worse and worse, forcing millions of people to flee.
The immense wave of refugees that we already see moving across continents may be just the beginning.
Advertisement Continue reading the main story

Scientists urged decades ago that we buy ourselves some insurance by cutting emissions.
We yawned.
Even today, when millions of people have awakened to the danger, tens of millions have not.
So the political demand for change is still too weak to overcome the entrenched interests that want to block it.
In Washington, progress on climate change has stalled.
The administration has announced its intent to withdraw from the global Paris climate accord.
And top Trump appointees insist that the causes of climate change are too uncertain and the scientific forecasts too unreliable to be a basis for action.
Photo

This argument might have been halfway plausible 20 years ago  or, if you want to be generous, even 10 years ago.
But today?
Today, salt water is inundating the coastal towns of the United States, to the point that they are starting to put giant rulers in the intersections so people can tell if it is safe to drive through.
The city leaders are also posting no wake signs  not on canals but on the streets, to stop trucks from plowing through the water so fast as to send waves crashing into nearby homes.
We all see the giant storms, more threatening than any in our lifetimes  and while scientists are not entirely comfortable yet drawing links between the power of these hurricanes and climate change, many people are coming to their own common-sense conclusions.
As the challenges in the real world worsen, some senior Republicans continue to question the link between human-caused emissions and rising temperatures.
Scott Pruitt, the head of the Environmental Protection Agency, said this on CNBC in March:

I think that measuring with precision human activity on the climate is something very challenging to do and theres tremendous disagreement about the degree of impact, so no, I would not agree that its a primary contributor to the global warming that we see.
Note that he acknowledges the planet is warming.
Note that he offers no alternative hypothesis about the cause of that warming  nor will he ever, for the simple reason that there is no plausible alternative.
But still, he clings to uncertainty as a reason to do nothing.
To be sure, fair-minded people can and should ask: What are the real uncertainties?
They exist in climate science, and despite claims to the contrary made by climate denialists, nobody hides them.
You can spend long days at conferences, as I have, hearing from the scientists themselves about all the error bars of their studies and all the weak points of their computer models.
Advertisement Continue reading the main story

We are not entirely sure, for instance, how much the planet will warm in response to a given level of emissions.
That is a pretty basic question, and the inability of climate science to narrow it down has been one of the great frustrations of the field these past few decades.
In the 1970s, the experts made a best guess about how sensitive the Earth would be to greenhouse gases, and as evidence accumulates, that early estimate is holding up pretty well.
Forecasts from the 1980s and 1990s about the rate of warming have proven fairly accurate, too, give or take 20 percent.
ProPublica and The New York Times analyzed Medicare prescription drug plans covering 35.7 million people in the second quarter of this year.
Only one-third of the people covered, for example, had any access to Butrans, a painkilling skin patch that contains a less-risky opioid, buprenorphine.
And every drug plan that covered lidocaine patches, which are not addictive but cost more than other generic pain drugs, required that patients get prior approval for them.
In contrast, almost every plan covered common opioids and very few required any prior approval.
The insurers have also erected more hurdles to approving addiction treatments than for the addictive substances themselves, the analysis found.
Alisa Erkes lives with stabbing pain in her abdomen that, for more than two years, was made tolerable by Butrans.
But in January, her insurer, UnitedHealthcare, stopped covering the drug, which had cost the company $342 for a four-week supply.
After unsuccessfully appealing the denial, Ms. Erkes and her doctor scrambled to find a replacement that would quiet her excruciating stomach pains.
They eventually settled on long-acting morphine, a cheaper opioid that UnitedHealthcare covered with no questions asked.
It costs her and her insurer a total of $29 for a months supply.
Advertisement Continue reading the main story

The Drug Enforcement Administration places morphine in a higher category than Butrans for risk of abuse and dependence.
Addiction experts say that buprenorphine also carries a lower risk of overdose.
UnitedHealthcare, the nations largest health insurer, places morphine on its lowest-cost drug coverage tier with no prior permission required, while in many cases excluding Butrans.
And it places Lyrica, a non-opioid, brand-name drug that treats nerve pain, on its most expensive tier, requiring patients to try other drugs first.
Ms. Erkes, who is 28 and lives in Smyrna, Ga., is afraid of becoming addicted and has asked her husband to keep a close watch on her.
Because my Butrans was denied, I have had to jump into addictive drugs, she said.
UnitedHealthcare said Ms. Erkes had not exhausted her appeals, including the right to ask a third party to review her case.
It said in a statement, We will work with her physician to find the best option for her current health status.
Matthew N. Wiggin, a spokesman for UnitedHealthcare, said that the company was trying to reduce long-term use of opioids.
All opioids are addictive, which is why we work with care providers and members to promote non-opioid treatment options for people suffering from chronic pain, he said.
Dr. Thomas R. Frieden, who led the Centers for Disease Control and Prevention under President Obama, said that insurance companies, with few exceptions, had not done what they need to do to address the opioid epidemic.
Right now, he noted, it is easier for most patients to get opioids than treatment for addiction.
Photo

Leo Beletsky, an associate professor of law and health sciences at Northeastern University, went further, calling the insurance system one of the major causes of the crisis because doctors are given incentives to use less expensive treatments that provide fast relief.
The Department of Health and Human Services is studying whether insurance companies make opioids more accessible than other pain treatments.
An early analysis suggests that they are placing fewer restrictions on opioids than on less addictive, non-opioid medications and non-drug treatments like physical therapy, said Christopher M. Jones, a senior policy official at the department.
Advertisement Continue reading the main story

Insurers say they have been addressing the issue on many fronts, including monitoring patients opioid prescriptions, as well as doctors prescribing patterns.
We have a very comprehensive approach toward identifying in advance who might be getting into trouble, and who may be on that trajectory toward becoming dependent on opioids, said Dr. Mark Friedlander, the chief medical officer of Aetna Behavioral Health, who participates on its opioid task force.
Aetna and other insurers say they have seen marked declines in monthly opioid prescriptions in the past year or so.
At least two large pharmacy benefit managers announced this year that they would limit coverage of new prescriptions for pain pills to a seven- or 10-day supply.
And bowing to public pressure  not to mention government investigations  several insurers have removed barriers that had made it difficult to get coverage for drugs that treat addiction, like Suboxone.
Experts in addiction note that the opioid epidemic has been changing and that the problem now appears to be rooted more in the illicit trade of heroin and fentanyl.
But the potential for addiction to prescribed opioids is real: 20 percent of patients who receive an initial 10-day prescription for opioids will still be using the drugs after a year, according to a recent study conducted by researchers at the University of Arkansas for Medical Sciences.
Several patients said in interviews that they were terrified of becoming dependent on opioid medications and were unwilling to take them, despite their pain.
In 2009, Amanda Jantzi weaned herself off opioids by switching to the more expensive Lyrica to treat the pain associated with interstitial cystitis, a chronic bladder condition.
But earlier this year, Ms. Jantzi, who is 33 and lives in Virginia, switched jobs and got a new insurer  Anthem  which said it would not cover Lyrica because there was not sufficient evidence to prove that it worked for interstitial cystitis.
Ms. Jantzis appeal was denied.
She cannot afford the roughly $520 monthly retail price of Lyrica, she said, so she takes generic gabapentin, a related, cheaper drug.
She said it does not manage the pain as well as Lyrica, which she took for eight years.
Its infuriating, she said.
Photo

Ms. Jantzi said she wanted to avoid returning to opioids.
However, I could see other people, faced with a similar situation, saying, I cant live like this, Im going to need to go back to painkillers,  she said.
In a statement, Anthem said that its members have to meet certain requirements before it will pay for Lyrica.
Members can apply for an exception, the insurer said.
Ms. Jantzi said she did just that and was turned down.
Advertisement Continue reading the main story

With Butrans, the drug that Ms. Erkes was denied, several insurers either do not cover it, require a high out-of-pocket payment, or will pay for it only after a patient has tried other opioids and failed to get relief.
Newsletter Sign Up Continue reading the main story Please verify you're not a robot by clicking the box.
Invalid email address.
Please re-enter.
You must select a newsletter to subscribe to.
Sign Up You agree to receive occasional updates and special offers for The New York Times's products and services.
Thank you for subscribing.
An error has occurred.
Please try again later.
View all New York Times newsletters.
In one case, OptumRx, which is owned by UnitedHealth Group, suggested that a member taking Butrans consider switching to a lower cost alternative, such as OxyContin or extended-release morphine, according to a letter provided by the member.
Mr. Wiggin, the UnitedHealthcare spokesman, said the companys rules and preferred drug list are designed to ensure members have access to drugs they need for acute situations, such as post-surgical care or serious injury, or ongoing cancer treatment and end of life care, as well as for long-term use after alternatives are tried.
Butrans is sold by Purdue Pharma, which has been accused of fueling the opioid epidemic through its aggressive marketing of OxyContin.
Butrans is meant for patients for whom other medications, like immediate-release opioids or anti-inflammatory pain drugs, have failed to work, and some scientific analyses say there is not enough evidence to show it works better than other drugs for pain.
Dr. Andrew Kolodny is a critic of widespread opioid prescribing and a co-director of opioid policy research at the Heller School for Social Policy and Management at Brandeis University.
Dr. Kolodny said he was no fan of Butrans because he did not believe it was effective for chronic pain, but he objected to insurers suggesting that patients instead take a cheaper, more dangerous opioid.
Thats stupid, he said.
Ms. Erkess pain specialist, Dr. Jordan Tate, said her patient had been stable on the Butrans patch until January, when UnitedHealthcare stopped covering the product and denied Ms. Erkess appeal.
Without Butrans, Ms. Erkes, who once visited the doctor every two months, was now in Dr. Tates office much more frequently, and once went to the emergency room because she could not control her pain, thought to be related to an autoimmune disorder, Behcets disease.
Photo

Dr. Tate said she and Ms. Erkes reluctantly settled on extended-release morphine, a drug that UnitedHealthcare approved without any prior authorization, even though morphine is considered more addictive than the Butrans patch.
She also takes hydrocodone when the pain spikes and Lyrica, which UnitedHealthcare approved after requiring a prior authorization.
Ms. Erkes acknowledged that she could have continued with further appeals, but said the process exhausted her and she eventually gave up.
While Dr. Tate said Ms. Erkes had not shown signs of abusing painkillers, her situation was far from ideal.
Shes in her 20s and shes on extended-release morphine  its just not the pretty story that it was six months ago.
Advertisement Continue reading the main story

Many experts who study opioid abuse say they also are concerned about insurers limits on addiction treatments.
Some state Medicaid programs for the poor, which pay for a large share of addiction treatments, continue to require advance approval before Suboxone can be prescribed or they place time limits on its use, both of which interfere with treatment, said Lindsey Vuolo, associate director of health law and policy at the National Center on Addiction and Substance Abuse.
Drugs like Suboxone, or its generic equivalent, are used to wean people off opioids but can also be misused.
The analysis by ProPublica and The Times found that restrictions remain prevalent in Medicare plans, as well.
Drug plans covering 33.6 million people include Suboxone, but two-thirds require prior authorization.
Even when such requirements do not exist, the out-of-pocket costs of the drugs are often unaffordable, a number of pharmacists and doctors said.
At Dr. Shawn Ryans addiction-treatment practice in Cincinnati, called BrightView, staff members often take patients to the pharmacy to fill their prescriptions for addiction medications and then watch them take their first dose.
Research has shown that such oversight improves the odds of success.
But when it takes hours to gain approval, some patients leave, said Dr. Ryan, who is also president of the Ohio Society of Addiction Medicine.
The guy walks out, and you cant blame him, Dr. Ryan said.
Hes like, Hey man, Im here to get help.
Whats the deal?
Have you had trouble paying for prescription drugs?
Tell us about it at propublica.org/drugprices.
